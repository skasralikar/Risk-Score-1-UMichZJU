{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (1.17.2)\n",
      "CPU times: user 37.5 ms, sys: 16.5 ms, total: 54 ms\n",
      "Wall time: 2.48 s\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "CPU times: user 19.3 ms, sys: 8.94 ms, total: 28.2 ms\n",
      "Wall time: 1.49 s\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.17.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.4.0)\n",
      "CPU times: user 18.7 ms, sys: 8.8 ms, total: 27.5 ms\n",
      "Wall time: 1.41 s\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=f977b4cd9b9919327570b69d3e26ef72a3a26cd1a00554fb52f11de2e3ca9a18\n",
      "  Stored in directory: /Users/skasralikar/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "CPU times: user 44.6 ms, sys: 16.9 ms, total: 61.5 ms\n",
      "Wall time: 2.81 s\n",
      "Collecting datetime\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/22/a5297f3a1f92468cc737f8ce7ba6e5f245fcfafeae810ba37bd1039ea01c/DateTime-4.3-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zope.interface (from datetime)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/a3/80438e695d45017ced5defd8cd02a3b53430d555a4a17afd3c9dbf106bc4/zope.interface-5.1.0-cp37-cp37m-macosx_10_9_x86_64.whl (192kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 4.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/anaconda3/lib/python3.7/site-packages (from datetime) (2019.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from zope.interface->datetime) (41.4.0)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "Successfully installed datetime-4.3 zope.interface-5.1.0\n",
      "CPU times: user 48.9 ms, sys: 18.3 ms, total: 67.2 ms\n",
      "Wall time: 2.58 s\n",
      "Collecting argparse\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "CPU times: user 29.1 ms, sys: 11.7 ms, total: 40.8 ms\n",
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "import sys\n",
    "%time  !{sys.executable} -m pip install numpy\n",
    "%time  !{sys.executable} -m pip install pandas\n",
    "%time  !{sys.executable} -m pip install matplotlib\n",
    "%time  !{sys.executable} -m pip install sklearn\n",
    "%time  !{sys.executable} -m pip install datetime\n",
    "%time  !{sys.executable} -m pip install argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/ad/51da3af99a515c31226f50c37d85e63423f9e28174c2984e11e4fb47ae01/torch-1.5.1-cp37-none-macosx_10_9_x86_64.whl (80.5MB)\n",
      "\u001b[K     |████████████████████████████████| 80.5MB 17.0MB/s eta 0:00:01     |████████████████████▊           | 52.1MB 3.5MB/s eta 0:00:09     |█████████████████████████▍      | 63.8MB 14.9MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from torch) (1.17.2)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.7/site-packages (from torch) (0.17.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.5.1\n",
      "CPU times: user 1.07 s, sys: 389 ms, total: 1.45 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "# method 1 to install 'torch'\n",
    "%time  !{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: torch-1.0.1-cp37-cp37m-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# method 2 to install 'torch'\n",
    "!pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read database about the confirmed cases and try to filter out the area\n",
    "import pandas as pd\n",
    "import datetime\n",
    "url=\"https://raw.githubusercontent.com/datadesk/california-coronavirus-data/master/latimes-place-totals.csv\"\n",
    "df = pd.read_csv(url,header=0)\n",
    "df = df[df['county']=='Los Angeles'][['date','place','confirmed_cases']]\n",
    "\n",
    "target = ['Alhambra', 'Arcadia', 'Beverly Hills', 'Boyle Heights', 'Carson', 'Diamond Bar', 'Encino', 'Gardena', 'Glendale', 'Glendora',\n",
    "          'Granada Hills', 'Inglewood', 'La Mirada', 'Lancaster', 'Manhattan Beach', 'Melrose', 'Northridge', 'San Dimas', 'San Pedro',\n",
    "          'Santa Monica', 'Sherman Oaks', 'Silver Lake', 'Tarzana', 'Torrance', 'Venice', 'West Adams', 'West Hills', 'West Hollywood',\n",
    "          'West Vernon', 'Westchester', 'Altadena', 'Baldwin Hills', 'Brentwood', 'Culver City', 'Eagle Rock', 'Hollywood',\n",
    "          'Hollywood Hills', 'Lynwood', 'Mar Vista', 'Monterey Park', 'North Hollywood', 'Reseda', 'Santa Clarita', 'Woodland Hills',\n",
    "          'Sylmar', 'Walnut', 'Beverlywood', 'Burbank', 'Calabasas', 'Castaic', 'Covina', 'Crestview', 'East Los Angeles', 'Echo Park', \n",
    "          'Hancock Park', 'Hawthorne', 'Lawndale', 'Lomita', 'Palms', 'Playa Vista', 'South El Monte', 'Stevenson Ranch', 'Studio City',\n",
    "          'Tujunga', 'University Park', 'Valley Glen', 'Van Nuys', 'Vermont Knolls', 'Westwood', 'Whittier', 'Century City', 'El Segundo',\n",
    "          'Lake Balboa', 'Lakewood', 'Miracle Mile', 'Park La Brea', 'Redondo Beach', 'San Fernando', 'South Whittier', 'Winnetka', \n",
    "          'Del Rey', 'La Canada Flintridge', 'La Verne', 'Montebello', 'Sun Valley', 'Sunland', 'Vermont Vista', 'Vernon Central',\n",
    "          'West Covina', 'Westlake', 'Bellflower', 'Canoga Park', 'East Hollywood', 'Los Feliz', 'Paramount', 'Rancho Palos Verdes', \n",
    "          'South Gate', 'Agoura Hills', 'Duarte', 'Exposition Park', 'Hyde Park', 'Lincoln Heights', 'Palmdale', 'South Park',\n",
    "          'Wilshire Center', 'Canyon Country', 'Claremont', 'Downey', 'Harbor Gateway', 'Harvard Heights', 'Highland Park', \n",
    "          'La Puente', 'Norwalk', 'Pico Rivera', 'Porter Ranch', 'San Gabriel', 'Wholesale District', 'Willowbrook', 'Arleta',\n",
    "          'Bell Gardens', 'Glassell Park', 'Panorama City', 'Pomona', 'Valinda', 'Watts', 'Azusa', 'Bell', 'Chatsworth', \n",
    "          'Hacienda Heights', 'Harbor City', 'Leimert Park', 'Maywood', 'Monrovia', 'North Hills', 'Pacoima', 'Avalon', 'Baldwin Park',\n",
    "          'Bassett', 'Central', 'El Monte', 'El Sereno', 'Harvard Park', 'Lake Los Angeles', 'Rosemead', 'Rowland Heights', 'Temple City',\n",
    "          'Acton', 'Cerritos', 'Cloverdale/Cochran', 'Compton', 'Downtown', 'Huntington Park', 'Koreatown', 'Mt. Washington', 'Pasadena', \n",
    "          'South Pasadena', 'Wilmington']\n",
    "\n",
    "df = df[df['place'].isin(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Data Type \n",
    "result = df.copy()\n",
    "result['place'].replace('Silver Lake','Silverlake',inplace = True)\n",
    "result['date'] = pd.to_datetime(result['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add New Columns\n",
    "result = result.sort_values(by=['place','date'])\n",
    "result['new_confirmed_cases'] = result['confirmed_cases']\n",
    "result['ave_new7_10after'] = result['confirmed_cases']\n",
    "result['ave_new6_9after'] = result['confirmed_cases']\n",
    "result['ave_new8_11after'] = result['confirmed_cases']\n",
    "result.iloc[0,3] = None\n",
    "\n",
    "# Calculate Daily New Cases\n",
    "for i in range(1,len(result)):\n",
    "    if result.iloc[i,1] != result.iloc[(i-1),1]:\n",
    "        result.iloc[i,3] = None\n",
    "    else:\n",
    "        result.iloc[i,3] = max([0,int(result.iloc[i,2])-int(result.iloc[(i-1),2])])    \n",
    "# Calculate Future Cases in AVG\n",
    "for i in range(1,len(result)):    \n",
    "    if i < (len(result)-11):\n",
    "        if result.iloc[i,1] == result.iloc[(i+11),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3] + result.iloc[(i+11),3])/4.0\n",
    "        elif result.iloc[i,1] == result.iloc[(i+10),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/3.0\n",
    "        elif result.iloc[i,1] == result.iloc[(i+9),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/3.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3])/2.0\n",
    "        elif result.iloc[i,1] == result.iloc[(i+8),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3])/2.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3])/3.0\n",
    "            result.iloc[i,6] = result.iloc[(i+8),3]\n",
    "        elif result.iloc[i,1] == result.iloc[(i+7),1]:\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3])/2.0\n",
    "            result.iloc[i,6] = result.iloc[i,4] = result.iloc[(i+7),3]\n",
    "        else:\n",
    "            for j in range(8):\n",
    "                if result.iloc[i,1] == result.iloc[(i+7-j),1]:\n",
    "                    result.iloc[i,4] = result.iloc[i,5] = result.iloc[i,6] = result.iloc[(i+7-j),3]\n",
    "                    break\n",
    "    else:\n",
    "        if i < (len(result)-10):\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/3.0\n",
    "        elif i < (len(result)-9):\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/3.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3])/2.0\n",
    "        elif i < (len(result)-8):\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3])/2.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3])/3.0\n",
    "            result.iloc[i,6] = result.iloc[(i+8),3]\n",
    "        elif i < (len(result)-7):\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3])/2.0\n",
    "            result.iloc[i,6] = result.iloc[i,4] = result.iloc[(i+7),3]\n",
    "        else:          \n",
    "            result.iloc[i,4] = result.iloc[i,5] = result.iloc[i,6] = result.iloc[-1,3]\n",
    "\n",
    "result.dropna(inplace = True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read Mobility Data\n",
    "\n",
    "url2= \"https://covid19-static.cdn-apple.com/covid19-mobility-data/2013HotfixDev8/v3/en-us/applemobilitytrends-2020-07-25.csv\"\n",
    "apple_mobility = pd.read_csv(url2,header=0)\n",
    "\n",
    "url3 = \"https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv?cachebust=04188f017409e90a\"\n",
    "google_mobility = pd.read_csv(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit Mobility Data for Merging\n",
    "apple_mobility = apple_mobility[apple_mobility['region']=='Los Angeles']\n",
    "google_mobility = google_mobility[google_mobility['sub_region_2'] == 'Los Angeles County']\n",
    "\n",
    "amobility= apple_mobility.copy()\n",
    "amobility = amobility.set_index('transportation_type').transpose().iloc[5:]\n",
    "\n",
    "amobility['date'] = pd.to_datetime(amobility.index)\n",
    "\n",
    "gmobility = google_mobility[['date','retail_and_recreation_percent_change_from_baseline',\n",
    "                       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                       'parks_percent_change_from_baseline',\n",
    "                       'transit_stations_percent_change_from_baseline',\n",
    "                       'workplaces_percent_change_from_baseline',\n",
    "                       'residential_percent_change_from_baseline',]].copy()\n",
    "gmobility['date'] = pd.to_datetime(google_mobility['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Modify Econ Data\n",
    "url4 = \"https://raw.githubusercontent.com/skasralikar/Risk-Score-1-UMichZJU/master/econ_level.csv\"\n",
    "econ = pd.read_csv(url4, index_col = 0)\n",
    "econ.columns = ['place','Density_Per_Sq_Mile','population','Income_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Mobility Data\n",
    "final = result.merge(amobility,how = 'left',on = 'date')\n",
    "final_result = final.merge(gmobility,how = 'left',on = 'date')\n",
    "final_result.dropna(inplace = True)\n",
    "\n",
    "# Merge Econ Data\n",
    "final_results = final_result.merge(econ, how = 'left', on = 'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['ZIP'] = final_results['place']\n",
    "final_results['ZIP'].astype(str)\n",
    "final_results['date'].astype(str)\n",
    "\n",
    "LA_daily = final_results[['ZIP','date','confirmed_cases','new_confirmed_cases','population','Density_Per_Sq_Mile','Income_level','driving','transit',\n",
    "                          'walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                          'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                          'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                          'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline',\n",
    "                          'ave_new7_10after','ave_new6_9after','ave_new8_11after']]\n",
    "\n",
    "LA_daily_predict = final_results[['ZIP','date','confirmed_cases','new_confirmed_cases','population','Density_Per_Sq_Mile','Income_level','driving',\n",
    "                                  'transit','walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                                  'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                                  'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                                  'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline',\n",
    "                                  'ave_new7_10after']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZIP       date  confirmed_cases  new_confirmed_cases  population  \\\n",
      "0  Acton 2020-04-03                1                  0.0        6522   \n",
      "1  Acton 2020-04-04                1                  0.0        6522   \n",
      "2  Acton 2020-04-05                1                  0.0        6522   \n",
      "3  Acton 2020-04-06                1                  0.0        6522   \n",
      "4  Acton 2020-04-07                1                  0.0        6522   \n",
      "5  Acton 2020-04-08                1                  0.0        6522   \n",
      "6  Acton 2020-04-09                1                  0.0        6522   \n",
      "7  Acton 2020-04-10                5                  4.0        6522   \n",
      "8  Acton 2020-04-11                5                  0.0        6522   \n",
      "9  Acton 2020-04-12                5                  0.0        6522   \n",
      "\n",
      "   Density_Per_Sq_Mile  Income_level driving transit walking  \\\n",
      "0                  166             2   52.04    26.3    52.6   \n",
      "1                  166             2   44.77   22.14   48.28   \n",
      "2                  166             2   33.92   19.22   36.02   \n",
      "3                  166             2   40.81   21.76   37.63   \n",
      "4                  166             2   41.36   22.16   38.13   \n",
      "5                  166             2   42.38   21.82   41.92   \n",
      "6                  166             2   40.85    19.1   35.31   \n",
      "7                  166             2   48.47    21.7    45.5   \n",
      "8                  166             2   46.57   21.66   50.85   \n",
      "9                  166             2   30.88    17.8   31.73   \n",
      "\n",
      "   retail_and_recreation_percent_change_from_baseline  \\\n",
      "0                                              -43.0    \n",
      "1                                              -50.0    \n",
      "2                                              -53.0    \n",
      "3                                              -49.0    \n",
      "4                                              -51.0    \n",
      "5                                              -49.0    \n",
      "6                                              -55.0    \n",
      "7                                              -49.0    \n",
      "8                                              -51.0    \n",
      "9                                              -64.0    \n",
      "\n",
      "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
      "0                                              -15.0   \n",
      "1                                              -20.0   \n",
      "2                                              -27.0   \n",
      "3                                              -27.0   \n",
      "4                                              -30.0   \n",
      "5                                              -27.0   \n",
      "6                                              -34.0   \n",
      "7                                              -22.0   \n",
      "8                                              -19.0   \n",
      "9                                              -38.0   \n",
      "\n",
      "   parks_percent_change_from_baseline  \\\n",
      "0                               -38.0   \n",
      "1                               -54.0   \n",
      "2                               -59.0   \n",
      "3                               -58.0   \n",
      "4                               -58.0   \n",
      "5                               -51.0   \n",
      "6                               -69.0   \n",
      "7                               -55.0   \n",
      "8                               -54.0   \n",
      "9                               -69.0   \n",
      "\n",
      "   transit_stations_percent_change_from_baseline  \\\n",
      "0                                          -51.0   \n",
      "1                                          -51.0   \n",
      "2                                          -57.0   \n",
      "3                                          -59.0   \n",
      "4                                          -58.0   \n",
      "5                                          -57.0   \n",
      "6                                          -65.0   \n",
      "7                                          -58.0   \n",
      "8                                          -52.0   \n",
      "9                                          -60.0   \n",
      "\n",
      "   workplaces_percent_change_from_baseline  \\\n",
      "0                                    -51.0   \n",
      "1                                    -41.0   \n",
      "2                                    -43.0   \n",
      "3                                    -54.0   \n",
      "4                                    -54.0   \n",
      "5                                    -55.0   \n",
      "6                                    -57.0   \n",
      "7                                    -57.0   \n",
      "8                                    -43.0   \n",
      "9                                    -46.0   \n",
      "\n",
      "   residential_percent_change_from_baseline  ave_new7_10after  \\\n",
      "0                                      25.0              1.00   \n",
      "1                                      20.0              0.00   \n",
      "2                                      17.0              0.00   \n",
      "3                                      25.0              0.00   \n",
      "4                                      26.0              1.00   \n",
      "5                                      26.0              1.00   \n",
      "6                                      29.0              1.00   \n",
      "7                                      29.0              1.25   \n",
      "8                                      20.0              0.75   \n",
      "9                                      18.0              0.75   \n",
      "\n",
      "   ave_new6_9after  ave_new8_11after  \n",
      "0             1.00              0.00  \n",
      "1             1.00              0.00  \n",
      "2             0.00              0.00  \n",
      "3             0.00              1.00  \n",
      "4             0.00              1.00  \n",
      "5             1.00              1.00  \n",
      "6             1.00              1.25  \n",
      "7             1.00              0.75  \n",
      "8             1.25              0.75  \n",
      "9             0.75              0.75  \n",
      "     ZIP       date  confirmed_cases  new_confirmed_cases  population  \\\n",
      "0  Acton 2020-04-03                1                  0.0        6522   \n",
      "1  Acton 2020-04-04                1                  0.0        6522   \n",
      "2  Acton 2020-04-05                1                  0.0        6522   \n",
      "3  Acton 2020-04-06                1                  0.0        6522   \n",
      "4  Acton 2020-04-07                1                  0.0        6522   \n",
      "5  Acton 2020-04-08                1                  0.0        6522   \n",
      "6  Acton 2020-04-09                1                  0.0        6522   \n",
      "7  Acton 2020-04-10                5                  4.0        6522   \n",
      "8  Acton 2020-04-11                5                  0.0        6522   \n",
      "9  Acton 2020-04-12                5                  0.0        6522   \n",
      "\n",
      "   Density_Per_Sq_Mile  Income_level driving transit walking  \\\n",
      "0                  166             2   52.04    26.3    52.6   \n",
      "1                  166             2   44.77   22.14   48.28   \n",
      "2                  166             2   33.92   19.22   36.02   \n",
      "3                  166             2   40.81   21.76   37.63   \n",
      "4                  166             2   41.36   22.16   38.13   \n",
      "5                  166             2   42.38   21.82   41.92   \n",
      "6                  166             2   40.85    19.1   35.31   \n",
      "7                  166             2   48.47    21.7    45.5   \n",
      "8                  166             2   46.57   21.66   50.85   \n",
      "9                  166             2   30.88    17.8   31.73   \n",
      "\n",
      "   retail_and_recreation_percent_change_from_baseline  \\\n",
      "0                                              -43.0    \n",
      "1                                              -50.0    \n",
      "2                                              -53.0    \n",
      "3                                              -49.0    \n",
      "4                                              -51.0    \n",
      "5                                              -49.0    \n",
      "6                                              -55.0    \n",
      "7                                              -49.0    \n",
      "8                                              -51.0    \n",
      "9                                              -64.0    \n",
      "\n",
      "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
      "0                                              -15.0   \n",
      "1                                              -20.0   \n",
      "2                                              -27.0   \n",
      "3                                              -27.0   \n",
      "4                                              -30.0   \n",
      "5                                              -27.0   \n",
      "6                                              -34.0   \n",
      "7                                              -22.0   \n",
      "8                                              -19.0   \n",
      "9                                              -38.0   \n",
      "\n",
      "   parks_percent_change_from_baseline  \\\n",
      "0                               -38.0   \n",
      "1                               -54.0   \n",
      "2                               -59.0   \n",
      "3                               -58.0   \n",
      "4                               -58.0   \n",
      "5                               -51.0   \n",
      "6                               -69.0   \n",
      "7                               -55.0   \n",
      "8                               -54.0   \n",
      "9                               -69.0   \n",
      "\n",
      "   transit_stations_percent_change_from_baseline  \\\n",
      "0                                          -51.0   \n",
      "1                                          -51.0   \n",
      "2                                          -57.0   \n",
      "3                                          -59.0   \n",
      "4                                          -58.0   \n",
      "5                                          -57.0   \n",
      "6                                          -65.0   \n",
      "7                                          -58.0   \n",
      "8                                          -52.0   \n",
      "9                                          -60.0   \n",
      "\n",
      "   workplaces_percent_change_from_baseline  \\\n",
      "0                                    -51.0   \n",
      "1                                    -41.0   \n",
      "2                                    -43.0   \n",
      "3                                    -54.0   \n",
      "4                                    -54.0   \n",
      "5                                    -55.0   \n",
      "6                                    -57.0   \n",
      "7                                    -57.0   \n",
      "8                                    -43.0   \n",
      "9                                    -46.0   \n",
      "\n",
      "   residential_percent_change_from_baseline  ave_new7_10after  \n",
      "0                                      25.0              1.00  \n",
      "1                                      20.0              0.00  \n",
      "2                                      17.0              0.00  \n",
      "3                                      25.0              0.00  \n",
      "4                                      26.0              1.00  \n",
      "5                                      26.0              1.00  \n",
      "6                                      29.0              1.00  \n",
      "7                                      29.0              1.25  \n",
      "8                                      20.0              0.75  \n",
      "9                                      18.0              0.75  \n"
     ]
    }
   ],
   "source": [
    "print(LA_daily.head(10))\n",
    "print(LA_daily_predict.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_daily.py\n",
    "\"\"\"    super parameter     \"\"\"\n",
    "day_input = 6                      # how many days' feature we use to predict\n",
    "timelagging = 6                     # the length of latent window of Social Distancing data & Mobility data\n",
    "average_num = 4                     # how many days does the average cases get from\n",
    "### change the feature numbers  ###\n",
    "feature_num = 14+2*(day_input-1)    # the number of feature that one input contains\n",
    "### -------------------------  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_daily.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from parameter_daily import day_input, average_num, feature_num, timelagging\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, input, output):\n",
    "        super(Mydataset, self).__init__()\n",
    "        self.input = input\n",
    "        self.lable = output\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index], self.lable[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "\n",
    "def dataset_generate_daily():\n",
    "    \"\"\"    read data in and clean!     \"\"\"\n",
    "\n",
    "    ### change the input datset name ###\n",
    "#     filename = \"LA_daily.csv\"\n",
    "    ### ---------------------------- ###\n",
    "    zipcode_daily = LA_daily\n",
    "#     pd.read_csv(filename, encoding=\"ISO-8859-1\", dtype={'ZIP': str, 'date': str})\n",
    "    zip = zipcode_daily['ZIP']  # 'ZIP' column\n",
    "    date = zipcode_daily['date']  # we have to preserve the date\n",
    "    del zipcode_daily['ZIP']  # delete the non-numeric columns\n",
    "    del zipcode_daily['date']\n",
    "    zipcode_daily = pd.DataFrame(zipcode_daily, dtype=float)  # change the type from 'int' to 'float'\n",
    "    zipcode_daily['ZIP'] = zip  # add the 'ZIP' column again\n",
    "\n",
    "    # key: 'zip code', value: feature that belong to the 'zip code'\n",
    "    data_dict = {}\n",
    "    for i, zipcode in enumerate(zipcode_daily[:]['ZIP']):\n",
    "        if zipcode not in data_dict:\n",
    "            data_dict[zipcode] = []\n",
    "        feature = []\n",
    "        for f in zipcode_daily.iloc[i]:\n",
    "            feature.append(f)\n",
    "        data_dict[zipcode].append(feature)\n",
    "\n",
    "    data_x = []  # input\n",
    "    data_y = []  # lable\n",
    "    for key, values in data_dict.items():\n",
    "        l = len(values)\n",
    "        input_num = l - timelagging - average_num  # determine how many input here\n",
    "        feature = []\n",
    "        for i in range(input_num):  # one input point contains 6 days's data, that is day1~day6\n",
    "            first = True\n",
    "            for j in range(day_input):\n",
    "                if first:  # one input point contains all the feature of day1\n",
    "                    for k in values[i][:-4]:\n",
    "                        feature.append(k)\n",
    "                    first = False\n",
    "                else:  # for day2~day6, one input point only contains confirmed_cases & new_confirmed_cases\n",
    "                    feature.append(values[i + j][0])\n",
    "                    feature.append(values[i + j][1])\n",
    "            data_y.append(values[i][-4])  # output: average cases, that is ave_new7_10after\n",
    "            tmp = []\n",
    "            tmp.append(feature)\n",
    "            data_x.append(tmp)  # size: [1, feature_num]\n",
    "            feature = []\n",
    "    # split data to train and test, and split test to validation and test in the following.\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(data_x, data_y, test_size=0.3,\n",
    "                                                                        random_state=1)\n",
    "\n",
    "    train_x_ls = []  # Change the format for later processing\n",
    "    for j in train_x:\n",
    "        for i in j:\n",
    "            train_x_ls.append(i)\n",
    "    train_x_df = pd.DataFrame(train_x_ls)\n",
    "    train_y_df = pd.DataFrame(train_y)\n",
    "    train_x_mean = train_x_df.mean()  # train_x dataset mean\n",
    "    train_x_std = train_x_df.std()  # train_x dataset std\n",
    "    train_y_mean = train_y_df.mean()  # train_y dataset mean\n",
    "    train_y_std = train_y_df.std()  # train_y dataset std\n",
    "\n",
    "    for i in range(len(train_x)):       # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(train_x[i])):\n",
    "            for k in range(len(train_x[i][j])):\n",
    "                train_x[i][j][k] = (train_x[i][j][k] - train_x_mean[k]) / train_x_std[k]\n",
    "\n",
    "    for i in range(len(train_y)):       # using train_y mean and train_y std to normalize\n",
    "        train_y[i] = (train_y[i] - train_y_mean) / train_y_std\n",
    "\n",
    "    for i in range(len(test_x)):        # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(test_x[i])):\n",
    "            for k in range(len(test_x[i][j])):\n",
    "                test_x[i][j][k] = (test_x[i][j][k] - train_x_mean[k]) / train_x_std[k]\n",
    "\n",
    "    for i in range(len(test_y)):        # using train_y mean and train_y std to normalize\n",
    "        test_y[i] = (test_y[i] - train_y_mean) / train_y_std\n",
    "\n",
    "    # split test to validation and test\n",
    "    validation_x, test_x, validation_y, test_y = model_selection.train_test_split(test_x, test_y, test_size=0.5,\n",
    "                                                                                  random_state=1)\n",
    "    train_x = torch.tensor(train_x)\n",
    "    train_y = torch.tensor(train_y).reshape(-1, 1)\n",
    "    validation_x = torch.tensor(validation_x)\n",
    "    validation_y = torch.tensor(validation_y).reshape(-1, 1)\n",
    "    test_x = torch.tensor(test_x)\n",
    "    test_y = torch.tensor(test_y).reshape(-1, 1)\n",
    "\n",
    "    # define dataset\n",
    "    train_data = Mydataset(train_x, train_y)\n",
    "    trainloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "\n",
    "    return trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "           test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function.py\n",
    "import torch\n",
    "\n",
    "\n",
    "# scale the output value back to its original size and cal the loss\n",
    "def loss_cal(predict, lable, train_mean, train_std):\n",
    "    x = predict[:]\n",
    "    y = lable[:]\n",
    "    for i in range(len(predict)):\n",
    "        x[i][0] = x[i][0] * torch.tensor(train_std) + torch.tensor(train_mean)\n",
    "        y[i][0] = y[i][0] * torch.tensor(train_std) + torch.tensor(train_mean)\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    loss = loss_fun(x, y)\n",
    "    return loss, x, y\n",
    "\n",
    "\n",
    "# change the learning rate\n",
    "def adjust_learning_rate(optimizer, learning_r=None):\n",
    "    i = 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_r\n",
    "        if i == 0:\n",
    "            print(\"optimizer lr : {}\".format(param_group['lr']))\n",
    "            i += 1\n",
    "\n",
    "\n",
    "\"\"\"     define LSTM model   \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, feature_num):\n",
    "        super(Net, self).__init__()\n",
    "        # if batch_first=True, then input shape = (batch, seq, shape)\n",
    "        self.lstm = torch.nn.LSTM(input_size=feature_num, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(64 * 1, 32)\n",
    "        self.linear1 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(-1, 64 * 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_daily.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from dataset_daily import dataset_generate_daily\n",
    "#from function import loss_cal, adjust_learning_rate, Net\n",
    "#from parameter_daily import feature_num\n",
    "\n",
    "\n",
    "def train_daily():\n",
    "\n",
    "    trainloader, train_x, train_y, validation_x, validation_y, test_x, test_y, \\\n",
    "    train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate_daily()\n",
    "\n",
    "    \"\"\"         training start!         \"\"\"\n",
    "    # determine optimizer, loss_function and checkpoint path\n",
    "    model = Net(feature_num)\n",
    "    learning_r = 0.0002\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_r)\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    ### change the path name ###\n",
    "    path = 'checkpoint_0727.tar'\n",
    "    ### ------------------- ###\n",
    "\n",
    "    \"\"\" if you want train your model from a pre-trained model, uncomment the following code. \"\"\"\n",
    "    # checkpoint = torch.load(path)\n",
    "    # model.load_state_dict(checkpoint['net'])\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # validation_loss = checkpoint['best_validation_loss']\n",
    "    # learning_r = 6.400000000000004e-8\n",
    "\n",
    "    model.train()\n",
    "    # val_loss_info = [validation_loss]\n",
    "    val_loss_info = []      # preserve every epoch's train loss\n",
    "    train_loss_info = []    # preserve every epoch's validation loss\n",
    "    not_improve = 0\n",
    "    for epoch in range(1500):\n",
    "        for i, values in enumerate(trainloader):\n",
    "            input, lable = values\n",
    "            output = model(input)\n",
    "            loss = loss_fun(output, lable)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0 and epoch > 0:\n",
    "            train_loss = loss_fun(model(train_x),train_y).item()\n",
    "            vali_loss = loss_fun(model(validation_x), validation_y).item()\n",
    "            if len(val_loss_info) == 0 or vali_loss < min(val_loss_info):  # save the best model\n",
    "                not_improve = 0\n",
    "                state = {'net': model.state_dict(), 'optimizer': optimizer.state_dict(),'best_validation_loss': vali_loss}\n",
    "                torch.save(state, path)\n",
    "                print(\"Saved the model.\")\n",
    "            else:                           # if validation loss didn't decrease, reload the best model in next epoch.\n",
    "                checkpoint = torch.load(path)\n",
    "                model.load_state_dict(checkpoint['net'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                not_improve += 1\n",
    "                print(\"not_improve : {}\".format(not_improve))\n",
    "            if (not_improve+1) % 8 == 0:    # when validation loss doesn't decrease for 7 epochs, reduce the learning rate.\n",
    "                learning_r *= 0.2\n",
    "                adjust_learning_rate(optimizer, learning_r)\n",
    "            if (not_improve+1) % 25 == 0:   # early stopping\n",
    "                print(\"Training End......\")\n",
    "                break\n",
    "\n",
    "            print(\"epoch:{}, train_loss:{}, vali_loss: {}\".format(epoch, train_loss, vali_loss))\n",
    "            train_loss_info.append(train_loss)\n",
    "            val_loss_info.append(vali_loss)\n",
    "\n",
    "    return train_loss_info, val_loss_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_daily.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#from function import loss_cal, adjust_learning_rate, Net\n",
    "#from parameter_daily import feature_num\n",
    "import numpy as np\n",
    "\n",
    "def test_daily(path, test_x, test_y, train_mean, train_std):\n",
    "    \"\"\"     test start!     \"\"\"\n",
    "    # using the test dataset to test model\n",
    "    model = Net(feature_num)\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    model.eval()\n",
    "    predict = model(test_x)\n",
    "    real = test_y.clone()\n",
    "\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    # two losses, one is normalized scale, another is original scale\n",
    "    loss = loss_fun(predict, real)\n",
    "    loss_original_scale, pre, rea = loss_cal(predict, real, train_mean, train_std)\n",
    "    pre = np.array(pre.data)\n",
    "    rea = np.array(rea.data)\n",
    "    print(\"Test loss: \" + str(loss))\n",
    "    print(\"Test loss in original scale: \" + str(loss_original_scale))\n",
    "\n",
    "    # true output and predicted output\n",
    "    plt.figure(2)\n",
    "    plt.plot(list(rea), label=\"real\")\n",
    "    plt.plot(list(pre), label=\"pred\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # true output and predicted output\n",
    "    plt.figure(3)\n",
    "    min_val = min(rea)\n",
    "    max_val = max(rea)\n",
    "    plt.scatter(rea,pre)\n",
    "    plt.plot([min_val,max_val],[min_val,max_val],color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\"\"\"\n",
    "\n",
    "In this project, We created a LSTM model to predict covid-19 daily new_cases and weekly new cases in Los Angeles.\n",
    "\n",
    "If you find anything wrong with the code, please feel free to contact us.\n",
    "\n",
    "@University: Umich & ZJU\n",
    "@author: Wenxue Li, Zixian Ma, Xinyu Li\n",
    "@email: liwenxue@zju.edu.cn, 3170103467@zju.edu.cn\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from dataset_daily import dataset_generate_daily\n",
    "from dataset_weekly import dataset_generate\n",
    "from train_daily import train_daily\n",
    "from train_weekly import train_weekly\n",
    "from test_daily import test_daily\n",
    "from test_weekly import test_weekly\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='COVID-LSTM')\n",
    "parser.add_argument('--mode', default='train', type=str, help='choose train or test')\n",
    "parser.add_argument('--type', default='daily', type=str, help='daily or weekly')\n",
    "\n",
    "args = parser.parse_args(args=[]) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the model.\n",
      "epoch:10, train_loss:0.23581671714782715, vali_loss: 0.26640358567237854\n",
      "Saved the model.\n",
      "epoch:20, train_loss:0.2202320396900177, vali_loss: 0.25467345118522644\n",
      "Saved the model.\n",
      "epoch:30, train_loss:0.2083442360162735, vali_loss: 0.24657389521598816\n",
      "Saved the model.\n",
      "epoch:40, train_loss:0.1992214173078537, vali_loss: 0.2402394562959671\n",
      "Saved the model.\n",
      "epoch:50, train_loss:0.19169357419013977, vali_loss: 0.23641279339790344\n",
      "Saved the model.\n",
      "epoch:60, train_loss:0.1858120709657669, vali_loss: 0.23278628289699554\n",
      "Saved the model.\n",
      "epoch:70, train_loss:0.18032899498939514, vali_loss: 0.23030145466327667\n",
      "Saved the model.\n",
      "epoch:80, train_loss:0.17577402293682098, vali_loss: 0.2279222309589386\n",
      "Saved the model.\n",
      "epoch:90, train_loss:0.17148926854133606, vali_loss: 0.22641438245773315\n",
      "Saved the model.\n",
      "epoch:100, train_loss:0.16759809851646423, vali_loss: 0.224184051156044\n",
      "Saved the model.\n",
      "epoch:110, train_loss:0.1638946384191513, vali_loss: 0.22371232509613037\n",
      "not_improve : 1\n",
      "epoch:120, train_loss:0.1616460233926773, vali_loss: 0.22541405260562897\n",
      "not_improve : 2\n",
      "epoch:130, train_loss:0.1603151261806488, vali_loss: 0.22378034889698029\n",
      "not_improve : 3\n",
      "epoch:140, train_loss:0.16154073178768158, vali_loss: 0.22640080749988556\n",
      "Saved the model.\n",
      "epoch:150, train_loss:0.16159743070602417, vali_loss: 0.22278743982315063\n",
      "Saved the model.\n",
      "epoch:160, train_loss:0.15688757598400116, vali_loss: 0.22272811830043793\n",
      "Saved the model.\n",
      "epoch:170, train_loss:0.15397444367408752, vali_loss: 0.22195851802825928\n",
      "not_improve : 1\n",
      "epoch:180, train_loss:0.15171468257904053, vali_loss: 0.22504779696464539\n",
      "Saved the model.\n",
      "epoch:190, train_loss:0.15079782903194427, vali_loss: 0.22195182740688324\n",
      "not_improve : 1\n",
      "epoch:200, train_loss:0.1478603035211563, vali_loss: 0.22304803133010864\n",
      "not_improve : 2\n",
      "epoch:210, train_loss:0.14788417518138885, vali_loss: 0.22219862043857574\n",
      "not_improve : 3\n",
      "epoch:220, train_loss:0.15060573816299438, vali_loss: 0.22222363948822021\n",
      "not_improve : 4\n",
      "epoch:230, train_loss:0.1485051065683365, vali_loss: 0.2228441685438156\n",
      "not_improve : 5\n",
      "epoch:240, train_loss:0.14857669174671173, vali_loss: 0.22396419942378998\n",
      "not_improve : 6\n",
      "epoch:250, train_loss:0.14833486080169678, vali_loss: 0.2252245992422104\n",
      "Saved the model.\n",
      "epoch:260, train_loss:0.14954540133476257, vali_loss: 0.22158554196357727\n",
      "not_improve : 1\n",
      "epoch:270, train_loss:0.14545243978500366, vali_loss: 0.222828671336174\n",
      "not_improve : 2\n",
      "epoch:280, train_loss:0.1451578289270401, vali_loss: 0.2224140465259552\n",
      "not_improve : 3\n",
      "epoch:290, train_loss:0.14622527360916138, vali_loss: 0.22221679985523224\n",
      "not_improve : 4\n",
      "epoch:300, train_loss:0.14515048265457153, vali_loss: 0.22408244013786316\n",
      "not_improve : 5\n",
      "epoch:310, train_loss:0.14534974098205566, vali_loss: 0.22287364304065704\n",
      "not_improve : 6\n",
      "epoch:320, train_loss:0.1457705944776535, vali_loss: 0.2254307121038437\n",
      "not_improve : 7\n",
      "optimizer lr : 4e-05\n",
      "epoch:330, train_loss:0.14841368794441223, vali_loss: 0.22975945472717285\n",
      "not_improve : 8\n",
      "epoch:340, train_loss:0.14710766077041626, vali_loss: 0.2222822904586792\n",
      "not_improve : 9\n",
      "epoch:350, train_loss:0.14517942070960999, vali_loss: 0.22369574010372162\n",
      "not_improve : 10\n",
      "epoch:360, train_loss:0.14612478017807007, vali_loss: 0.2264728546142578\n",
      "not_improve : 11\n",
      "epoch:370, train_loss:0.14662691950798035, vali_loss: 0.2268313765525818\n",
      "not_improve : 12\n",
      "epoch:380, train_loss:0.14533117413520813, vali_loss: 0.2236301600933075\n",
      "not_improve : 13\n",
      "epoch:390, train_loss:0.14536897838115692, vali_loss: 0.22353595495224\n",
      "not_improve : 14\n",
      "epoch:400, train_loss:0.14547452330589294, vali_loss: 0.22238627076148987\n",
      "not_improve : 15\n",
      "optimizer lr : 8.000000000000001e-06\n",
      "epoch:410, train_loss:0.14593657851219177, vali_loss: 0.22565601766109467\n",
      "not_improve : 16\n",
      "epoch:420, train_loss:0.14751359820365906, vali_loss: 0.22239969670772552\n",
      "not_improve : 17\n",
      "epoch:430, train_loss:0.1458723098039627, vali_loss: 0.223567396402359\n",
      "not_improve : 18\n",
      "epoch:440, train_loss:0.14700450003147125, vali_loss: 0.22801797091960907\n",
      "not_improve : 19\n",
      "epoch:450, train_loss:0.14566993713378906, vali_loss: 0.2240494340658188\n",
      "not_improve : 20\n",
      "epoch:460, train_loss:0.1456144154071808, vali_loss: 0.22163750231266022\n",
      "not_improve : 21\n",
      "epoch:470, train_loss:0.14524151384830475, vali_loss: 0.22376957535743713\n",
      "not_improve : 22\n",
      "epoch:480, train_loss:0.14509277045726776, vali_loss: 0.22343909740447998\n",
      "not_improve : 23\n",
      "optimizer lr : 1.6000000000000004e-06\n",
      "epoch:490, train_loss:0.14608125388622284, vali_loss: 0.22308653593063354\n",
      "not_improve : 24\n",
      "Training End......\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU5fX48c/JZF+AEMIaCGGXNWDYxQ0XECzUFQVFq6Vo3aUVW21dW9taq35/KFrXKhUQXEBRVAQ3ZAnIviWsCVtCEkIWss7z++MZaIgJmcAkk8yc9+s1r8ncuffOuUnm3Oee+9znijEGpZRS/iPA2wEopZSqX5r4lVLKz2jiV0opP6OJXyml/IwmfqWU8jOB3g6gKi1atDAdO3b0dhhKKdVorFmz5ogxJtadeRtk4u/YsSPJycneDkMppRoNEdnr7rxa6lFKKT+jiV8ppfyMJn6llPIzDbLGr5TyPaWlpaSnp1NUVOTtUBq10NBQ4uLiCAoKOuN1aOJXStWL9PR0oqKi6NixIyLi7XAaJWMMWVlZpKenk5CQcMbr0VKPUqpeFBUVERMTo0n/LIgIMTExZ33UpIlfKVVvNOmfPU/8Dn0n8Zcehx9ehF3LvB2JUko1aL6T+B3BsPz/IPkNb0eilFINmu8k/gAHnHMl7PgCSgq8HY1SqoE5evQoL730Uq2Xu+KKKzh69Gitl7vllluYN29erZerD76T+AF6jYey45DyhbcjUUo1MNUl/vLy8tMut2jRIpo1a1ZXYXmFb3XnjB8OEbGw+SPo9UtvR6OUqsbjCzez5cAxj66zZ9sm/PnKXtW+P336dHbu3EliYiJBQUFERkbSpk0b1q1bx5YtWxg/fjxpaWkUFRVx7733MmXKFOB/Y4fl5+czevRozjvvPJYvX067du34+OOPCQsLqzG2JUuWMG3aNMrKyhg4cCAvv/wyISEhTJ8+nQULFhAYGMhll13Gs88+y/vvv8/jjz+Ow+GgadOmfPvttx77HZ3gW4n/RLln/WwoKYTgcG9HpJRqIJ555hk2bdrEunXrWLZsGWPGjGHTpk0n+8O/8cYbNG/enOPHjzNw4ECuvvpqYmJiTllHSkoK7733Hv/+97+57rrrmD9/PpMmTTrt5xYVFXHLLbewZMkSunXrxs0338zLL7/MzTffzIcffsi2bdsQkZPlpCeeeILFixfTrl27MyoxucO3Ej9Az/H2BG/KF7b0o5RqcE7XMq8vgwYNOuUiqBdffJEPP/wQgLS0NFJSUn6W+BMSEkhMTATg3HPPZc+ePTV+zvbt20lISKBbt24ATJ48mRkzZnDXXXcRGhrK7bffzpgxYxg7diwAw4cP55ZbbuG6667jqquu8sSm/oxv1fjBlnvCW8CWj7wdiVKqAYuIiDj587Jly/jqq6/48ccfWb9+Pf3796/yIqmQkJCTPzscDsrKymr8HGNMldMDAwNZtWoVV199NR999BGjRo0CYObMmTz11FOkpaWRmJhIVlZWbTetRr7X4ncE2nLPhjla7lFKnRQVFUVeXl6V7+Xm5hIdHU14eDjbtm1jxYoVHvvcHj16sGfPHlJTU+nSpQvvvPMOF1xwAfn5+RQWFnLFFVcwZMgQunTpAsDOnTsZPHgwgwcPZuHChaSlpf3syONsuZX4RWQU8ALgAF4zxjxT6f2JwEOul/nAHcaY9a73mgGvAb0BA/zKGPOjZ8KvRq/xsOZNSP0Seo6r049SSjUOMTExDB8+nN69exMWFkarVq1Ovjdq1ChmzpxJ37596d69O0OGDPHY54aGhvLmm29y7bXXnjy5O3XqVLKzsxk3bhxFRUUYY/jXv/4FwO9+9ztSUlIwxjBy5Ej69evnsVhOkOoOQ07OIOIAdgCXAunAauAGY8yWCvMMA7YaY3JEZDTwmDFmsOu9t4HvjDGviUgwEG6MOe0Zi6SkJHNWd+AqL4N/doOEC+DaN898PUopj9m6dSvnnHOOt8PwCVX9LkVkjTEmyZ3l3anxDwJSjTG7jDElwGzglGa0MWa5MSbH9XIFEOcKpAlwPvC6a76SmpK+R5wo9+xYbIdyUEopdZI7ib8dkFbhdbprWnVuAz5z/dwJyATeFJGfROQ1EYmoaiERmSIiySKSnJmZ6UZYNeg5DkoLIOXLs1+XUkpV47e//S2JiYmnPN58s2FXGtyp8Vc1FFyV9SERuQib+M+rsP4BwN3GmJUi8gIwHXj0Zys05lXgVbClHjfiOr2O50NYc9u7p+cvznp1SilVlRkzZng7hFpzp8WfDrSv8DoOOFB5JhHpiz2JO84Yk1Vh2XRjzErX63nYHUHdcwTCOWO13KOUUpW4k/hXA11FJMF1cnYCsKDiDCLSAfgAuMkYs+PEdGPMISBNRLq7Jo0EtlBfeo6HknxIXVJvH6mUUg1djaUeY0yZiNwFLMZ253zDGLNZRKa63p8J/AmIAV5y3SSgrMLZ5buBWa6dxi7gVs9vRjUSzoewaFvuOWdsvX2sUko1ZG714zfGLAIWVZo2s8LPtwO3V7PsOsCtLkYe5wiCHmPtoG2lRRAU6pUwlFKqIfG9IRsq6zUeSvJgp5Z7lFLui4yMrPa9PXv20Lt373qMxrN8P/EnXGDLPZt17B6llAJfHKunMkcQnPML2Pg+FByBiBbejkgp9dl0OLTRs+ts3QdGP1Pt2w899BDx8fHceeedADz22GOICN9++y05OTmUlpby1FNPMW5c7YZ5KSoq4o477iA5OZnAwECee+45LrroIjZv3sytt95KSUkJTqeT+fPn07ZtW6677jrS09MpLy/n0Ucf5frrrz+rzT4Tvt/iBxhyp+3SueJlb0eilPKSCRMmMGfOnJOv586dy6233sqHH37I2rVrWbp0KQ8++GC1o2lW50Q//o0bN/Lee+8xefJkioqKmDlzJvfeey/r1q0jOTmZuLg4Pv/8c9q2bcv69evZtGnTyRE565vvt/gBWvawQzis+jcMvwdCm3o7IqX822la5nWlf//+ZGRkcODAATIzM4mOjqZNmzbcf//9fPvttwQEBLB//34OHz5M69at3V7v999/z9133w3YkTjj4+PZsWMHQ4cO5emnnyY9PZ2rrrqKrl270qdPH6ZNm8ZDDz3E2LFjGTFiRF1t7mn5R4sf4PxpUJxrk79Syi9dc801zJs3jzlz5jBhwgRmzZpFZmYma9asYd26dbRq1arKcfhPp7ojhBtvvJEFCxYQFhbG5Zdfztdff023bt1Ys2YNffr04eGHH+aJJ57wxGbVmv8k/jb9oMulsOIlKCnwdjRKKS+YMGECs2fPZt68eVxzzTXk5ubSsmVLgoKCWLp0KXv37q31Os8//3xmzZoFwI4dO9i3bx/du3dn165ddOrUiXvuuYdf/OIXbNiwgQMHDhAeHs6kSZOYNm0aa9eu9fQmusV/Ej/YVn9hFqx529uRKKW8oFevXuTl5dGuXTvatGnDxIkTSU5OJikpiVmzZtGjR49ar/POO++kvLycPn36cP311/PWW28REhLCnDlz6N27N4mJiWzbto2bb76ZjRs3MmjQIBITE3n66ad55JFH6mAra1bjePzecNbj8Z/Om2Mgeyfcux4CQ2qeXynlEToev+fUx3j8vuX8ByHvIKz7r7cjUUopr/CPXj0VdboI2g6AH56H/jfZUTyVUqoKGzdu5KabbjplWkhICCtXrqxmicbB/7KeiK31z74RNs2HfvV/8YRS/soYg2sgx0ahT58+rFu3ztthnMIT5Xn/K/UAdBsNLXvC98+B0+ntaJTyC6GhoWRlZXkkcfkrYwxZWVmEhp7dgJP+1+IHCAiAEQ/C/Ntg2yd6hy6l6kFcXBzp6el45Naqfiw0NJS4uLizWod/Jn6AXr+EpU/Dd/+0V/U2osNPpRqjoKAgEhISvB2Gwl9LPQABDjjvATi4DrYuqHl+pZTyEf6b+AH63QCt+sDnD0NxvrejUUqpeuHfid8RCGOfg2P7YdlfvR2NUkrVC/9O/ADtB8GAyXbI5kObvB2NUkrVOU38AJc8BmHN4JP7tXunUsrnaeIHCG8Olz0F6avgp3e8HY1SStUpTfwn9LsB4ofDV3+2t2hUSikfpYn/BBEY808ozoMv/+TtaJRSqs64lfhFZJSIbBeRVBGZXsX7E0Vkg+uxXET6VXrfISI/icgnngq8TrQ8B4bdDetmwd7l3o5GKaXqRI2JX0QcwAxgNNATuEFEelaabTdwgTGmL/Ak8Gql9+8Ftp59uPXg/N9D0w7wyQNQVuLtaJRSyuPcafEPAlKNMbuMMSXAbGBcxRmMMcuNMTmulyuAkwNJiEgcMAZ4zTMh17HgcLji75C5FZY+BTqglFLKx7iT+NsBaRVep7umVec24LMKr58Hfg+ctp+kiEwRkWQRSfb6IE7dR9u+/T+8AF9r8ldK+RZ3BmmravSyKjOhiFyETfznuV6PBTKMMWtE5MLTfYgx5lVcJaKkpCTvZ9qxzwMGvnsWnKVwyeM6kJtSyie4k/jTgfYVXscBByrPJCJ9seWc0caYLNfk4cAvROQKIBRoIiLvGmMmnV3Y9SAgAMa+AAFBtuXvLLd9/TX5K6UaOXcS/2qgq4gkAPuBCcCNFWcQkQ7AB8BNxpgdJ6YbYx4GHnbNcyEwrVEk/RMCAmwXz4BA+PH/gbMMRj2jyV8p1ajVmPiNMWUichewGHAAbxhjNovIVNf7M4E/ATHAS67bqpW5e7f3Bk8ERv/NDuO84iUoL4UrnrU7BaWUaoSkId4GLSkpySQnJ3s7jFMZYy/sWv6iPfE79l92Z6CUUg2AiKxxt8HtM83WotJyfvf+ej5et79uPkAELn3C3rJx7dsw/3bt56+UapR85taLIYEBLN+ZRUFJGeMST9fb9CyIwMg/QUgUfPWYHd7huv/Yvv9KKdVI+EyLX0QY3Kk5K3ZlU+flq/PuhytfgNSv4N2r4PjRuv08pZTyIJ9J/ABDOsWQXVBCSkY93Ebx3FvgmjcgPRneHgv5GXX/mUop5QE+lfiHdooBYMWurBrm9JDeV8ENs+FIKrwxCo7uq5/PVUqps+BTiT8uOox2zcLqL/EDdL0Ebv7IjuH/xigd1VMp1eD5VOKv1zp/RR2GwK2f2u6db46GhfdBUW79fb5SStWCTyV+qOc6f0Wt+8CdK2DoXba754zBsHVh/caglFJu8LnEX+91/oqCI+Dyp+H2JRDeAuZMso9jB+s/FqWUqobPJf646DDaNg31TuI/od0AmLIURv4ZUr60rf/Vr9mB3pRSyst8LvGLCEM6xbCyvuv8lTmCYMQDcMdyaNsPPn0QXr8UDqzzXkxKARRmw7xfwb4V3o5EeYnPJX6wdf6sghJS67vOX5WYznDzArjq33A0Df59ESz6vZ78Vd5RehzeuwE2zYdP7tejUD/ls4kfvFTnr4oI9L0O7loNSbfBqlfh/w2EjfP07l6q/pSX2ZZ+2krodyNkbIFNH3g7KuUFPpn42zc/UefP9nYopwprBmOetfX/Jm1h/m22++fGeVBa5O3olC8zBhY9CNsXwei/w7gZ0Ko3LPuLHWpcwfbP4MUBsOsbb0dS53wy8Z+o86/YleXdOn912va3PX/GPAfH9tsdwD+72xLQoY3ejk75om/+BmvesqPLDp5i7ydx8SOQvQvW/bduPtOYxnNEm74G3r/V/j7emwB7fvB2RHXKZ8fjn7s6jd/P38CX959P11ZRHoqsDjidsPsb+Okd2++/vATaJMKAmyFxIgSF1n9MhdmQmwZt+tX/ZyvPS34TPrnP/j+Nm/G/O8gZA69dAnkH4e61Z/a/5nTa8wWZW+14VfkZUHDiORNadLMj2MZ09uw2eVL2bvt7CI6AG96D92+B3P1w0wf24sxGwi/H46+swdX5qxMQAJ0vsgO+PbjdHoY7y+HTB2DGQNj8Uf22mrYssOcfXrkAVv27/j5X1Y2tn9j/pa6X2RFlK942VARGPmqPOte8Wft1HzsA74yHD26H75+3XZfzDkJ4DHS6EAb/xq773xfDrmUe2qAqlB4/82ULs2HWNWDKYdJ8aNULJi+EJm3g3WsgbbXn4mxAfDbxN9g6/+mEN7dflqnfwc0fQ3AUvD8Z3hoDB9fXfn3lZXbH8cEU+Ond039BCrNh3m0w9yZ7/qHLJbBoGnzzj7rb8ZQU1M1660JZsR2G+0iKtyNx3+YPbRmx7QC49i3bxbiyThdCxxHw3T+huBa94LYuhJeHQfpqu0N59AhM227/dyfNh/EvwWVPwa+XQlQbeOcqWPmKZ/+Xysvgs+nwl3bw44zar7u0CGbfaAdXnPBfaNHVTo9qbZN/RAs77Pr+tZ6LuYHw2cTf4Ov8pyNiv5C/+dbe4jFzm22BL7jbveGfj+fADy/Ci4l2x7HtU/j4t/DcOfDFo5Cz59T5t38GLw2BLR/BhX+AX39tRx3tOwGWPgWL/2gP6T3FGPjuOfhrHCy4xybVhqikALZ8bHeIf+8M714NM0dAylfejuz08jNgzk22ZNHyHLhxri1jVGfkn2xZZuXMmtddUmD/ZnMmQbN4+z967i3V34O6eQLc9oU94vjs97DwXs/cua7omK3Fr3zZJuzFf6jdup1O+Ggq7PsRfjkT4oed+n6Ttjb5hzWzRzVn0vBqwHy2xg+NqM5fk+NH4dt/2C9mYBh0HwVN20OzDtCsPTTtAE3j7GH1ypn2ZF1poW3JDbkDurlGDV39b3vob5zQ7XL7hd2yANb/F1r2gl++fGpd3+mExQ/bdSZOhCtfBMdZ3rStOM/uhLZ8bE9yH/gJ2iXB9e/YL5u3FWbblv3WBTbBlx2HsObQY4z9nX3zN8jYBle9aoflri95h2DDHJtsu4y0d4GrzBjYMBc+fwhKCuHC6TDsHvf+Zv+93ibBezfYZFeVAz/ZW45m7YTh98JFf4TAYPfidzptI+K7f0KHYfbvHdHCvWUry9kD/50AWSlwxT9gwC3/W3fHEfacQnjz06/ji0ft/bMvfcJuS7WftRfevAJKC2DiPIhzq4RuOcvr9b7ctanx+3Ti35dVyPn/WMqT43px09COZx+Ytx1Jha+ftIeex/bbumRljmDocy0Mngpt+v78/dz9tnfHmrfsSThx2CuMz/991V9iY+Cbv9tufz3GwtWvn/kJ56yd9tD6yA645HEYdrctGXx0BwSFw3Vv/7zlVdecTji0wdanU76A/cl2xxjZGs65Enr+wiaqE8nz+FHb0ty3wpY4zp1ct/Hl7IUfXrClunLXkZEj2B4Rdr/CPqJa2Xr7J/fDjs8hbqA9iRvb3f3PObgBXhkBI6bZuv8J5WWwaymsn2131hGxcNUrkHD+mW3Pxnl2xx8cCdHx4AixJShHsH0EBkPrvrax0vKcU89JgP29z74RnGU2wXe68H/vrZ8DC+6CJu3sUU5st1OXLS+FvT/YaxfWvg0Db4crnv35Z1SWvQveuhLyDsDAX9veUKFNqp//2AFY+hfbAAsMtTu4iFjXI6bCzy0h0vWIaAlh0dUfOblBE7+LMYbhz3xN/w7RzJg4wAORNSDOcnsi7Wia7YFzdB8EBELijfYfqSZlJbZl26wDtO5d8/wrX7GH6vHnQc9xtiUT4LCfeeLRpK0dpbSq1uj2z+25hgAHXPvmqV/YjG2uWuteuPyvMOjXp34Zc9NtrKlf2dZem342ucUNhNge7reqjIH8w3bHk7ndtmBTvrQ7QLC18K6XQddL7c/VfQlLCu25kNSv4NInYfg9VX9WxlbY+TUEhtg6d5M2NilFxNYcc+YO+P4524KXAPt3HXaPjX/bp7DtE/v7QqDdufbcQ3mJLdsM/s2ZtTTfvxV2LIZ719uGxYY5NlEXZEBoM9uguOgPNbema7J/LfzwvD2nUF5iE3J5iX2UFEDObjtf0w72KKvb5bYlv+UjW+5s2h5unPO/mnxFaavs/1JZif0/a9vf/o13fAapS6D4mN3Z9L0Oxj7v/hFsUS4sedKOuRXVGkY9Y78HFf9Pi47ZnfSPM+yOqf9Eu4MryKzwyLLPziqunQgIhOad7IWeZ0ATfwUPzFnHNzsySX7kEqSmPbs6vfVz7Bev/HQ1eYGYLtA20XZLbdPPtrKW/dW25CbMsjubyopy4YPf2C9ovxuh77X2i5q6xHYVBJs0W3S19dbjOXZacKQdFK/tAPuzcQLGPhvXc94hOLLdJvyKQ2WENrNlk66XQeeREBnr/u+irAQ+nGJPoI54EC5+1H7egbX2KGbrQsjeWc2vyGGTR3iM3UkGR9oafEikPaGfu8+W5AJDIelWO9R303anrsMYe+Xttk/tOZrwGBj9t7PrNnkkBWYMsjEV5UJAkE26/SbY31FgyJmvuzaOHbBHXzsW295ApYW2xFl23L1SztF9thR04v/GOG2Lutvl0H20bXSc7pzH6aSvgU/utdfbdL3MlpqatLNH0MuegcIj0Psae9QU3bHqdRgDRUchP9PuyAsy7M8FGfa9S/58RqFp4q/AZ+r8DUVJoe0d5Cz7+SNnjx2E7uB6OLjOthpP6HeDPVEdFFb9up1O+PbvdicB9tA/fpjtYdTlEtu6F7FfjuxdtkdJ+mp73+NDG6sofYmdP7yFLXu06OZ67gotutsjlLNpDDjLbXll7duQcIFNnHkHbMst4XxbKuo22rbY8w7Y4bnzDtjEduwgHM+2rd6SPNdzvn12BMHA22DInWdeBz9TS560tf7eV0OvX5596/5slRbBnu8hZbE913L+tKp7J1VWnGfPx5w4J9am/1mVUU5RXgarXoGvn3aVBVvao6/48+CyJ+wRmBd4PPGLyCjgBcABvGaMeabS+xOBh1wv84E7jDHrRaQ98B+gNeAEXjXGvFDT53ky8Z+s84/vzU1D4j2yTuWm/Mz/9YboMtL9JJueDIVZ0PE891tmznK7QxCxiba+ju6MgSVP2BZf/DBXsr/c1muVb8tNhy8esc8jptm/uxerCh5N/CLiAHYAlwLpwGrgBmPMlgrzDAO2GmNyRGQ08JgxZrCItAHaGGPWikgUsAYYX3HZqngy8Z+s88dHM+NGH6vzK6WUi6ev3B0EpBpjdhljSoDZwLiKMxhjlhtjXEVXVgBxrukHjTFrXT/nAVuBSsXKunWiP//y1COUlXuwL7pSSjVS7iT+dkBahdfpnD553wZ8VnmiiHQE+gMrq1pIRKaISLKIJGdmZroRlvsu7dmKnMJSVu1uRFfxKqVUHXEn8VdVtKqyPiQiF2ET/0OVpkcC84H7jDHHqlrWGPOqMSbJGJMUG1uL3hVuuLB7S8KCHHy26ZBH16uUUo2RO4k/HWhf4XUccKDyTCLSF3gNGGeMyaowPQib9GcZY7xy14ewYAcX9Yjl882HKHc2vF5MSilVn9xJ/KuBriKSICLBwARgQcUZRKQD8AFwkzFmR4XpAryOPfH7nOfCrr3RvduQmVfMmr05Nc+slFI+rMbEb4wpA+4CFmNPzs41xmwWkakiMtU125+AGOAlEVknIie65AwHbgIudk1fJyJXeH4zanZRj5aEBAawaONBb3y8Uko1GD5/AVdFU/6TzIb0XJZPv5iAAL2KVynlO/RGLNUY3ac1h44VsS79qLdDUUopr/GrxD/ynFYEOYTPtNyjlPJjfpX4m4QGMaJrLIs2Hmp8N2dRSikP8avEDzC6d2v2Hz3Oxv25Nc+slFI+yO8S/6U9WxEYIHoxl1LKb/ld4m8WHszQzjF8tvGglnuUUn7J7xI/wBV92rAnq5CtB/O8HYpSStU7v0z8l/VsRYDAZ5u0d49Syv/4ZeKPiQxhSKcYrfMrpfySXyZ+gNF92pCakU/KYS33KKX8i98m/st7tUIEFm3UVr9Syr/4beJvGRXKwPjmWudXSvkdv038YMfu2XYoj9SMfG+HopRS9cavE//Yvm0Jcgjvrtjr7VCUUqre+HXij40KYUyfNsxbk05+cZm3w1FKqXrh14kf4JbhCeQXl/HB2nRvh6KUUvXC7xN/Yvtm9GvfjLeW78Gp9+NVSvkBv0/8ALcMi2dXZgHfpx7xdihKKVXnNPFjx+5pERnM28v3eDsUpZSqc5r4gZBABzcO6sDX2zPYm1Xg7XCUUqpOaeJ3mTgkHocI//lRu3YqpXybJn6XVk1CGd2nDXOT0yjQrp1KKR+mib+CW4bFk1dUxoc/7fd2KEopVWfcSvwiMkpEtotIqohMr+L9iSKywfVYLiL93F22IRnQIZre7Zrw9vI9encupZTPqjHxi4gDmAGMBnoCN4hIz0qz7QYuMMb0BZ4EXq3Fsg2GiDB5aEdSMvJZvjPL2+EopVSdcKfFPwhINcbsMsaUALOBcRVnMMYsN8bkuF6uAOLcXbahubJfW5pHBPOWdu1USvkodxJ/OyCtwut017Tq3AZ8VttlRWSKiCSLSHJmZqYbYdWN0CAHEwa2Z8nWw6RlF3otDqWUqivuJH6pYlqVBXARuQib+B+q7bLGmFeNMUnGmKTY2Fg3wqo7k4bEIyK8+cMer8ahlFJ1wZ3Enw60r/A6DjhQeSYR6Qu8BowzxmTVZtmGpm2zMMYntmPWyr0cyi3ydjhKKeVR7iT+1UBXEUkQkWBgArCg4gwi0gH4ALjJGLOjNss2VPeO7Eq50zBjaaq3Q1FKKY+qMfEbY8qAu4DFwFZgrjFms4hMFZGprtn+BMQAL4nIOhFJPt2ydbAdHtchJpzrB7Zn9up9WutXSvkUaYj91ZOSkkxycrK3w+Bg7nEu+McyxvVryz+u7VfzAkop5SUissYYk+TOvHrl7mm0aRrGpMHxzF+bzq5MvS+vUso3aOKvwZ0XdSYk0MHzX6V4OxSllPIITfw1aBEZwq3DO7JwwwG2HTrm7XCUUuqsaeJ3w2/O70xkSCDPfbGj5pmVUqqB08TvhqbhQfx6RCe+2HKYDelHvR2OUkqdFU38brp1eEeiw4N4Vlv9SqlGThO/m6JCg7jjws58uyOTVbuzvR2OUkqdMU38tXDTkI7ERoXwj8XbdLx+pVSjpYm/FsKCHTx4aTdW78nhvVVpNS+glFINkCb+Wrp+YHuGdY7hL4u2sv/ocW+Ho5RStaaJv5ZEhL9d3RenMUyfv0FLPkqpRkcT/xlo3zyc6aN78F3KEd5PTs75aqEAABXWSURBVPd2OEopVSua+M/QpMHxDE5ozpOfbOFgrpZ8lFKNhyb+MxQQIPz9mr6UOQ1/+GCjlnyUUo2GJv6zEB8Twe8u787S7Zl8sHa/t8NRSim3aOI/S7cM68jAjtE8vnAzh4/pbRqVUg2fJv6zZEs+/Sguc/LHD7Xko5Rq+DTxe0BCiwimXdadr7ZmMG+N9vJRSjVsmvg95FfnJTAooTmPLdjM3qwCb4ejlFLV0sTvIY4A4V/XJxIQINw3Zx1l5U5vh6SUUlXSxO9B7ZqF8Zdf9uGnfUf5v69TvR2OUkpVSRO/h13Zry1X9W/H/32dwpq9OnyzUqrh0cRfBx4f14t20WHcN2cdeUWl3g5HKaVOoYm/DkSFBvH89YnszznOnxds9nY4Sil1CrcSv4iMEpHtIpIqItOreL+HiPwoIsUiMq3Se/eLyGYR2SQi74lIqKeCb8jOjW/OXRd35YO1+1m4/oC3w1FKqZNqTPwi4gBmAKOBnsANItKz0mzZwD3As5WWbeeanmSM6Q04gAkeiLtRuOfiLvTv0Iw/friRAzp2v1KqgXCnxT8ISDXG7DLGlACzgXEVZzDGZBhjVgNVFbQDgTARCQTCAb9p/gY6Anj++kTKnYY73l3D8ZJyb4eklFJuJf52QMX7DKa7ptXIGLMfexSwDzgI5BpjvqhqXhGZIiLJIpKcmZnpzuobhfiYCP51fSIb9ufywNx1OJ06pINSyrvcSfxSxTS3speIRGOPDhKAtkCEiEyqal5jzKvGmCRjTFJsbKw7q280LuvVmj9ecQ6fbTrE3xdv93Y4Sik/507iTwfaV3gdh/vlmkuA3caYTGNMKfABMKx2IfqG285LYOLgDsz8ZiezV+3zdjhKKT/mTuJfDXQVkQQRCcaenF3g5vr3AUNEJFxEBBgJbD2zUBs3EeHxX/Ti/G6xPPLRJn5IPeLtkJRSfqrGxG+MKQPuAhZjk/ZcY8xmEZkqIlMBRKS1iKQDDwCPiEi6iDQxxqwE5gFrgY2uz3u1jralwQt0BDDjxv50jo1k6rtrSDmc5+2QlFJ+SBri+PFJSUkmOTnZ22HUmfScQsbPWE5YcAAf3jmcFpEh3g5JKdXIicgaY0ySO/PqlbteEBcdzmuTk8jMK+bX/0nWbp5KqXqlid9LEts34/nr+7Mu7Si//e9aSnUYZ6VUPdHE70WjerfmyXG9+XpbBg9/oLdtVErVj0BvB+DvJg2J50h+Mc9/lUKLyBCmj+7h7ZCUUj5OE38DcO/IrhzJL2bmNztpERnM7SM6eTskpZQP08TfANg+/r3JLijhqU+30iIyhPH93RoVQymlak1r/A3EiXv2Du0Uw7T317Nse4a3Q1JK+ShN/A1ISKCDV24+l26torjj3bUk79FbNyqlPE8TfwPTJDSIt341kDZNQ5n8xipN/kopj9PE3wC1jArlvSlDaNVEk79SyvM08TdQrZpo8ldK1Q1N/A2YJn+lVF3QxN/AafJXSnmaJv5GoHLyX63JXyl1FjTxNxIVk//Nr6/i+xS9kYtS6sxo4m9EWjUJZfZvhtCheTi/ems1X2057O2QlFKNkCb+RqZlVCizpwyhR5sopr67hoXr3b39sVJKWZr4G6HoiGBm3T6YAR2iuWf2T8xdnebtkJRSjYgm/kYqKjSIt381iPO6tOD38zfw5g+7vR2SUqqR0MTfiIUFO3htchKX9WzF4wu38PxXOyjTO3kppWqgib+RCwl0MGPiAH7Zvx3Pf5XCmBe/54dU7fGjlKqeJn4fEOQI4Lnr+jFz0rkUlpYx8bWV/OadZPZlFXo7NKVUA6SJ30eICKN6t+bL+y/gd5d357uUI1zy3Df87fNt5BeXeTs8pVQDIu7c4FtERgEvAA7gNWPMM5Xe7wG8CQwA/miMebbCe82A14DegAF+ZYz58XSfl5SUZJKTk2u5Kaqiw8eK+Nvn2/hg7X5io0K49tw4xvZtyzltohCRapfbl1XIF1sOsWl/LmVOQ7nTUOY0OF3PoUEB/O7y7nRpGVWPW6OUqomIrDHGJLk1b02JX0QcwA7gUiAdWA3cYIzZUmGelkA8MB7IqZT43wa+M8a8JiLBQLgx5ujpPlMTv+f8tC+H579K4fvUI5Q7DZ1jI7iyX1vG9m1Ll5aRGGPYcvAYX2w+zOLNh9h2KA+Ads3CCAkKwCGCI0AIdAiOgAB2Z+bTLDyYj387nOiIYC9vnVLqBE8n/qHAY8aYy12vHwYwxvy1inkfA/JPJH4RaQKsBzoZdw4tXDTxe15WfjGfbz7EwvUHWLk7G2OgR+soCkrKSMs+jggMjG/OZb1acVnP1nSICa9yPWv35TDh1RUM6NCMd24bTJBDq4VKNQS1Sfzu3Gy9HVDxCqF0YLCbsXQCMoE3RaQfsAa41xhT4ObyykNiIkOYODieiYPjOXysiEUbD/LZpkO0bRbGby/swiU9W9EiMqTG9QzoEM0zV/XhgbnreXzhZp4a36ceoldKeZI7ib+qgrC7rfdAbN3/bmPMShF5AZgOPPqzDxGZAkwB6NChg5urV2eiVZNQbh2ewK3DE85o+asGxLH9cB6vfLOL7q2iuGloR88GqJSqU+4cp6cD7Su8jgPcHSAmHUg3xqx0vZ6H3RH8jDHmVWNMkjEmKTY21s3VK2/5/eU9uLhHSx5buIXlet2AUo2KO4l/NdBVRBJcJ2cnAAvcWbkx5hCQJiLdXZNGAltOs4hqJBwBwgsTEunUIoI7Zq1lzxGt3inVWNSY+I0xZcBdwGJgKzDXGLNZRKaKyFQAEWktIunAA8AjIpLuOrELcDcwS0Q2AInAX+piQ1T9iwoN4vXJAxGB295ezbGiUm+HpJRyg1v9+Oub9uppXJbvPMLNr6+iV7umzLixP3HRVfcIUkrVndr06tG+eOqsDevcgv934wB2ZuRzxQvf8cXmQ94OSSl1Gpr4lUeM6t2aT+4+jw4x4Ux5Zw1PfrKFkjIdKVSphkgTv/KYji0imH/HMCYPjef173dz7Ss/kpatA8Up1dBo4lceFRLo4PFxvXlp4gB2ZeQz5sXv+HyTln6Uakg08as6cUWfNnxyz3nEx0Qw9d013PbWanZrl0+lGgRN/KrOxMfY0s/00T1YsSuLy/71DX9dtJU87faplFdp4ld1KjgwgKkXdGbp7y5kXGI7Xvl2Fxf/8xveT07D6Wx4XYmV8gfaj1/Vq/VpR3ls4WZ+2neUfnFNGd+/HQM7NqdH6ygCdaRPpc6YR4dl9gZN/L7N6TR8vH4/z3+Vwl7X7SEjgh0MiI9mYMfmJHWM5tz4aEICHV6OVKnGQxO/ajQOHD1O8t4ckvdks2p3NtsP52EMdIqN4KWJA+jRuknNK6lGTkEJT326lcAA4Z5LutKuWZgHI1eqYdHErxqt3OOl/JB6hD8v2ExeUSlPjOvNdUnta16wkm93ZDLt/fXkFJacvNXk5KHx3HlhF4/fOcwYQ3GZk9AgPUJR3qOJXzV6mXnF3DfnJ35IzeLqAXE8Ob4X4cE13z6iqLScZz7bxlvL99C1ZST/uj6R6Ihg/vXlDuavTScyJJA7L+zCrcM7nlWiLit3smpPNl9uOcwXmw+TU1jCm7cMZHCnmDNep1JnQxO/8gnlTsP/fZ3CC0tS6BIbycuTBpz2Ju+b9udy35x1pGbkc+vwjjw0qscpyX37oTz+/vk2lmzLoHWTUCYP60h4sIMyp6Gs3Ol6NpQ7nYSHBNIkNIgmYfY5KjSQqNAgUjPy+GLLYb7elsHRwlKCAwMY0aUFu48UkJFXzKzbB9OvfbP6+PWclbTsQpqFBxEVGuTtUJSHaOJXPuX7lCPcN+cnCorLeeDSbrRsEoLTGIwBp7Gllj1ZBbz67S6aRwTz7LX9GNG1+pv5rNyVxTOfb+OnfUfPKJ6mYUGM7NGSy3q1YkTXWCJCAjmUW8S1rywnr6iMOVOG0r119TsobyooLuMvi7Yya+U+ggMDuLBbLGP6tmHkOa2IDHHnhnyqodLEr3zO4WNF3PPeT6zcnV3tPGP6tOHpX/amWXjNNXxjDEfySwgQCHQEEBggBDqEoIAAROB4aTnHjpdxrKiUY8dLXc9ltGwSwsCOzau8yXxadiHXzFxOuRPenzqUhBYRZ7XNnrZyVxbT5q0nPec4k4d2RAQWbTzI4WPFhAQGcGH3WMb0bcsl57R0q6zWUJWWO/lqy2E+XneA+BbhTBocT/vmvj9UuCZ+5ZOcTsO+7EKcxhAggggnn4MdAbRsEurtEEnNyOO6V1YQGhjA3KlDG8S9CYpKy3l28XZe/2E37aPDefbafgxKaA7Y3+mafTl8uuEgizYeJCOvmKZhQdx+XgKTh3ekyRmUgkrKnBw4epy0nELCgwPp374ZAQFV3brbs9JzCpm9Ko05yWlk5hXTIjKEnMISnMYwskcrJg+LZ3jnFj+LJS27kGXbM1i6PZMtB44xrHMMV/Zry/AuLQgObDzXlmjiV8qLNh/I5YZXV9A8Ipi5vxnq1g6p3GnYtD+X71Iy2ZNVSFJ8NOd3i6XtWXZBXZd2lAfnrmNnZgGThnTg4dHnEFFNSafcaVi1O5vXv9/FV1szaBIayK/OS+DW4Qk0Dfv5DqCotJz1aUdJ3pvDrswC0nIKSc8u5NCxIipelN2qSQije7dhTN82nNsh2mM7gXKnITOvmA3pR5m9Oo2l2zMAuKh7SyYO7sCF3Vty+FgR/125j/dW7SOroIROsRHcPCSebq2iWLYjk6XbMkjJyAcgPiacXm2b8ENqFrnHS2kaFsTo3q25sl9bhnSKwVGHO6/c46Ws2p3NoWNF3DQk/ozWoYlfKS9buy+HSa+tJC46jDsu7Eyz8GCiw4OJDg8iOiKYqJBADuYW8X3KEb5NyeSH1CPkFNoxjKLDg07+3KVlJCO6tuD8brEMSYghLNhBcVk5BcXlFBSXkV9cRkFxGVkFJRw+VsTB3CIOnXgcK2JvVgGtmoTy92v6nva8R2Wb9ufywpIUvtxymKjQQG4dnsANg9qTmpHPqt3ZrNydzbq0oyfvudC6SSjtm4fRPjqcuObhtI8Oo33zcA4fK+LTDQdZtiOTkjLnyZ3AxT1aEhbsoNxpcBqD0wnlxv5cWuakpNxJSZl9lJY7KS5zknu8lP1Hj7M/5zgHco9zKLeI0nKbv2KjQpgwsD3XD2xf5VFWcVk5n208xNs/7jl5bifIIQxOiOGiHi25qHssnWIjAXvE8n1qJgvXH+SLzYcoKCmnRWQw8TEROAKEwADB4XoEBghhwYHERoYQGxVCyyjXc5MQWkSGEBEcSEhgwM92dvnFZazenc2Pu7L4cWcWmw/k4jT2b5/8yKVntJPRxK9UA7B85xFufzuZwpLyn70XGCCUuZrFLaNCGNE1lvO7tWB4lxbERASTkpHPtzsy+WZHJqt2Z1Nc5iQwwJa1TiS7qgQGCK2ahNKmaSitmobSOTaS286rusXujs0HcnlxSQqLNx8+Oc0RIPRu24TBnWIY5LrSuqbzKnlFpXy9LeOUnUBtBQi0aRpG22ahtG0WRrtmYbRtFkbHmAgGd6r6vEtVNqbnkpFXxOBOMTWe0C4qLWfptgw+23SIrIJiV68vQ7mxz2XlhsKSMjLziimo4u98QmhQAKFBDsKCHAQHBpCec5xypyHYEUBih2YM7RTD0M4xJLZvdsbdjDXxK9VAFBSXkZFXTHZBCUcLS8gpLCWnoIScwhKiw4MZ0a0F3VtFnbzIrCpFpeWs2p3Nil1ZOA1EhjiICAkkIiSQSNdzdHgQbZqGERMRXCf19K0Hj7Fseya92jZhQHz0WfUAyi8uY33aUYyxyTzA1XoOEBARgh0BBAcG/O/Z9QgPcjTo8ZwKiu0OICOvmMy8Yo7kF3O8tJzjJeUUldrH8dJyjpc6iW8eztDOMQzoEE1YsGcu/NPEr5RSfkZvtq6UUqpamviVUsrPaOJXSik/41biF5FRIrJdRFJFZHoV7/cQkR9FpFhEplXxvkNEfhKRTzwRtFJKqTNXY+IXEQcwAxgN9ARuEJGelWbLBu4Bnq1mNfcCW88iTqWUUh7iTot/EJBqjNlljCkBZgPjKs5gjMkwxqwGfnYXbRGJA8YAr3kgXqWUUmfJncTfDkir8DrdNc1dzwO/B057xYaITBGRZBFJzszMrMXqlVJK1YY7ib+qq0Hc6vwvImOBDGPMmprmNca8aoxJMsYkxca6f2m5Ukqp2nHn8rt0oOK97+KAA26ufzjwCxG5AggFmojIu8aYSadbaM2aNUdEZK+bn1FZC+DIGS7b2PnztoN/b79uu/86sf1uj+5W45W7IhII7ABGAvuB1cCNxpjNVcz7GJBvjPnZSV4RuRCYZowZ625wZ0JEkt29es3X+PO2g39vv267f247nNn219jiN8aUichdwGLAAbxhjNksIlNd788UkdZAMtAEcIrIfUBPY8yxWm+FUkqpOuXWSEvGmEXAokrTZlb4+RC2BHS6dSwDltU6QqWUUh7li1fuvurtALzIn7cd/Hv7ddv9V623v0GOzqmUUqru+GKLXyml1Glo4ldKKT/jM4m/poHkfI2IvCEiGSKyqcK05iLypYikuJ6jvRljXRGR9iKyVES2ishmEbnXNd3nt19EQkVklYisd237467pPr/tJ1Qe9NHPtn2PiGwUkXUikuyaVuvt94nE7+ZAcr7mLWBUpWnTgSXGmK7AEtdrX1QGPGiMOQcYAvzW9ff2h+0vBi42xvQDEoFRIjIE/9j2EyoP+uhP2w5wkTEmsULf/Vpvv08kftwYSM7XGGO+xY6KWtE44G3Xz28D4+s1qHpijDlojFnr+jkPmwTa4Qfbb6x818sg18PgB9sO1Q766Bfbfhq13n5fSfxnO5Ccr2hljDkINjkCLb0cT50TkY5Af2AlfrL9rlLHOiAD+NIY4zfbTtWDPvrLtoPdyX8hImtEZIprWq23360LuBqBMx5ITjVeIhIJzAfuM8YcE6nq38D3GGPKgUQRaQZ8KCK9vR1Tfag46KNrCBh/NNwYc0BEWgJfisi2M1mJr7T4z2YgOV9yWETaALieM7wcT50RkSBs0p9ljPnANdlvth/AGHMUezX8KPxj208M+rgHW869WETexT+2HQBjzAHXcwbwIbbMXevt95XEvxroKiIJIhIMTAAWeDkmb1gATHb9PBn42Iux1BmxTfvXga3GmOcqvOXz2y8isa6WPiISBlwCbMMPtt0Y87AxJs4Y0xH7Hf/aNdKvz287gIhEiEjUiZ+By4BNnMH2+8yVu66hn5/nfwPJPe3lkOqUiLwHXIgdkvUw8GfgI2Au0AHYB1xrjKl8ArjRE5HzgO+Ajfyv1vsHbJ3fp7dfRPpiT+A5sA23ucaYJ0QkBh/f9ooqjvbrL9suIp2wrXywZfr/GmOePpPt95nEr5RSyj2+UupRSinlJk38SinlZzTxK6WUn9HEr5RSfkYTv1JK+RlN/Eop5Wc08SullJ/5/z0aJEvA8EQpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if args.mode == 'train':\n",
    "    if args.type == 'daily':\n",
    "        train_loss_info, val_loss_info = train_daily()\n",
    "        # training loss trend and validation loss trend\n",
    "        plt.figure(1)\n",
    "        plt.plot(train_loss_info, label='train_loss')\n",
    "        plt.plot(val_loss_info, label='val_loss')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "    if args.type == 'weekly':\n",
    "        train_loss_info, val_loss_info = train_weekly()\n",
    "        # training loss trend and validation loss trend\n",
    "        plt.figure(1)\n",
    "        plt.plot(train_loss_info, label='train_loss')\n",
    "        plt.plot(val_loss_info, label='val_loss')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode == 'test':\n",
    "    if args.type == 'daily':\n",
    "        trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "        test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate_daily()\n",
    "        # path = 'checkpoint_1.tar'\n",
    "        path = 'checkpoint_daily.tar'\n",
    "        test_daily(path, test_x, test_y, train_y_mean, train_y_std)\n",
    "    if args.type == 'weekly':\n",
    "        # path = 'checkpoint_2.tar'\n",
    "        path = 'checkpoint_weekly_sequential.tar'\n",
    "        trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "        test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate()\n",
    "        test_weekly(path, test_x, test_y, train_y_mean, train_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_predict_4_day_avg.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "day_input = 6\n",
    "timelagging = 6\n",
    "average_num = 4\n",
    "### change the numbers of feature ###\n",
    "feature_num = 14+2*(day_input-1)\n",
    "### ------------------------###\n",
    "\n",
    "\"\"\"     read in data and process, this part is very similar to lstm_1.py    \"\"\"\n",
    "### change the input dataset name ###\n",
    "# filename = \"LA_daily_predict.csv\"\n",
    "### --------------------------- ###\n",
    "zipcode_daily = LA_daily_predict\n",
    "# pd.read_csv(filename, encoding=\"ISO-8859-1\", dtype={'ZIP': str, 'date': str})\n",
    "zip = zipcode_daily['ZIP']\n",
    "date = zipcode_daily['date']  # we have to preserve the date\n",
    "del zipcode_daily['ZIP']\n",
    "del zipcode_daily['date']\n",
    "zipcode_daily = pd.DataFrame(zipcode_daily, dtype=float)  # change the type from 'int' to 'float'\n",
    "zipcode_daily['ZIP'] = zip\n",
    "zipcode_daily['date'] = date  # add date back\n",
    "\n",
    "data_dict = {}  # key: 'zip', value: feature that belong to the key\n",
    "for i, zipcode in enumerate(zipcode_daily[:]['ZIP']):\n",
    "    if zipcode not in data_dict:\n",
    "        data_dict[zipcode] = []\n",
    "    feature = []\n",
    "    for f in zipcode_daily.iloc[i]:\n",
    "        feature.append(f)\n",
    "    data_dict[zipcode].append(feature)\n",
    "\n",
    "zipcode = []  # save 'zip code' correlating to input point\n",
    "date = []     # save 'date' correlating to input point\n",
    "\n",
    "data_x = []  # input\n",
    "for key, values in data_dict.items():\n",
    "    l = len(values)\n",
    "    input_num = l - timelagging - average_num\n",
    "    feature = []\n",
    "    input_num=input_num+5\n",
    "    for i in range(input_num):\n",
    "        first = True\n",
    "        for j in range(day_input):\n",
    "            if first:\n",
    "                zipcode.append(values[i][-2])   # save 'zip code' correlating to ont input point\n",
    "                date.append(values[i][-1])      # save 'date' correlating to ont input point\n",
    "                # because we add 'date' back, the last feature is values[i][:-5] not values[i][:-4]\n",
    "                for k in values[i][:-3]:\n",
    "                    feature.append(k)\n",
    "                first = False\n",
    "            else:\n",
    "                feature.append(values[i + j][0])\n",
    "                feature.append(values[i + j][1])\n",
    "        tmp = []\n",
    "        tmp.append(feature)\n",
    "        data_x.append(tmp)  # one input point\n",
    "        feature = []\n",
    "\n",
    "data_x_ls = []\n",
    "for j in data_x:\n",
    "    for i in j:\n",
    "        data_x_ls.append(i)\n",
    "data_x_df = pd.DataFrame(data_x_ls)\n",
    "data_x_mean = data_x_df.mean()  # train dataset mean\n",
    "data_x_std = data_x_df.std()    # train dataset std\n",
    "\n",
    "for i in range(len(data_x)):    # using train_x mean and train_x std to normalize\n",
    "    for j in range(len(data_x[i])):\n",
    "        for k in range(len(data_x[i][j])):\n",
    "            data_x[i][j][k] = (data_x[i][j][k] - data_x_mean[k]) / data_x_std[k]\n",
    "\n",
    "data_x = torch.tensor(data_x)\n",
    "\n",
    "\n",
    "# scale the output value back to its original size and cal the loss\n",
    "def upscale(predict):\n",
    "    x = predict[:]\n",
    "    for i in range(len(predict)):\n",
    "        x[i][0] = x[i][0] * torch.tensor(data_x_std[1]) + torch.tensor(data_x_mean[1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     define LSTM model   \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # if batch_first=True, then input shape = (batch, seq, shape)\n",
    "        self.lstm = torch.nn.LSTM(input_size=feature_num, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(64 * 1, 32)\n",
    "        self.linear1 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(-1, 64 * 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "### change the path name ###\n",
    "path = 'checkpoint_0727.tar'\n",
    "### -------------------- ###\n",
    "# load from file\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "predict = np.array(model(data_x).data)  # output\n",
    "predict_upscale = upscale(predict)      # original scale output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "###\n",
    "date_list = []\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-04-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-05-'+str(i))\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-06-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-07-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-08-'+str(i))\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-09-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-10-'+str(i))\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-11-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-12-'+str(i))\n",
    "\n",
    "\n",
    "date_list_new = []\n",
    "\"\"\"\n",
    "for date_ in date:\n",
    "    date_start = date_list[date_list.index(date_)+6]\n",
    "    date_end = date_list[date_list.index(date_)+9]\n",
    "    date_list_new.append(date_start+' - ' + date_end)\n",
    "\"\"\"\n",
    "for date_ in date:\n",
    "    date_start = (date_+datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "    date_end = (date_+datetime.timedelta(days=9)).strftime(\"%Y-%m-%d\")\n",
    "    date_list_new.append(date_start+' - ' + date_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZIP    date_start - date_end  Predicted new cases risk_score_level  \\\n",
      "0  Acton  2020-04-09 - 2020-04-12            -0.961864             None   \n",
      "1  Acton  2020-04-10 - 2020-04-13            -1.684089             None   \n",
      "2  Acton  2020-04-11 - 2020-04-14            -0.810418             None   \n",
      "3  Acton  2020-04-12 - 2020-04-15            -1.404660             None   \n",
      "4  Acton  2020-04-13 - 2020-04-16            -1.500849             None   \n",
      "\n",
      "   cases/population  \n",
      "0         -1.474799  \n",
      "1         -2.582167  \n",
      "2         -1.242591  \n",
      "3         -2.153725  \n",
      "4         -2.301210  \n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame()                            # generate table\n",
    "out['ZIP'] = zipcode                            # zip code column\n",
    "out['date_start - date_end'] = date_list_new    # date column\n",
    "out['Predicted new cases'] = predict_upscale     # predicted new cases columns\n",
    "out['risk_score_level']=None\n",
    "###\n",
    "pop = pd.read_csv('LApopulation.csv', index_col = False)  # population data\n",
    "###\n",
    "for i in range(out.shape[0]):\n",
    "    for j in range(pop.shape[0]):\n",
    "        if (out.at[i,'ZIP'] == pop.at[j,'ZIP']):\n",
    "            out.at[i,'cases/population'] = 10000 * out.at[i,'Predicted new cases'] / pop.at[j,'population']\n",
    "\n",
    "print(out.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZIP    date_start - date_end  Predicted new cases  risk_score_level  \\\n",
      "0  Acton  2020-04-09 - 2020-04-12            -0.961864                 1   \n",
      "1  Acton  2020-04-10 - 2020-04-13            -1.684089                 1   \n",
      "2  Acton  2020-04-11 - 2020-04-14            -0.810418                 1   \n",
      "3  Acton  2020-04-12 - 2020-04-15            -1.404660                 1   \n",
      "4  Acton  2020-04-13 - 2020-04-16            -1.500849                 1   \n",
      "\n",
      "   cases/population  \n",
      "0         -1.474799  \n",
      "1         -2.582167  \n",
      "2         -1.242591  \n",
      "3         -2.153725  \n",
      "4         -2.301210  \n"
     ]
    }
   ],
   "source": [
    "# defind the risk score level\n",
    "for i in range(len(out)):\n",
    "    if out['cases/population'][i]<=2:\n",
    "        out.loc[i,'risk_score_level']=1\n",
    "    elif out['cases/population'][i]<=10:\n",
    "        out.loc[i,'risk_score_level']=2\n",
    "    elif out['cases/population'][i]<=20:\n",
    "        out.loc[i,'risk_score_level']=3\n",
    "    else:\n",
    "        out.loc[i,'risk_score_level']=4\n",
    "print(out.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the output dataset name ###\n",
    "out.to_csv('LA_daily_out.csv')\n",
    "### ----------------------------   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
