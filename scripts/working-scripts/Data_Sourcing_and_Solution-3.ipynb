{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.1 in /opt/anaconda3/lib/python3.7/site-packages (1.18.1)\n",
      "CPU times: user 42.6 ms, sys: 21.6 ms, total: 64.3 ms\n",
      "Wall time: 2.82 s\n",
      "Requirement already satisfied: pandas==0.24.2 in /opt/anaconda3/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from pandas==0.24.2) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/anaconda3/lib/python3.7/site-packages (from pandas==0.24.2) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/anaconda3/lib/python3.7/site-packages (from pandas==0.24.2) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas==0.24.2) (1.12.0)\n",
      "CPU times: user 21.3 ms, sys: 9.77 ms, total: 31.1 ms\n",
      "Wall time: 1.56 s\n",
      "Requirement already satisfied: matplotlib==3.2.1 in /opt/anaconda3/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1) (1.18.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib==3.2.1) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.2.1) (41.4.0)\n",
      "CPU times: user 21.2 ms, sys: 9.43 ms, total: 30.6 ms\n",
      "Wall time: 1.5 s\n",
      "Requirement already satisfied: scikit-learn==0.23.1 in /opt/anaconda3/lib/python3.7/site-packages (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1) (1.18.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.23.1) (1.3.1)\n",
      "CPU times: user 21.6 ms, sys: 9.49 ms, total: 31 ms\n",
      "Wall time: 1.57 s\n",
      "Requirement already satisfied: datetime==4.3 in /opt/anaconda3/lib/python3.7/site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in /opt/anaconda3/lib/python3.7/site-packages (from datetime==4.3) (5.1.0)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.7/site-packages (from datetime==4.3) (2019.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from zope.interface->datetime==4.3) (41.4.0)\n",
      "CPU times: user 22.7 ms, sys: 12.3 ms, total: 35.1 ms\n",
      "Wall time: 1.56 s\n",
      "Requirement already satisfied: argparse==1.4.0 in /opt/anaconda3/lib/python3.7/site-packages (1.4.0)\n",
      "CPU times: user 20.2 ms, sys: 8.79 ms, total: 29 ms\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "import sys\n",
    "%time  !{sys.executable} -m pip install numpy==1.18.1\n",
    "%time  !{sys.executable} -m pip install pandas==0.24.2\n",
    "%time  !{sys.executable} -m pip install matplotlib==3.2.1\n",
    "%time  !{sys.executable} -m pip install scikit-learn==0.23.1\n",
    "%time  !{sys.executable} -m pip install datetime==4.3\n",
    "%time  !{sys.executable} -m pip install argparse==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (1.0.1)\n",
      "CPU times: user 20.1 ms, sys: 11.2 ms, total: 31.3 ms\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "# method 1 to install 'torch'\n",
    "%time  !{sys.executable} -m pip install torch==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import sklearn\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import re\n",
    "import zipfile as zp\n",
    "\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targeted communities in LA County\n",
    "target = ['Alhambra', 'Arcadia', 'Beverly Hills', 'Boyle Heights', 'Carson', 'Diamond Bar', 'Encino', 'Gardena', 'Glendale', 'Glendora',\n",
    "          'Granada Hills', 'Inglewood', 'La Mirada', 'Lancaster', 'Manhattan Beach', 'Melrose', 'Northridge', 'San Dimas', 'San Pedro',\n",
    "          'Santa Monica', 'Sherman Oaks', 'Silver Lake', 'Tarzana', 'Torrance', 'Venice', 'West Adams', 'West Hills', 'West Hollywood',\n",
    "          'West Vernon', 'Westchester', 'Altadena', 'Baldwin Hills', 'Brentwood', 'Culver City', 'Eagle Rock', 'Hollywood',\n",
    "          'Hollywood Hills', 'Lynwood', 'Mar Vista', 'Monterey Park', 'North Hollywood', 'Reseda', 'Santa Clarita', 'Woodland Hills',\n",
    "          'Sylmar', 'Walnut', 'Beverlywood', 'Burbank', 'Calabasas', 'Castaic', 'Covina', 'Crestview', 'East Los Angeles', 'Echo Park', \n",
    "          'Hancock Park', 'Hawthorne', 'Lawndale', 'Lomita', 'Palms', 'Playa Vista', 'South El Monte', 'Stevenson Ranch', 'Studio City',\n",
    "          'Tujunga', 'University Park', 'Valley Glen', 'Van Nuys', 'Vermont Knolls', 'Westwood', 'Whittier', 'Century City', 'El Segundo',\n",
    "          'Lake Balboa', 'Lakewood', 'Miracle Mile', 'Park La Brea', 'Redondo Beach', 'San Fernando', 'South Whittier', 'Winnetka', \n",
    "          'Del Rey', 'La Canada Flintridge', 'La Verne', 'Montebello', 'Sun Valley', 'Sunland', 'Vermont Vista', 'Vernon Central',\n",
    "          'West Covina', 'Westlake', 'Bellflower', 'Canoga Park', 'East Hollywood', 'Los Feliz', 'Paramount', 'Rancho Palos Verdes', \n",
    "          'South Gate', 'Agoura Hills', 'Duarte', 'Exposition Park', 'Hyde Park', 'Lincoln Heights', 'Palmdale', 'South Park',\n",
    "          'Wilshire Center', 'Canyon Country', 'Claremont', 'Downey', 'Harbor Gateway', 'Harvard Heights', 'Highland Park', \n",
    "          'La Puente', 'Norwalk', 'Pico Rivera', 'Porter Ranch', 'San Gabriel', 'Wholesale District', 'Willowbrook', 'Arleta',\n",
    "          'Bell Gardens', 'Glassell Park', 'Panorama City', 'Pomona', 'Valinda', 'Watts', 'Azusa', 'Bell', 'Chatsworth', \n",
    "          'Hacienda Heights', 'Harbor City', 'Leimert Park', 'Maywood', 'Monrovia', 'North Hills', 'Pacoima', 'Avalon', 'Baldwin Park',\n",
    "          'Bassett', 'Central', 'El Monte', 'El Sereno', 'Harvard Park', 'Lake Los Angeles', 'Rosemead', 'Rowland Heights', 'Temple City',\n",
    "          'Acton', 'Cerritos', 'Cloverdale/Cochran', 'Compton', 'Downtown', 'Huntington Park', 'Koreatown', 'Mt. Washington', 'Pasadena', \n",
    "          'South Pasadena', 'Wilmington']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confirmed_cases_LA():\n",
    "    #Read the data from the source\n",
    "    url=\"https://raw.githubusercontent.com/datadesk/california-coronavirus-data/master/latimes-place-totals.csv\"\n",
    "    df = pd.read_csv(url,header=0)\n",
    "    df = df[df['county']=='Los Angeles'][['date','place','confirmed_cases']]\n",
    "    df = df[df['place'].isin(target)]\n",
    "    \n",
    "    # Change format\n",
    "    result = df.copy()\n",
    "    result['place'].replace('Silver Lake','Silverlake',inplace = True)\n",
    "    result['date'] = pd.to_datetime(result['date'])\n",
    "    \n",
    "    result = result.sort_values(by=['place','date'])\n",
    "    result['new_confirmed_cases'] = result['confirmed_cases']\n",
    "    result['ave_new7_10after'] = result['confirmed_cases']\n",
    "    result['ave_new6_9after'] = result['confirmed_cases']\n",
    "    result['ave_new8_11after'] = result['confirmed_cases']\n",
    "    result.iloc[0,3] = None\n",
    "    return result\n",
    "\n",
    "def read_case_LA():\n",
    "    result = get_confirmed_cases_LA()\n",
    "    for i in range(1,len(result)):    \n",
    "        if i < (len(result)-11):\n",
    "            if result.iloc[i,1] == result.iloc[(i+11),1]:\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "                result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3] + result.iloc[(i+11),3])/4.0\n",
    "            elif result.iloc[i,1] == result.iloc[(i+10),1]:\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "                result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/3.0\n",
    "            elif result.iloc[i,1] == result.iloc[(i+9),1]:\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/3.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "                result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3])/2.0\n",
    "            elif result.iloc[i,1] == result.iloc[(i+8),1]:\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3])/2.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3])/3.0\n",
    "                result.iloc[i,6] = result.iloc[(i+8),3]\n",
    "            elif result.iloc[i,1] == result.iloc[(i+7),1]:\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3])/2.0\n",
    "                result.iloc[i,6] = result.iloc[i,4] = result.iloc[(i+7),3]\n",
    "            else:\n",
    "                for j in range(8):\n",
    "                    if result.iloc[i,1] == result.iloc[(i+7-j),1]:\n",
    "                        result.iloc[i,4] = result.iloc[i,5] = result.iloc[i,6] = result.iloc[(i+7-j),3]\n",
    "                        break\n",
    "        else:\n",
    "            if i < (len(result)-10):\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "                result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/3.0\n",
    "            elif i < (len(result)-9):\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/3.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "                result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3])/2.0\n",
    "            elif i < (len(result)-8):\n",
    "                result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3])/2.0\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3])/3.0\n",
    "                result.iloc[i,6] = result.iloc[(i+8),3]\n",
    "            elif i < (len(result)-7):\n",
    "                result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3])/2.0\n",
    "                result.iloc[i,6] = result.iloc[i,4] = result.iloc[(i+7),3]\n",
    "            else:          \n",
    "                result.iloc[i,4] = result.iloc[i,5] = result.iloc[i,6] = result.iloc[-1,3]\n",
    "    result.dropna(inplace = True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date to string\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "d = today.strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apple_link():\n",
    "    '''Get link of Apple Mobility Trends report file\n",
    "    \n",
    "       Returns:\n",
    "           link (str): link of Apple Mobility Trends report file\n",
    "    '''\n",
    "    # get link via API\n",
    "    json_link = \"https://covid19-static.cdn-apple.com/covid19-mobility-data/current/v3/index.json\"\n",
    "    with urllib.request.urlopen(json_link) as url:\n",
    "        json_data = json.loads(url.read().decode())\n",
    "    link = \"https://covid19-static.cdn-apple.com\" + \\\n",
    "        json_data['basePath'] + json_data['regions']['en-us']['csvPath']\n",
    "    return link\n",
    "\n",
    "def download_apple_report(directory=\"apple_reports\"):\n",
    "    '''Download Apple Mobility Trends report in CSV\n",
    "\n",
    "        Args:\n",
    "            directory: directory to which CSV report will be downloaded\n",
    "\n",
    "        Returns:\n",
    "            new_files (bool): flag indicating whether or not a new file has been downloaded\n",
    "    '''\n",
    "    new_files = False\n",
    "    \n",
    "    # create directory if it don't exist\n",
    "    if not os.path.exists(directory) and directory!='':\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    link = get_apple_link()\n",
    "    file_name = \"applemobilitytrends.csv\"\n",
    "    path = os.path.join(directory, file_name)\n",
    "    path = os.path.join(directory, file_name)\n",
    "    old_size = os.path.getsize(path) if os.path.isfile(path) else 0\n",
    "    urllib.request.urlretrieve(link, path)\n",
    "    new_size = os.path.getsize(path)\n",
    "    if old_size!=new_size:\n",
    "        new_files = True\n",
    "\n",
    "    if not new_files:\n",
    "        print('Apple: No updates')\n",
    "    else:\n",
    "        print('Apple: Update available')\n",
    "    \n",
    "    return new_files\n",
    "\n",
    "def build_apple_report(\n",
    "    source=os.path.join(\n",
    "        'apple_reports',\n",
    "        \"applemobilitytrends.csv\"),\n",
    "        report_type=\"regions\"):\n",
    "    '''Build cleaned Apple report (transform dates from columns to rows, add country names for subregions and cities)\n",
    "       for the worldwide or for some country (currently only for the US)\n",
    "\n",
    "        Args:\n",
    "            source: location of the raw Apple CSV report\n",
    "            destination: destination file path\n",
    "            report_type: two options available: \"regions\" - report for the worldwide, \"US\" - report for the US\n",
    "\n",
    "        Returns:\n",
    "           apple (DataFrame): generated Apple report\n",
    "    '''\n",
    "    apple = pd.read_csv(source)\n",
    "    apple = apple.drop(columns=['alternative_name'])\n",
    "    apple['country'] = apple.apply(\n",
    "        lambda x: x['region'] if x['geo_type'] == 'country/region' else x['country'],\n",
    "        axis=1)\n",
    "\n",
    "    if report_type == 'regions':\n",
    "        apple = apple[apple.geo_type != 'county']\n",
    "        apple['sub-region'] = apple.apply(lambda x: 'Total' if x['geo_type'] == 'country/region' else (\n",
    "            x['region'] if x['geo_type'] == 'sub-region' else x['sub-region']), axis=1)\n",
    "        apple['subregion_and_city'] = apple.apply(\n",
    "            lambda x: 'Total' if x['geo_type'] == 'country/region' else x['region'], axis=1)\n",
    "        apple = apple.drop(columns=['region'])\n",
    "        apple['sub-region'] = apple['sub-region'].fillna(\n",
    "            apple['subregion_and_city'])\n",
    "\n",
    "        apple = apple.melt(\n",
    "            id_vars=[\n",
    "                'geo_type',\n",
    "                'subregion_and_city',\n",
    "                'sub-region',\n",
    "                'transportation_type',\n",
    "                'country'],\n",
    "            var_name='date')\n",
    "        apple['value'] = apple['value'] - 100\n",
    "\n",
    "        apple = apple.pivot_table(\n",
    "            index=[\n",
    "                \"geo_type\",\n",
    "                \"subregion_and_city\",\n",
    "                \"sub-region\",\n",
    "                \"date\",\n",
    "                \"country\"],\n",
    "            columns='transportation_type').reset_index()\n",
    "        apple.columns = [t + (v if v != \"value\" else \"\")\n",
    "                         for v, t in apple.columns]\n",
    "        apple = apple.loc[:,\n",
    "                          ['country',\n",
    "                           'sub-region',\n",
    "                           'subregion_and_city',\n",
    "                           'geo_type',\n",
    "                           'date',\n",
    "                           'driving',\n",
    "                           'transit',\n",
    "                           'walking']]\n",
    "        apple = apple.sort_values(by=['country',\n",
    "                                      'sub-region',\n",
    "                                      'subregion_and_city',\n",
    "                                      'date']).reset_index(drop=True)\n",
    "    elif report_type == \"US\":\n",
    "        apple = apple[apple.country == \"United States\"].drop(columns=[\n",
    "                                                             'country'])\n",
    "        apple['sub-region'] = apple['sub-region'].fillna(\n",
    "            apple['region']).replace({\"United States\": \"Total\"})\n",
    "        apple['region'] = apple.apply(lambda x: x['region'] if (\n",
    "            x['geo_type'] == 'city' or x['geo_type'] == 'county') else 'Total', axis=1)\n",
    "        apple = apple.rename(\n",
    "            columns={\n",
    "                'sub-region': 'state',\n",
    "                'region': 'county_and_city'})\n",
    "\n",
    "        apple = apple.melt(\n",
    "            id_vars=[\n",
    "                'geo_type',\n",
    "                'state',\n",
    "                'county_and_city',\n",
    "                'transportation_type'],\n",
    "            var_name='date')\n",
    "        apple['value'] = apple['value'] - 100\n",
    "\n",
    "        apple = apple.pivot_table(\n",
    "            index=[\n",
    "                'geo_type',\n",
    "                'state',\n",
    "                'county_and_city',\n",
    "                'date'],\n",
    "            columns='transportation_type').reset_index()\n",
    "        apple.columns = [t + (v if v != \"value\" else \"\")\n",
    "                         for v, t in apple.columns]\n",
    "\n",
    "        apple = apple.loc[:, ['state', 'county_and_city', 'geo_type',\n",
    "                              'date', 'driving', 'transit', 'walking']]\n",
    "        apple = apple.sort_values(\n",
    "            by=['state', 'county_and_city', 'geo_type', 'date']).reset_index(drop=True)\n",
    "    return apple\n",
    "\n",
    "def read_apple_LA():\n",
    "    new_files_status_apple = download_apple_report()\n",
    "    apple_mobility = build_apple_report(report_type=\"US\")\n",
    "    apple_mobility = apple_mobility[apple_mobility['county_and_city']=='Los Angeles']\n",
    "    apple_mobility['driving'] = apple_mobility['driving']+100\n",
    "    apple_mobility['transit'] = apple_mobility['transit']+100\n",
    "    apple_mobility['walking'] = apple_mobility['walking']+100\n",
    "    apple_mobility = apple_mobility[['date','driving','transit','walking']]\n",
    "    apple_mobility['date'] = pd.to_datetime(apple_mobility['date'])\n",
    "    return apple_mobility\n",
    "\n",
    "# Read google Mobility Data\n",
    "def build_google_mobility():\n",
    "    url3 = \"https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv?cachebust=04188f017409e90a\"\n",
    "    google_mobility = pd.read_csv(url3)    \n",
    "    return google_mobility\n",
    "\n",
    "def read_google_LA():\n",
    "    google_mobility = build_google_mobility()\n",
    "    google_mobility = google_mobility[google_mobility['sub_region_2'] == 'Los Angeles County']\n",
    "    gmobility = google_mobility[['date','retail_and_recreation_percent_change_from_baseline',\n",
    "                       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                       'parks_percent_change_from_baseline',\n",
    "                       'transit_stations_percent_change_from_baseline',\n",
    "                       'workplaces_percent_change_from_baseline',\n",
    "                       'residential_percent_change_from_baseline',]].copy()\n",
    "    gmobility['date'] = pd.to_datetime(google_mobility['date'])\n",
    "    return gmobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Modify Econ Data\n",
    "def read_econ_LA():\n",
    "    url4 = \"https://raw.githubusercontent.com/skasralikar/Risk-Score-1-UMichZJU/master/data/input/econ_level.csv\"\n",
    "    econ = pd.read_csv(url4, index_col = 0)\n",
    "    econ.columns = ['place','Density_Per_Sq_Mile','population','Income_level']\n",
    "    return econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_LA(result,amobility,gmobility,econ):\n",
    "    # Merge Mobility Data\n",
    "    final = result.merge(amobility,how = 'left',on = 'date')\n",
    "    final_result = final.merge(gmobility,how = 'left',on = 'date')\n",
    "    final_result.dropna(inplace = True)\n",
    "    # Merge Econ Data\n",
    "    final_results = final_result.merge(econ, how = 'left', on = 'place')\n",
    "    \n",
    "    # Change format\n",
    "    final_results['ZIP'] = final_results['place']\n",
    "    final_results['ZIP'].astype(str)\n",
    "    final_results['date'].astype(str)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: Update available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "LA_cases = read_case_LA()\n",
    "LA_amobility = read_apple_LA()\n",
    "LA_gmobility = read_google_LA()\n",
    "LA_econ = read_econ_LA()\n",
    "\n",
    "final_results = merge_LA(LA_cases,LA_amobility,LA_gmobility,LA_econ)\n",
    "\n",
    "LA_daily = final_results[['ZIP','date','confirmed_cases','new_confirmed_cases','population','Density_Per_Sq_Mile',\n",
    "                              'Income_level','driving','transit',\n",
    "                              'walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                              'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                              'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                              'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline',\n",
    "                              'ave_new7_10after','ave_new6_9after','ave_new8_11after']]\n",
    "\n",
    "LA_daily_predict = final_results[['ZIP','date','confirmed_cases','new_confirmed_cases','population','Density_Per_Sq_Mile',\n",
    "                                      'Income_level','driving','transit','walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                                  'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                                  'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                                  'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline',\n",
    "                                  'ave_new7_10after']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed_cases</th>\n",
       "      <th>new_confirmed_cases</th>\n",
       "      <th>population</th>\n",
       "      <th>Density_Per_Sq_Mile</th>\n",
       "      <th>Income_level</th>\n",
       "      <th>driving</th>\n",
       "      <th>transit</th>\n",
       "      <th>walking</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "      <th>ave_new7_10after</th>\n",
       "      <th>ave_new6_9after</th>\n",
       "      <th>ave_new8_11after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>52.04</td>\n",
       "      <td>26.30</td>\n",
       "      <td>52.60</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>44.77</td>\n",
       "      <td>22.14</td>\n",
       "      <td>48.28</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>33.92</td>\n",
       "      <td>19.22</td>\n",
       "      <td>36.02</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>40.81</td>\n",
       "      <td>21.76</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>41.36</td>\n",
       "      <td>22.16</td>\n",
       "      <td>38.13</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>42.38</td>\n",
       "      <td>21.82</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>40.85</td>\n",
       "      <td>19.10</td>\n",
       "      <td>35.31</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>48.47</td>\n",
       "      <td>21.70</td>\n",
       "      <td>45.50</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>46.57</td>\n",
       "      <td>21.66</td>\n",
       "      <td>50.85</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>30.88</td>\n",
       "      <td>17.80</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP       date  confirmed_cases  new_confirmed_cases  population  \\\n",
       "0  Acton 2020-04-03                1                  1.0        6522   \n",
       "1  Acton 2020-04-04                1                  1.0        6522   \n",
       "2  Acton 2020-04-05                1                  1.0        6522   \n",
       "3  Acton 2020-04-06                1                  1.0        6522   \n",
       "4  Acton 2020-04-07                1                  1.0        6522   \n",
       "5  Acton 2020-04-08                1                  1.0        6522   \n",
       "6  Acton 2020-04-09                1                  1.0        6522   \n",
       "7  Acton 2020-04-10                5                  5.0        6522   \n",
       "8  Acton 2020-04-11                5                  5.0        6522   \n",
       "9  Acton 2020-04-12                5                  5.0        6522   \n",
       "\n",
       "   Density_Per_Sq_Mile  Income_level  driving  transit  walking  \\\n",
       "0                  166             2    52.04    26.30    52.60   \n",
       "1                  166             2    44.77    22.14    48.28   \n",
       "2                  166             2    33.92    19.22    36.02   \n",
       "3                  166             2    40.81    21.76    37.63   \n",
       "4                  166             2    41.36    22.16    38.13   \n",
       "5                  166             2    42.38    21.82    41.92   \n",
       "6                  166             2    40.85    19.10    35.31   \n",
       "7                  166             2    48.47    21.70    45.50   \n",
       "8                  166             2    46.57    21.66    50.85   \n",
       "9                  166             2    30.88    17.80    31.73   \n",
       "\n",
       "   retail_and_recreation_percent_change_from_baseline  \\\n",
       "0                                              -43.0    \n",
       "1                                              -50.0    \n",
       "2                                              -53.0    \n",
       "3                                              -49.0    \n",
       "4                                              -51.0    \n",
       "5                                              -49.0    \n",
       "6                                              -55.0    \n",
       "7                                              -49.0    \n",
       "8                                              -51.0    \n",
       "9                                              -64.0    \n",
       "\n",
       "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "0                                              -15.0   \n",
       "1                                              -20.0   \n",
       "2                                              -27.0   \n",
       "3                                              -27.0   \n",
       "4                                              -30.0   \n",
       "5                                              -27.0   \n",
       "6                                              -34.0   \n",
       "7                                              -22.0   \n",
       "8                                              -19.0   \n",
       "9                                              -38.0   \n",
       "\n",
       "   parks_percent_change_from_baseline  \\\n",
       "0                               -38.0   \n",
       "1                               -54.0   \n",
       "2                               -59.0   \n",
       "3                               -58.0   \n",
       "4                               -58.0   \n",
       "5                               -51.0   \n",
       "6                               -69.0   \n",
       "7                               -55.0   \n",
       "8                               -54.0   \n",
       "9                               -69.0   \n",
       "\n",
       "   transit_stations_percent_change_from_baseline  \\\n",
       "0                                          -51.0   \n",
       "1                                          -51.0   \n",
       "2                                          -57.0   \n",
       "3                                          -59.0   \n",
       "4                                          -58.0   \n",
       "5                                          -57.0   \n",
       "6                                          -65.0   \n",
       "7                                          -58.0   \n",
       "8                                          -52.0   \n",
       "9                                          -60.0   \n",
       "\n",
       "   workplaces_percent_change_from_baseline  \\\n",
       "0                                    -51.0   \n",
       "1                                    -41.0   \n",
       "2                                    -43.0   \n",
       "3                                    -54.0   \n",
       "4                                    -54.0   \n",
       "5                                    -55.0   \n",
       "6                                    -57.0   \n",
       "7                                    -57.0   \n",
       "8                                    -43.0   \n",
       "9                                    -46.0   \n",
       "\n",
       "   residential_percent_change_from_baseline  ave_new7_10after  \\\n",
       "0                                      25.0              4.00   \n",
       "1                                      20.0              3.00   \n",
       "2                                      17.0              2.00   \n",
       "3                                      25.0              1.00   \n",
       "4                                      26.0              2.00   \n",
       "5                                      26.0              3.00   \n",
       "6                                      29.0              4.00   \n",
       "7                                      29.0              5.25   \n",
       "8                                      20.0              6.00   \n",
       "9                                      18.0              6.75   \n",
       "\n",
       "   ave_new6_9after  ave_new8_11after  \n",
       "0             4.00              3.00  \n",
       "1             4.00              2.00  \n",
       "2             3.00              1.00  \n",
       "3             2.00              2.00  \n",
       "4             1.00              3.00  \n",
       "5             2.00              4.00  \n",
       "6             3.00              5.25  \n",
       "7             4.00              6.00  \n",
       "8             5.25              6.75  \n",
       "9             6.00              7.50  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_daily.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed_cases</th>\n",
       "      <th>new_confirmed_cases</th>\n",
       "      <th>population</th>\n",
       "      <th>Density_Per_Sq_Mile</th>\n",
       "      <th>Income_level</th>\n",
       "      <th>driving</th>\n",
       "      <th>transit</th>\n",
       "      <th>walking</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "      <th>ave_new7_10after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>52.04</td>\n",
       "      <td>26.30</td>\n",
       "      <td>52.60</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>44.77</td>\n",
       "      <td>22.14</td>\n",
       "      <td>48.28</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>33.92</td>\n",
       "      <td>19.22</td>\n",
       "      <td>36.02</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>40.81</td>\n",
       "      <td>21.76</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>41.36</td>\n",
       "      <td>22.16</td>\n",
       "      <td>38.13</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>42.38</td>\n",
       "      <td>21.82</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>40.85</td>\n",
       "      <td>19.10</td>\n",
       "      <td>35.31</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>48.47</td>\n",
       "      <td>21.70</td>\n",
       "      <td>45.50</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>46.57</td>\n",
       "      <td>21.66</td>\n",
       "      <td>50.85</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6522</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>30.88</td>\n",
       "      <td>17.80</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP       date  confirmed_cases  new_confirmed_cases  population  \\\n",
       "0  Acton 2020-04-03                1                  1.0        6522   \n",
       "1  Acton 2020-04-04                1                  1.0        6522   \n",
       "2  Acton 2020-04-05                1                  1.0        6522   \n",
       "3  Acton 2020-04-06                1                  1.0        6522   \n",
       "4  Acton 2020-04-07                1                  1.0        6522   \n",
       "5  Acton 2020-04-08                1                  1.0        6522   \n",
       "6  Acton 2020-04-09                1                  1.0        6522   \n",
       "7  Acton 2020-04-10                5                  5.0        6522   \n",
       "8  Acton 2020-04-11                5                  5.0        6522   \n",
       "9  Acton 2020-04-12                5                  5.0        6522   \n",
       "\n",
       "   Density_Per_Sq_Mile  Income_level  driving  transit  walking  \\\n",
       "0                  166             2    52.04    26.30    52.60   \n",
       "1                  166             2    44.77    22.14    48.28   \n",
       "2                  166             2    33.92    19.22    36.02   \n",
       "3                  166             2    40.81    21.76    37.63   \n",
       "4                  166             2    41.36    22.16    38.13   \n",
       "5                  166             2    42.38    21.82    41.92   \n",
       "6                  166             2    40.85    19.10    35.31   \n",
       "7                  166             2    48.47    21.70    45.50   \n",
       "8                  166             2    46.57    21.66    50.85   \n",
       "9                  166             2    30.88    17.80    31.73   \n",
       "\n",
       "   retail_and_recreation_percent_change_from_baseline  \\\n",
       "0                                              -43.0    \n",
       "1                                              -50.0    \n",
       "2                                              -53.0    \n",
       "3                                              -49.0    \n",
       "4                                              -51.0    \n",
       "5                                              -49.0    \n",
       "6                                              -55.0    \n",
       "7                                              -49.0    \n",
       "8                                              -51.0    \n",
       "9                                              -64.0    \n",
       "\n",
       "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "0                                              -15.0   \n",
       "1                                              -20.0   \n",
       "2                                              -27.0   \n",
       "3                                              -27.0   \n",
       "4                                              -30.0   \n",
       "5                                              -27.0   \n",
       "6                                              -34.0   \n",
       "7                                              -22.0   \n",
       "8                                              -19.0   \n",
       "9                                              -38.0   \n",
       "\n",
       "   parks_percent_change_from_baseline  \\\n",
       "0                               -38.0   \n",
       "1                               -54.0   \n",
       "2                               -59.0   \n",
       "3                               -58.0   \n",
       "4                               -58.0   \n",
       "5                               -51.0   \n",
       "6                               -69.0   \n",
       "7                               -55.0   \n",
       "8                               -54.0   \n",
       "9                               -69.0   \n",
       "\n",
       "   transit_stations_percent_change_from_baseline  \\\n",
       "0                                          -51.0   \n",
       "1                                          -51.0   \n",
       "2                                          -57.0   \n",
       "3                                          -59.0   \n",
       "4                                          -58.0   \n",
       "5                                          -57.0   \n",
       "6                                          -65.0   \n",
       "7                                          -58.0   \n",
       "8                                          -52.0   \n",
       "9                                          -60.0   \n",
       "\n",
       "   workplaces_percent_change_from_baseline  \\\n",
       "0                                    -51.0   \n",
       "1                                    -41.0   \n",
       "2                                    -43.0   \n",
       "3                                    -54.0   \n",
       "4                                    -54.0   \n",
       "5                                    -55.0   \n",
       "6                                    -57.0   \n",
       "7                                    -57.0   \n",
       "8                                    -43.0   \n",
       "9                                    -46.0   \n",
       "\n",
       "   residential_percent_change_from_baseline  ave_new7_10after  \n",
       "0                                      25.0              4.00  \n",
       "1                                      20.0              3.00  \n",
       "2                                      17.0              2.00  \n",
       "3                                      25.0              1.00  \n",
       "4                                      26.0              2.00  \n",
       "5                                      26.0              3.00  \n",
       "6                                      29.0              4.00  \n",
       "7                                      29.0              5.25  \n",
       "8                                      20.0              6.00  \n",
       "9                                      18.0              6.75  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_daily_predict.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed_cases</th>\n",
       "      <th>new_confirmed_cases</th>\n",
       "      <th>population</th>\n",
       "      <th>Density_Per_Sq_Mile</th>\n",
       "      <th>Income_level</th>\n",
       "      <th>driving</th>\n",
       "      <th>transit</th>\n",
       "      <th>walking</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "      <th>ave_new7_10after</th>\n",
       "      <th>ave_new6_9after</th>\n",
       "      <th>ave_new8_11after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26113</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>795</td>\n",
       "      <td>795.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>99.56</td>\n",
       "      <td>40.99</td>\n",
       "      <td>114.24</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>822.500000</td>\n",
       "      <td>825.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26114</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>801</td>\n",
       "      <td>801.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>103.50</td>\n",
       "      <td>48.34</td>\n",
       "      <td>108.53</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>825.750000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>827.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26115</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>806</td>\n",
       "      <td>806.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>106.30</td>\n",
       "      <td>48.42</td>\n",
       "      <td>111.73</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>827.500000</td>\n",
       "      <td>825.750000</td>\n",
       "      <td>828.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26116</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>809</td>\n",
       "      <td>809.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>109.09</td>\n",
       "      <td>49.16</td>\n",
       "      <td>113.58</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>828.333333</td>\n",
       "      <td>827.500000</td>\n",
       "      <td>829.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26117</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>811</td>\n",
       "      <td>811.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>114.65</td>\n",
       "      <td>50.85</td>\n",
       "      <td>117.76</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>829.500000</td>\n",
       "      <td>828.333333</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26118</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>818</td>\n",
       "      <td>818.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>138.07</td>\n",
       "      <td>56.62</td>\n",
       "      <td>140.78</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>829.500000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26119</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>820</td>\n",
       "      <td>820.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>123.47</td>\n",
       "      <td>47.24</td>\n",
       "      <td>145.19</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26120</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-06</td>\n",
       "      <td>822</td>\n",
       "      <td>822.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>102.19</td>\n",
       "      <td>39.96</td>\n",
       "      <td>119.58</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26121</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>823</td>\n",
       "      <td>823.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>92.82</td>\n",
       "      <td>42.18</td>\n",
       "      <td>102.91</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26122</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>825</td>\n",
       "      <td>825.0</td>\n",
       "      <td>59661</td>\n",
       "      <td>4040</td>\n",
       "      <td>2</td>\n",
       "      <td>105.62</td>\n",
       "      <td>50.09</td>\n",
       "      <td>106.92</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ZIP       date  confirmed_cases  new_confirmed_cases  \\\n",
       "26113  Woodland Hills 2020-08-30              795                795.0   \n",
       "26114  Woodland Hills 2020-08-31              801                801.0   \n",
       "26115  Woodland Hills 2020-09-01              806                806.0   \n",
       "26116  Woodland Hills 2020-09-02              809                809.0   \n",
       "26117  Woodland Hills 2020-09-03              811                811.0   \n",
       "26118  Woodland Hills 2020-09-04              818                818.0   \n",
       "26119  Woodland Hills 2020-09-05              820                820.0   \n",
       "26120  Woodland Hills 2020-09-06              822                822.0   \n",
       "26121  Woodland Hills 2020-09-07              823                823.0   \n",
       "26122  Woodland Hills 2020-09-08              825                825.0   \n",
       "\n",
       "       population  Density_Per_Sq_Mile  Income_level  driving  transit  \\\n",
       "26113       59661                 4040             2    99.56    40.99   \n",
       "26114       59661                 4040             2   103.50    48.34   \n",
       "26115       59661                 4040             2   106.30    48.42   \n",
       "26116       59661                 4040             2   109.09    49.16   \n",
       "26117       59661                 4040             2   114.65    50.85   \n",
       "26118       59661                 4040             2   138.07    56.62   \n",
       "26119       59661                 4040             2   123.47    47.24   \n",
       "26120       59661                 4040             2   102.19    39.96   \n",
       "26121       59661                 4040             2    92.82    42.18   \n",
       "26122       59661                 4040             2   105.62    50.09   \n",
       "\n",
       "       walking  retail_and_recreation_percent_change_from_baseline  \\\n",
       "26113   114.24                                              -29.0    \n",
       "26114   108.53                                              -28.0    \n",
       "26115   111.73                                              -26.0    \n",
       "26116   113.58                                              -27.0    \n",
       "26117   117.76                                              -25.0    \n",
       "26118   140.78                                              -26.0    \n",
       "26119   145.19                                              -33.0    \n",
       "26120   119.58                                              -34.0    \n",
       "26121   102.91                                              -29.0    \n",
       "26122   106.92                                              -27.0    \n",
       "\n",
       "       grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "26113                                              -12.0   \n",
       "26114                                              -14.0   \n",
       "26115                                              -10.0   \n",
       "26116                                              -11.0   \n",
       "26117                                               -9.0   \n",
       "26118                                               -7.0   \n",
       "26119                                               -8.0   \n",
       "26120                                              -14.0   \n",
       "26121                                              -12.0   \n",
       "26122                                              -11.0   \n",
       "\n",
       "       parks_percent_change_from_baseline  \\\n",
       "26113                                 6.0   \n",
       "26114                                 1.0   \n",
       "26115                                 4.0   \n",
       "26116                                 4.0   \n",
       "26117                                 1.0   \n",
       "26118                                 1.0   \n",
       "26119                               -13.0   \n",
       "26120                                -4.0   \n",
       "26121                                10.0   \n",
       "26122                                -4.0   \n",
       "\n",
       "       transit_stations_percent_change_from_baseline  \\\n",
       "26113                                          -40.0   \n",
       "26114                                          -42.0   \n",
       "26115                                          -40.0   \n",
       "26116                                          -41.0   \n",
       "26117                                          -40.0   \n",
       "26118                                          -40.0   \n",
       "26119                                          -43.0   \n",
       "26120                                          -46.0   \n",
       "26121                                          -55.0   \n",
       "26122                                          -42.0   \n",
       "\n",
       "       workplaces_percent_change_from_baseline  \\\n",
       "26113                                    -23.0   \n",
       "26114                                    -41.0   \n",
       "26115                                    -42.0   \n",
       "26116                                    -41.0   \n",
       "26117                                    -42.0   \n",
       "26118                                    -41.0   \n",
       "26119                                    -27.0   \n",
       "26120                                    -27.0   \n",
       "26121                                    -74.0   \n",
       "26122                                    -43.0   \n",
       "\n",
       "       residential_percent_change_from_baseline  ave_new7_10after  \\\n",
       "26113                                       6.0        824.000000   \n",
       "26114                                      13.0        825.750000   \n",
       "26115                                      14.0        827.500000   \n",
       "26116                                      14.0        828.333333   \n",
       "26117                                      14.0        829.500000   \n",
       "26118                                      13.0        830.000000   \n",
       "26119                                       8.0        830.000000   \n",
       "26120                                       6.0        830.000000   \n",
       "26121                                      20.0        830.000000   \n",
       "26122                                      14.0        830.000000   \n",
       "\n",
       "       ave_new6_9after  ave_new8_11after  \n",
       "26113       822.500000        825.750000  \n",
       "26114       824.000000        827.500000  \n",
       "26115       825.750000        828.333333  \n",
       "26116       827.500000        829.500000  \n",
       "26117       828.333333        830.000000  \n",
       "26118       829.500000        830.000000  \n",
       "26119       830.000000        830.000000  \n",
       "26120       830.000000        830.000000  \n",
       "26121       830.000000        830.000000  \n",
       "26122       830.000000        830.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_daily.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature table\n",
    "features = LA_daily[['ZIP','date','confirmed_cases','population', 'Income_level','driving','transit',\n",
    "                          'walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                          'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                          'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                          'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline']]\n",
    "features1 = features.groupby(['ZIP']).mean()\n",
    "features1.to_csv('features-{}.csv'.format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time series table\n",
    "time_series = features.pivot(index = 'ZIP', columns = 'date', values = ['confirmed_cases','population', 'Income_level','driving','transit',\n",
    "                          'walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                          'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                          'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                          'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline'])\n",
    "time_series = time_series.fillna(0)\n",
    "time_series.to_csv('timeseries-{}.csv'.format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_daily.py\n",
    "\"\"\"    super parameter     \"\"\"\n",
    "day_input = 6                      # how many days' feature we use to predict\n",
    "timelagging = 6                     # the length of latent window of Social Distancing data & Mobility data\n",
    "average_num = 4                     # how many days does the average cases get from\n",
    "feature_num = 14+2*(day_input-1)    # the number of feature that one input contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_daily.py\n",
    "#from parameter_daily import day_input, average_num, feature_num, timelagging\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, input, output):\n",
    "        super(Mydataset, self).__init__()\n",
    "        self.input = input\n",
    "        self.lable = output\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index], self.lable[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "\"\"\"    read daily data in and clean!     \"\"\"\n",
    "def dataset_generate_daily():\n",
    "#     filename = \"LA_daily.csv\"\n",
    "    community_daily = LA_daily.copy()\n",
    "#     pd.read_csv(filename, encoding=\"ISO-8859-1\", dtype={'ZIP': str, 'date': str})\n",
    "    community = community_daily['ZIP']  # 'ZIP' column\n",
    "    date = community_daily['date']  # we have to preserve the date\n",
    "    del community_daily['ZIP']  # delete the non-numeric columns\n",
    "    del community_daily['date']\n",
    "    community_daily = pd.DataFrame(community_daily, dtype=float)  # change the type from 'int' to 'float'\n",
    "    community_daily['ZIP'] = community  # add the 'ZIP' column again\n",
    "    \n",
    "    # key: 'community', value: feature that belong to the 'community'\n",
    "    data_dict = {}\n",
    "    for i, community in enumerate(community_daily[:]['ZIP']):\n",
    "        if community not in data_dict:\n",
    "            data_dict[community] = []\n",
    "        feature = []\n",
    "        for f in community_daily.iloc[i]:\n",
    "            feature.append(f)\n",
    "        data_dict[community].append(feature)\n",
    "\n",
    "    data_x = []  # input\n",
    "    data_y = []  # lable\n",
    "    for key, values in data_dict.items():\n",
    "        l = len(values)\n",
    "        input_num = l - timelagging - average_num  # determine how many input here\n",
    "        feature = []\n",
    "        for i in range(input_num):  # one input point contains 6 days's data, that is day1~day6\n",
    "            first = True\n",
    "            for j in range(day_input):\n",
    "                if first:  # one input point contains all the feature of day1\n",
    "                    for k in values[i][:-4]:\n",
    "                        feature.append(k)\n",
    "                    first = False\n",
    "                else:  # for day2~day6, one input point only contains confirmed_cases & new_confirmed_cases\n",
    "                    feature.append(values[i + j][0])\n",
    "                    feature.append(values[i + j][1])\n",
    "            data_y.append(values[i][-4])  # output: average cases, that is ave_new7_10after\n",
    "            tmp = []\n",
    "            tmp.append(feature)\n",
    "            data_x.append(tmp)  # size: [1, feature_num]\n",
    "            feature = []\n",
    "    # split data to train and test, and split test to validation and test in the following.\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(data_x, data_y, test_size=0.3,\n",
    "                                                                        random_state=1)\n",
    "\n",
    "    train_x_ls = []  # Change the format for later processing\n",
    "    for j in train_x:\n",
    "        for i in j:\n",
    "            train_x_ls.append(i)\n",
    "    train_x_df = pd.DataFrame(train_x_ls)\n",
    "    train_y_df = pd.DataFrame(train_y)\n",
    "    \n",
    "    #standardize input data\n",
    "    train_x_mean = train_x_df.mean()  # train_x dataset mean\n",
    "    train_x_std = train_x_df.std()  # train_x dataset std\n",
    "    train_y_mean = train_y_df.mean()  # train_y dataset mean\n",
    "    train_y_std = train_y_df.std()  # train_y dataset std\n",
    "\n",
    "    for i in range(len(train_x)):       # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(train_x[i])):\n",
    "            for k in range(len(train_x[i][j])):\n",
    "                train_x[i][j][k] = (train_x[i][j][k] - train_x_mean[k]) / train_x_std[k]\n",
    "\n",
    "    for i in range(len(train_y)):       # using train_y mean and train_y std to normalize\n",
    "        train_y[i] = (train_y[i] - train_y_mean) / train_y_std\n",
    "\n",
    "    for i in range(len(test_x)):        # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(test_x[i])):\n",
    "            for k in range(len(test_x[i][j])):\n",
    "                test_x[i][j][k] = (test_x[i][j][k] - train_x_mean[k]) / train_x_std[k]\n",
    "\n",
    "    for i in range(len(test_y)):        # using train_y mean and train_y std to normalize\n",
    "        test_y[i] = (test_y[i] - train_y_mean) / train_y_std\n",
    "\n",
    "        \n",
    "    # split test to validation and test\n",
    "    validation_x, test_x, validation_y, test_y = model_selection.train_test_split(test_x, test_y, test_size=0.5,\n",
    "                                                                                  random_state=1)\n",
    "    train_x = torch.tensor(train_x)\n",
    "    train_y = torch.tensor(train_y).reshape(-1, 1)\n",
    "    validation_x = torch.tensor(validation_x)\n",
    "    validation_y = torch.tensor(validation_y).reshape(-1, 1)\n",
    "    test_x = torch.tensor(test_x)\n",
    "    test_y = torch.tensor(test_y).reshape(-1, 1)\n",
    "\n",
    "    # define dataset\n",
    "    train_data = Mydataset(train_x, train_y)\n",
    "    trainloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "\n",
    "    return trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "           test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function.py\n",
    "\n",
    "\"\"\"     scale the output value back to its original size and cal the loss   \"\"\"\n",
    "def loss_cal(predict, lable, train_mean, train_std):\n",
    "    x = predict[:]\n",
    "    y = lable[:]\n",
    "    for i in range(len(predict)):\n",
    "        x[i][0] = x[i][0] * torch.tensor(train_std) + torch.tensor(train_mean)\n",
    "        y[i][0] = y[i][0] * torch.tensor(train_std) + torch.tensor(train_mean)\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    loss = loss_fun(x, y)\n",
    "    return loss, x, y\n",
    "\n",
    "\"\"\"     change the learning rate   \"\"\"\n",
    "def adjust_learning_rate(optimizer, learning_r=None):\n",
    "    i = 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_r\n",
    "        if i == 0:\n",
    "            print(\"optimizer lr : {}\".format(param_group['lr']))\n",
    "            i += 1\n",
    "\n",
    "\n",
    "\"\"\"     define LSTM model   \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, feature_num):\n",
    "        super(Net, self).__init__()\n",
    "        # if batch_first=True, then input shape = (batch, seq, shape)\n",
    "        self.lstm = torch.nn.LSTM(input_size=feature_num, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(64 * 1, 32)\n",
    "        self.linear1 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(-1, 64 * 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_daily.py\n",
    "\n",
    "#from dataset_daily import dataset_generate_daily\n",
    "#from function import loss_cal, adjust_learning_rate, Net\n",
    "#from parameter_daily import feature_num\n",
    "\n",
    "def train_daily():\n",
    "    \"\"\"         \n",
    "    train a LSTM model with the daily dataset\n",
    "    return: train_loss_info, val_loss_info\n",
    "    \"\"\"\n",
    "    trainloader, train_x, train_y, validation_x, validation_y, test_x, test_y, \\\n",
    "    train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate_daily()\n",
    "\n",
    "    \"\"\"         training start!         \"\"\"\n",
    "    # determine optimizer, loss_function and checkpoint path\n",
    "    model = Net(feature_num)\n",
    "    learning_r = 0.0002\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_r)\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    path = 'checkpoint_latest.tar'\n",
    "\n",
    "    \"\"\" if you want train your model from a pre-trained model, uncomment the following code. \"\"\"\n",
    "    # checkpoint = torch.load(path)\n",
    "    # model.load_state_dict(checkpoint['net'])\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # validation_loss = checkpoint['best_validation_loss']\n",
    "    # learning_r = 6.400000000000004e-8\n",
    "\n",
    "    model.train()\n",
    "    # val_loss_info = [validation_loss]\n",
    "    val_loss_info = []      # preserve every epoch's train loss\n",
    "    train_loss_info = []    # preserve every epoch's validation loss\n",
    "    not_improve = 0\n",
    "    for epoch in range(1500):\n",
    "        for i, values in enumerate(trainloader):\n",
    "            input, lable = values\n",
    "            output = model(input)\n",
    "            loss = loss_fun(output, lable)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0 and epoch > 0:\n",
    "            train_loss = loss_fun(model(train_x),train_y).item()\n",
    "            vali_loss = loss_fun(model(validation_x), validation_y).item()\n",
    "            if len(val_loss_info) == 0 or vali_loss < min(val_loss_info):  # save the best model\n",
    "                not_improve = 0\n",
    "                state = {'net': model.state_dict(), 'optimizer': optimizer.state_dict(),'best_validation_loss': vali_loss}\n",
    "                torch.save(state, path)\n",
    "                print(\"Saved the model.\")\n",
    "            else:                           # if validation loss didn't decrease, reload the best model in next epoch.\n",
    "                checkpoint = torch.load(path)\n",
    "                model.load_state_dict(checkpoint['net'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                not_improve += 1\n",
    "                print(\"not_improve : {}\".format(not_improve))\n",
    "            if (not_improve+1) % 8 == 0:    # when validation loss doesn't decrease for 7 epochs, reduce the learning rate.\n",
    "                learning_r *= 0.2\n",
    "                adjust_learning_rate(optimizer, learning_r)\n",
    "            if (not_improve+1) % 25 == 0:   # early stopping\n",
    "                print(\"Training End......\")\n",
    "                break\n",
    "\n",
    "            print(\"epoch:{}, train_loss:{}, vali_loss: {}\".format(epoch, train_loss, vali_loss))\n",
    "            train_loss_info.append(train_loss)\n",
    "            val_loss_info.append(vali_loss)\n",
    "\n",
    "    return train_loss_info, val_loss_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_daily.py\n",
    "\n",
    "def test_daily(path, test_x, test_y, train_mean, train_std):\n",
    "    \"\"\"\n",
    "    test the LSTM model with the daily dataset\n",
    "    arg:path, test_x, test_y, train_mean, train_std\n",
    "    no return\n",
    "    \"\"\"\n",
    "    \"\"\"     test start!     \"\"\"\n",
    "    # using the test dataset to test model\n",
    "    model = Net(feature_num)\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    model.eval()\n",
    "    predict = model(test_x)\n",
    "    real = test_y.clone()\n",
    "\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    # two losses, one is normalized scale, another is original scale\n",
    "    loss = loss_fun(predict, real)\n",
    "    loss_original_scale, pre, rea = loss_cal(predict, real, train_mean, train_std)\n",
    "    pre = np.array(pre.data)\n",
    "    rea = np.array(rea.data)\n",
    "    print(\"Test loss: \" + str(loss))\n",
    "    print(\"Test loss in original scale: \" + str(loss_original_scale))\n",
    "\n",
    "    # true output and predicted output\n",
    "    plt.figure(2)\n",
    "    plt.plot(list(rea), label=\"real\")\n",
    "    plt.plot(list(pre), label=\"pred\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # true output and predicted output\n",
    "    plt.figure(3)\n",
    "    min_val = min(rea)\n",
    "    max_val = max(rea)\n",
    "    plt.scatter(rea,pre)\n",
    "    plt.plot([min_val,max_val],[min_val,max_val],color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\"\"\"\n",
    "\n",
    "In this project, We created a LSTM model to predict covid-19 daily new_cases and weekly new cases in Los Angeles.\n",
    "\n",
    "If you find anything wrong with the code, please feel free to contact us.\n",
    "\n",
    "@University: Umich & ZJU\n",
    "@author: Wenxue Li, Zixian Ma, Xinyu Li\n",
    "@email: liwenxue@zju.edu.cn, 3170103467@zju.edu.cn\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from dataset_daily import dataset_generate_daily\n",
    "from dataset_weekly import dataset_generate\n",
    "from train_daily import train_daily\n",
    "from train_weekly import train_weekly\n",
    "from test_daily import test_daily\n",
    "from test_weekly import test_weekly\n",
    "\"\"\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description='COVID-LSTM')\n",
    "parser.add_argument('--mode', default='train', type=str, help='choose train or test')\n",
    "parser.add_argument('--type', default='daily', type=str, help='daily or weekly')\n",
    "\n",
    "args = parser.parse_args(args=[]) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the model.\n",
      "epoch:10, train_loss:0.005843961611390114, vali_loss: 0.005166829098016024\n",
      "Saved the model.\n",
      "epoch:20, train_loss:0.002508261241018772, vali_loss: 0.0024153701961040497\n",
      "Saved the model.\n",
      "epoch:30, train_loss:0.0017948390450328588, vali_loss: 0.001741946442052722\n",
      "Saved the model.\n",
      "epoch:40, train_loss:0.001298174262046814, vali_loss: 0.0012627231189981103\n",
      "Saved the model.\n",
      "epoch:50, train_loss:0.0010059882188215852, vali_loss: 0.001026064739562571\n",
      "Saved the model.\n",
      "epoch:60, train_loss:0.0008141539292410016, vali_loss: 0.0008180928998626769\n",
      "Saved the model.\n",
      "epoch:70, train_loss:0.0007029705448076129, vali_loss: 0.000686804938595742\n",
      "Saved the model.\n",
      "epoch:80, train_loss:0.0006723910919390619, vali_loss: 0.0006434667157009244\n",
      "not_improve : 1\n",
      "epoch:90, train_loss:0.0009007255430333316, vali_loss: 0.0008401805534958839\n",
      "Saved the model.\n",
      "epoch:100, train_loss:0.0006128924433141947, vali_loss: 0.0005794469034299254\n",
      "Saved the model.\n",
      "epoch:110, train_loss:0.0005968789337202907, vali_loss: 0.000557797378860414\n",
      "not_improve : 1\n",
      "epoch:120, train_loss:0.0006231960724107921, vali_loss: 0.0005767182447016239\n",
      "Saved the model.\n",
      "epoch:130, train_loss:0.0006011301302351058, vali_loss: 0.0005518569960258901\n",
      "Saved the model.\n",
      "epoch:140, train_loss:0.000598477607127279, vali_loss: 0.000551559787709266\n",
      "Saved the model.\n",
      "epoch:150, train_loss:0.0005591531516984105, vali_loss: 0.0005133338272571564\n",
      "not_improve : 1\n",
      "epoch:160, train_loss:0.0005548658082261682, vali_loss: 0.0005133347003720701\n",
      "Saved the model.\n",
      "epoch:170, train_loss:0.000554276630282402, vali_loss: 0.0005062361597083509\n",
      "not_improve : 1\n",
      "epoch:180, train_loss:0.0006883656024001539, vali_loss: 0.000636377080809325\n",
      "not_improve : 2\n",
      "epoch:190, train_loss:0.0006365528097376227, vali_loss: 0.0005830475711263716\n",
      "not_improve : 3\n",
      "epoch:200, train_loss:0.0007036817260086536, vali_loss: 0.0006460926379077137\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "if args.mode == 'train':\n",
    "    if args.type == 'daily':\n",
    "        train_loss_info, val_loss_info = train_daily()\n",
    "        # training loss trend and validation loss trend\n",
    "        plt.figure(1)\n",
    "        plt.plot(train_loss_info, label='train_loss')\n",
    "        plt.plot(val_loss_info, label='val_loss')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "    if args.type == 'weekly':\n",
    "        train_loss_info, val_loss_info = train_weekly()\n",
    "        # training loss trend and validation loss trend\n",
    "        plt.figure(1)\n",
    "        plt.plot(train_loss_info, label='train_loss')\n",
    "        plt.plot(val_loss_info, label='val_loss')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing model\n",
    "if args.mode == 'test':\n",
    "    if args.type == 'daily':\n",
    "        trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "        test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate_daily()\n",
    "        # path = 'checkpoint_1.tar'\n",
    "        path = 'checkpoint_daily.tar'\n",
    "        test_daily(path, test_x, test_y, train_y_mean, train_y_std)\n",
    "    if args.type == 'weekly':\n",
    "        # path = 'checkpoint_2.tar'\n",
    "        path = 'checkpoint_weekly_sequential.tar'\n",
    "        trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "        test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate()\n",
    "        test_weekly(path, test_x, test_y, train_y_mean, train_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_predict_4_day_avg.py\n",
    "# This part is to predict number of new cases\n",
    "\n",
    "day_input = 6\n",
    "timelagging = 6\n",
    "average_num = 4\n",
    "feature_num = 14+2*(day_input-1)\n",
    "\n",
    "def predict_dataset_daily():\n",
    "    \"\"\" \n",
    "    read in data and process, this part is very similar to lstm_1.py  \n",
    "    return:community,data_x,data_x_mean,data_x_std,date_list_new\n",
    "    \"\"\"\n",
    "    # filename = \"LA_daily_predict.csv\"\n",
    "    community_daily = LA_daily_predict.copy()\n",
    "    # pd.read_csv(filename, encoding=\"ISO-8859-1\", dtype={'ZIP': str, 'date': str})\n",
    "    community = community_daily['ZIP']\n",
    "    date = community_daily['date']  # we have to preserve the date\n",
    "    del community_daily['ZIP']\n",
    "    del community_daily['date']\n",
    "    community_daily = pd.DataFrame(community_daily, dtype=float)  # change the type from 'int' to 'float'\n",
    "    community_daily['ZIP'] = community\n",
    "    community_daily['date'] = date  # add date back\n",
    "\n",
    "    data_dict = {}  # key: 'community', value: feature that belong to the key\n",
    "    for i, community in enumerate(community_daily[:]['ZIP']):\n",
    "        if community not in data_dict:\n",
    "            data_dict[community] = []\n",
    "        feature = []\n",
    "        for f in community_daily.iloc[i]:\n",
    "            feature.append(f)\n",
    "        data_dict[community].append(feature)\n",
    "\n",
    "    community = []  # save 'community' correlating to input point\n",
    "    date = []     # save 'date' correlating to input point\n",
    "\n",
    "    data_x = []  # input\n",
    "    for key, values in data_dict.items():\n",
    "        l = len(values)\n",
    "        input_num = l - timelagging - average_num\n",
    "        feature = []\n",
    "        input_num=input_num+5\n",
    "        for i in range(input_num):\n",
    "            first = True\n",
    "            for j in range(day_input):\n",
    "                if first:\n",
    "                    community.append(values[i][-2])   # save 'community' correlating to ont input point\n",
    "                    date.append(values[i][-1])      # save 'date' correlating to ont input point\n",
    "                    # because we add 'date' back, the last feature is values[i][:-5] not values[i][:-4]\n",
    "                    for k in values[i][:-3]:\n",
    "                        feature.append(k)\n",
    "                    first = False\n",
    "                else:\n",
    "                    feature.append(values[i + j][0])\n",
    "                    feature.append(values[i + j][1])\n",
    "            tmp = []\n",
    "            tmp.append(feature)\n",
    "            data_x.append(tmp)  # one input point\n",
    "            feature = []\n",
    "\n",
    "    data_x_ls = []\n",
    "    for j in data_x:\n",
    "        for i in j:\n",
    "            data_x_ls.append(i)\n",
    "    data_x_df = pd.DataFrame(data_x_ls)\n",
    "    data_x_mean = data_x_df.mean()  # train dataset mean\n",
    "    data_x_std = data_x_df.std()    # train dataset std\n",
    "\n",
    "    for i in range(len(data_x)):    # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(data_x[i])):\n",
    "            for k in range(len(data_x[i][j])):\n",
    "                data_x[i][j][k] = (data_x[i][j][k] - data_x_mean[k]) / data_x_std[k]\n",
    "\n",
    "    data_x = torch.tensor(data_x)\n",
    "\n",
    "    date_list_new = []\n",
    "    for date_ in date:\n",
    "        date_start = (date_+datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "        date_end = (date_+datetime.timedelta(days=9)).strftime(\"%Y-%m-%d\")\n",
    "        date_list_new.append(date_start+' - ' + date_end)\n",
    "    return community,data_x,data_x_mean,data_x_std,date_list_new\n",
    "\n",
    "community,data_x,data_x_mean,data_x_std,date_list_new = predict_dataset_daily()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     scale the output value back to its original size and cal the loss   \"\"\"\n",
    "def upscale(predict,data_x_std,data_x_mean):\n",
    "    x = predict[:]\n",
    "    for i in range(len(predict)):\n",
    "        x[i][0] = x[i][0] * torch.tensor(data_x_std[1]) + torch.tensor(data_x_mean[1])\n",
    "    return x\n",
    "\n",
    "\"\"\"     define LSTM model   \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # if batch_first=True, then input shape = (batch, seq, shape)\n",
    "        self.lstm = torch.nn.LSTM(input_size=feature_num, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(64 * 1, 32)\n",
    "        self.linear1 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(-1, 64 * 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "path = 'checkpoint_latest.tar'\n",
    "# load from file\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "predict = np.array(model(data_x).data)  # output\n",
    "predict_upscale = upscale(predict,data_x_std,data_x_mean)      # original scale output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processOutput(community,date_list_new,predict_upscale):\n",
    "    \"\"\"\n",
    "    Organize the output dataframe\n",
    "    arg: Region name, Timestamp, Predicted new cases\n",
    "    return: an output dataframe with risk score\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame()                            # generate table\n",
    "    out['Region'] = community                            # zip code column\n",
    "    out['Timestamp'] = date_list_new    # date column\n",
    "    out['Predicted new cases'] = predict_upscale     # predicted new cases columns\n",
    "    out['Risk_score_level']=None\n",
    "    # read population data\n",
    "    url5=\"https://raw.githubusercontent.com/skasralikar/Risk-Score-1-UMichZJU/master/data/input/LApopulation.csv\"\n",
    "    pop = pd.read_csv(url5, index_col = False)  # population data\n",
    "    # calculate the risk score\n",
    "    # risk score=Predicted new cases*10000/population size\n",
    "    for i in range(out.shape[0]):\n",
    "        for j in range(pop.shape[0]):\n",
    "            if (out.at[i,'Region'] == pop.at[j,'ZIP']):\n",
    "                out.at[i,'Risk_score'] = 10000 * out.at[i,'Predicted new cases'] / pop.at[j,'population']\n",
    "\n",
    "    # delete the col 'predicted new cases'\n",
    "    out=out.drop(columns=['Predicted new cases'])\n",
    "    # set the first day of predicted period as 'Timestamp'\n",
    "    for i in range(len(out)):\n",
    "        out.loc[i,'Timestamp']=out.loc[i,'Timestamp'][0:11]\n",
    "    return out\n",
    "\n",
    "def riskScoreLevel(out):\n",
    "    \"\"\"\n",
    "    defind the risk score level\n",
    "    return: output dataframe with risk score level\n",
    "    \"\"\"\n",
    "    # -1-no data\n",
    "    # 0-very low level(risk score <=0.1)\n",
    "    # 1-low level(0.1<risk score <=1)\n",
    "    # 2-medium level(1<risk score <=2)\n",
    "    # 3-high level(risk score >2)\n",
    "    for i in range(len(out)):\n",
    "        if out['Risk_score'][i]<=0.1:\n",
    "            out.loc[i,'Risk_score_level']=0\n",
    "        elif out['Risk_score'][i]<=1:\n",
    "            out.loc[i,'Risk_score_level']=1\n",
    "        elif out['Risk_score'][i]<=2:\n",
    "            out.loc[i,'Risk_score_level']=2\n",
    "        else:\n",
    "            out.loc[i,'Risk_score_level']=3\n",
    "    return out\n",
    "\n",
    "out0=processOutput(community,date_list_new,predict_upscale)\n",
    "out=riskScoreLevel(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Risk_score_level</th>\n",
       "      <th>Risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.587520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.030156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>-22.628911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.349784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.503235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.058620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>-30.371915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-32.020903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.875444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region    Timestamp  Risk_score_level  Risk_score\n",
       "0  Acton  2020-04-09                  0  -24.587520\n",
       "1  Acton  2020-04-10                  0  -26.030156\n",
       "2  Acton  2020-04-11                  0  -22.628911\n",
       "3  Acton  2020-04-12                  0  -23.349784\n",
       "4  Acton  2020-04-13                  0  -18.503235\n",
       "5  Acton  2020-04-14                  0  -18.058620\n",
       "6  Acton  2020-04-15                  0  -30.371915\n",
       "7  Acton  2020-04-16                  0  -32.020903\n",
       "8  Acton  2020-04-17                  0  -26.015557\n",
       "9  Acton  2020-04-18                  0  -16.875444"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Risk_score_level</th>\n",
       "      <th>Risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Acton</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>24.049134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Agoura Hills</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>40.563168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Alhambra</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>97.892535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Altadena</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>94.688988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>49.960868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Arleta</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>292.238128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Avalon</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-65.012227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Azusa</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>218.980180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Baldwin Hills</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>127.742886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>3</td>\n",
       "      <td>242.552597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Region    Timestamp  Risk_score_level  Risk_score\n",
       "109           Acton  2020-08-01                  3   24.049134\n",
       "251    Agoura Hills  2020-08-01                  3   40.563168\n",
       "400        Alhambra  2020-08-01                  3   97.892535\n",
       "546        Altadena  2020-08-01                  3   94.688988\n",
       "695         Arcadia  2020-08-01                  3   49.960868\n",
       "835          Arleta  2020-08-01                  3  292.238128\n",
       "887          Avalon  2020-08-01                  0  -65.012227\n",
       "1026          Azusa  2020-08-01                  3  218.980180\n",
       "1174  Baldwin Hills  2020-08-01                  3  127.742886\n",
       "1308   Baldwin Park  2020-08-01                  3  242.552597"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_output\n",
    "Aug01=out.loc[out['Timestamp']=='2020-08-01 ']\n",
    "Aug01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('LA-daily-out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
