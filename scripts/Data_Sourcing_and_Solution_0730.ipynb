{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (1.18.1)\n",
      "Wall time: 3.09 s\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Wall time: 1.93 s\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Wall time: 2.05 s\n",
      "Requirement already satisfied: sklearn in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Wall time: 2.12 s\n",
      "Collecting datetime\n",
      "  Downloading https://files.pythonhosted.org/packages/73/22/a5297f3a1f92468cc737f8ce7ba6e5f245fcfafeae810ba37bd1039ea01c/DateTime-4.3-py2.py3-none-any.whl (60kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from datetime) (2019.3)\n",
      "Collecting zope.interface\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/f9/af181babed312b9e21271dbfd7ec0815f822a12aaa2fe472d98e62e5bac3/zope.interface-5.1.0-cp37-cp37m-win_amd64.whl (194kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (from zope.interface->datetime) (46.1.3)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "Successfully installed datetime-4.3 zope.interface-5.1.0\n",
      "Wall time: 5.05 s\n",
      "Requirement already satisfied: argparse in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (1.4.0)\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "import sys\n",
    "%time  !{sys.executable} -m pip install numpy\n",
    "%time  !{sys.executable} -m pip install pandas\n",
    "%time  !{sys.executable} -m pip install matplotlib\n",
    "%time  !{sys.executable} -m pip install sklearn\n",
    "%time  !{sys.executable} -m pip install datetime\n",
    "%time  !{sys.executable} -m pip install argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages (1.0.1)\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "# method 1 to install 'torch'\n",
    "%time  !{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 to install 'torch'\n",
    "!pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read database about the confirmed cases and try to filter out the area\n",
    "import pandas as pd\n",
    "import datetime\n",
    "url=\"https://raw.githubusercontent.com/datadesk/california-coronavirus-data/master/latimes-place-totals.csv\"\n",
    "df = pd.read_csv(url,header=0)\n",
    "df = df[df['county']=='Los Angeles'][['date','place','confirmed_cases']]\n",
    "\n",
    "target = ['Alhambra', 'Arcadia', 'Beverly Hills', 'Boyle Heights', 'Carson', 'Diamond Bar', 'Encino', 'Gardena', 'Glendale', 'Glendora',\n",
    "          'Granada Hills', 'Inglewood', 'La Mirada', 'Lancaster', 'Manhattan Beach', 'Melrose', 'Northridge', 'San Dimas', 'San Pedro',\n",
    "          'Santa Monica', 'Sherman Oaks', 'Silver Lake', 'Tarzana', 'Torrance', 'Venice', 'West Adams', 'West Hills', 'West Hollywood',\n",
    "          'West Vernon', 'Westchester', 'Altadena', 'Baldwin Hills', 'Brentwood', 'Culver City', 'Eagle Rock', 'Hollywood',\n",
    "          'Hollywood Hills', 'Lynwood', 'Mar Vista', 'Monterey Park', 'North Hollywood', 'Reseda', 'Santa Clarita', 'Woodland Hills',\n",
    "          'Sylmar', 'Walnut', 'Beverlywood', 'Burbank', 'Calabasas', 'Castaic', 'Covina', 'Crestview', 'East Los Angeles', 'Echo Park', \n",
    "          'Hancock Park', 'Hawthorne', 'Lawndale', 'Lomita', 'Palms', 'Playa Vista', 'South El Monte', 'Stevenson Ranch', 'Studio City',\n",
    "          'Tujunga', 'University Park', 'Valley Glen', 'Van Nuys', 'Vermont Knolls', 'Westwood', 'Whittier', 'Century City', 'El Segundo',\n",
    "          'Lake Balboa', 'Lakewood', 'Miracle Mile', 'Park La Brea', 'Redondo Beach', 'San Fernando', 'South Whittier', 'Winnetka', \n",
    "          'Del Rey', 'La Canada Flintridge', 'La Verne', 'Montebello', 'Sun Valley', 'Sunland', 'Vermont Vista', 'Vernon Central',\n",
    "          'West Covina', 'Westlake', 'Bellflower', 'Canoga Park', 'East Hollywood', 'Los Feliz', 'Paramount', 'Rancho Palos Verdes', \n",
    "          'South Gate', 'Agoura Hills', 'Duarte', 'Exposition Park', 'Hyde Park', 'Lincoln Heights', 'Palmdale', 'South Park',\n",
    "          'Wilshire Center', 'Canyon Country', 'Claremont', 'Downey', 'Harbor Gateway', 'Harvard Heights', 'Highland Park', \n",
    "          'La Puente', 'Norwalk', 'Pico Rivera', 'Porter Ranch', 'San Gabriel', 'Wholesale District', 'Willowbrook', 'Arleta',\n",
    "          'Bell Gardens', 'Glassell Park', 'Panorama City', 'Pomona', 'Valinda', 'Watts', 'Azusa', 'Bell', 'Chatsworth', \n",
    "          'Hacienda Heights', 'Harbor City', 'Leimert Park', 'Maywood', 'Monrovia', 'North Hills', 'Pacoima', 'Avalon', 'Baldwin Park',\n",
    "          'Bassett', 'Central', 'El Monte', 'El Sereno', 'Harvard Park', 'Lake Los Angeles', 'Rosemead', 'Rowland Heights', 'Temple City',\n",
    "          'Acton', 'Cerritos', 'Cloverdale/Cochran', 'Compton', 'Downtown', 'Huntington Park', 'Koreatown', 'Mt. Washington', 'Pasadena', \n",
    "          'South Pasadena', 'Wilmington']\n",
    "\n",
    "df = df[df['place'].isin(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Data Type \n",
    "result = df.copy()\n",
    "result['place'].replace('Silver Lake','Silverlake',inplace = True)\n",
    "result['date'] = pd.to_datetime(result['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add New Columns\n",
    "result = result.sort_values(by=['place','date'])\n",
    "result['new_confirmed_cases'] = result['confirmed_cases']\n",
    "result['ave_new7_10after'] = result['confirmed_cases']\n",
    "result['ave_new6_9after'] = result['confirmed_cases']\n",
    "result['ave_new8_11after'] = result['confirmed_cases']\n",
    "result.iloc[0,3] = None\n",
    "\n",
    "# Calculate Daily New Cases\n",
    "for i in range(1,len(result)):\n",
    "    if result.iloc[i,1] != result.iloc[(i-1),1]:\n",
    "        result.iloc[i,3] = None\n",
    "    else:\n",
    "        result.iloc[i,3] = max([0,int(result.iloc[i,2])-int(result.iloc[(i-1),2])])    \n",
    "# Calculate Future Cases in AVG\n",
    "for i in range(1,len(result)):    \n",
    "    if i < (len(result)-11):\n",
    "        if result.iloc[i,1] == result.iloc[(i+11),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3] + result.iloc[(i+11),3])/4.0\n",
    "        elif result.iloc[i,1] == result.iloc[(i+10),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/3.0\n",
    "        elif result.iloc[i,1] == result.iloc[(i+9),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/3.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3])/2.0\n",
    "        elif result.iloc[i,1] == result.iloc[(i+8),1]:\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3])/2.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3])/3.0\n",
    "            result.iloc[i,6] = result.iloc[(i+8),3]\n",
    "        elif result.iloc[i,1] == result.iloc[(i+7),1]:\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3])/2.0\n",
    "            result.iloc[i,6] = result.iloc[i,4] = result.iloc[(i+7),3]\n",
    "        else:\n",
    "            for j in range(8):\n",
    "                if result.iloc[i,1] == result.iloc[(i+7-j),1]:\n",
    "                    result.iloc[i,4] = result.iloc[i,5] = result.iloc[i,6] = result.iloc[(i+7-j),3]\n",
    "                    break\n",
    "    else:\n",
    "        if i < (len(result)-10):\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/4.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3] + result.iloc[(i+10),3])/3.0\n",
    "        elif i < (len(result)-9):\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/3.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3] + result.iloc[(i+9),3])/4.0\n",
    "            result.iloc[i,6] = (result.iloc[(i+8),3] + result.iloc[(i+9),3])/2.0\n",
    "        elif i < (len(result)-8):\n",
    "            result.iloc[i,4] = (result.iloc[(i+7),3] + result.iloc[(i+8),3])/2.0\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3] + result.iloc[(i+8),3])/3.0\n",
    "            result.iloc[i,6] = result.iloc[(i+8),3]\n",
    "        elif i < (len(result)-7):\n",
    "            result.iloc[i,5] = (result.iloc[(i+6),3] + result.iloc[(i+7),3])/2.0\n",
    "            result.iloc[i,6] = result.iloc[i,4] = result.iloc[(i+7),3]\n",
    "        else:          \n",
    "            result.iloc[i,4] = result.iloc[i,5] = result.iloc[i,6] = result.iloc[-1,3]\n",
    "\n",
    "result.dropna(inplace = True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\pycharmprojects\\test1\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2718: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read Mobility Data\n",
    "\n",
    "url2= \"https://covid19-static.cdn-apple.com/covid19-mobility-data/2013HotfixDev8/v3/en-us/applemobilitytrends-2020-07-25.csv\"\n",
    "apple_mobility = pd.read_csv(url2,header=0)\n",
    "\n",
    "url3 = \"https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv?cachebust=04188f017409e90a\"\n",
    "google_mobility = pd.read_csv(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit Mobility Data for Merging\n",
    "apple_mobility = apple_mobility[apple_mobility['region']=='Los Angeles']\n",
    "google_mobility = google_mobility[google_mobility['sub_region_2'] == 'Los Angeles County']\n",
    "\n",
    "amobility= apple_mobility.copy()\n",
    "amobility = amobility.set_index('transportation_type').transpose().iloc[5:]\n",
    "\n",
    "amobility['date'] = pd.to_datetime(amobility.index)\n",
    "\n",
    "gmobility = google_mobility[['date','retail_and_recreation_percent_change_from_baseline',\n",
    "                       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                       'parks_percent_change_from_baseline',\n",
    "                       'transit_stations_percent_change_from_baseline',\n",
    "                       'workplaces_percent_change_from_baseline',\n",
    "                       'residential_percent_change_from_baseline',]].copy()\n",
    "gmobility['date'] = pd.to_datetime(google_mobility['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Modify Econ Data\n",
    "url4 = \"https://raw.githubusercontent.com/skasralikar/Risk-Score-1-UMichZJU/master/data/econ_level.csv\"\n",
    "econ = pd.read_csv(url4, index_col = 0)\n",
    "econ.columns = ['place','Density_Per_Sq_Mile','population','Income_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Mobility Data\n",
    "final = result.merge(amobility,how = 'left',on = 'date')\n",
    "final_result = final.merge(gmobility,how = 'left',on = 'date')\n",
    "final_result.dropna(inplace = True)\n",
    "\n",
    "# Merge Econ Data\n",
    "final_results = final_result.merge(econ, how = 'left', on = 'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['ZIP'] = final_results['place']\n",
    "final_results['ZIP'].astype(str)\n",
    "final_results['date'].astype(str)\n",
    "\n",
    "LA_daily = final_results[['ZIP','date','confirmed_cases','new_confirmed_cases','population','Density_Per_Sq_Mile','Income_level','driving','transit',\n",
    "                          'walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                          'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                          'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                          'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline',\n",
    "                          'ave_new7_10after','ave_new6_9after','ave_new8_11after']]\n",
    "\n",
    "LA_daily_predict = final_results[['ZIP','date','confirmed_cases','new_confirmed_cases','population','Density_Per_Sq_Mile','Income_level','driving',\n",
    "                                  'transit','walking','retail_and_recreation_percent_change_from_baseline',\n",
    "                                  'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                                  'parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline',\n",
    "                                  'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline',\n",
    "                                  'ave_new7_10after']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZIP       date  confirmed_cases  new_confirmed_cases  population  \\\n",
      "0  Acton 2020-04-03                1                  0.0        6522   \n",
      "1  Acton 2020-04-04                1                  0.0        6522   \n",
      "2  Acton 2020-04-05                1                  0.0        6522   \n",
      "3  Acton 2020-04-06                1                  0.0        6522   \n",
      "4  Acton 2020-04-07                1                  0.0        6522   \n",
      "5  Acton 2020-04-08                1                  0.0        6522   \n",
      "6  Acton 2020-04-09                1                  0.0        6522   \n",
      "7  Acton 2020-04-10                5                  4.0        6522   \n",
      "8  Acton 2020-04-11                5                  0.0        6522   \n",
      "9  Acton 2020-04-12                5                  0.0        6522   \n",
      "\n",
      "   Density_Per_Sq_Mile  Income_level driving transit walking  \\\n",
      "0                  166             2   52.04    26.3    52.6   \n",
      "1                  166             2   44.77   22.14   48.28   \n",
      "2                  166             2   33.92   19.22   36.02   \n",
      "3                  166             2   40.81   21.76   37.63   \n",
      "4                  166             2   41.36   22.16   38.13   \n",
      "5                  166             2   42.38   21.82   41.92   \n",
      "6                  166             2   40.85    19.1   35.31   \n",
      "7                  166             2   48.47    21.7    45.5   \n",
      "8                  166             2   46.57   21.66   50.85   \n",
      "9                  166             2   30.88    17.8   31.73   \n",
      "\n",
      "   retail_and_recreation_percent_change_from_baseline  \\\n",
      "0                                              -43.0    \n",
      "1                                              -50.0    \n",
      "2                                              -53.0    \n",
      "3                                              -49.0    \n",
      "4                                              -51.0    \n",
      "5                                              -49.0    \n",
      "6                                              -55.0    \n",
      "7                                              -49.0    \n",
      "8                                              -51.0    \n",
      "9                                              -64.0    \n",
      "\n",
      "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
      "0                                              -15.0   \n",
      "1                                              -20.0   \n",
      "2                                              -27.0   \n",
      "3                                              -27.0   \n",
      "4                                              -30.0   \n",
      "5                                              -27.0   \n",
      "6                                              -34.0   \n",
      "7                                              -22.0   \n",
      "8                                              -19.0   \n",
      "9                                              -38.0   \n",
      "\n",
      "   parks_percent_change_from_baseline  \\\n",
      "0                               -38.0   \n",
      "1                               -54.0   \n",
      "2                               -59.0   \n",
      "3                               -58.0   \n",
      "4                               -58.0   \n",
      "5                               -51.0   \n",
      "6                               -69.0   \n",
      "7                               -55.0   \n",
      "8                               -54.0   \n",
      "9                               -69.0   \n",
      "\n",
      "   transit_stations_percent_change_from_baseline  \\\n",
      "0                                          -51.0   \n",
      "1                                          -51.0   \n",
      "2                                          -57.0   \n",
      "3                                          -59.0   \n",
      "4                                          -58.0   \n",
      "5                                          -57.0   \n",
      "6                                          -65.0   \n",
      "7                                          -58.0   \n",
      "8                                          -52.0   \n",
      "9                                          -60.0   \n",
      "\n",
      "   workplaces_percent_change_from_baseline  \\\n",
      "0                                    -51.0   \n",
      "1                                    -41.0   \n",
      "2                                    -43.0   \n",
      "3                                    -54.0   \n",
      "4                                    -54.0   \n",
      "5                                    -55.0   \n",
      "6                                    -57.0   \n",
      "7                                    -57.0   \n",
      "8                                    -43.0   \n",
      "9                                    -46.0   \n",
      "\n",
      "   residential_percent_change_from_baseline  ave_new7_10after  \\\n",
      "0                                      25.0              1.00   \n",
      "1                                      20.0              0.00   \n",
      "2                                      17.0              0.00   \n",
      "3                                      25.0              0.00   \n",
      "4                                      26.0              1.00   \n",
      "5                                      26.0              1.00   \n",
      "6                                      29.0              1.00   \n",
      "7                                      29.0              1.25   \n",
      "8                                      20.0              0.75   \n",
      "9                                      18.0              0.75   \n",
      "\n",
      "   ave_new6_9after  ave_new8_11after  \n",
      "0             1.00              0.00  \n",
      "1             1.00              0.00  \n",
      "2             0.00              0.00  \n",
      "3             0.00              1.00  \n",
      "4             0.00              1.00  \n",
      "5             1.00              1.00  \n",
      "6             1.00              1.25  \n",
      "7             1.00              0.75  \n",
      "8             1.25              0.75  \n",
      "9             0.75              0.75  \n",
      "     ZIP       date  confirmed_cases  new_confirmed_cases  population  \\\n",
      "0  Acton 2020-04-03                1                  0.0        6522   \n",
      "1  Acton 2020-04-04                1                  0.0        6522   \n",
      "2  Acton 2020-04-05                1                  0.0        6522   \n",
      "3  Acton 2020-04-06                1                  0.0        6522   \n",
      "4  Acton 2020-04-07                1                  0.0        6522   \n",
      "5  Acton 2020-04-08                1                  0.0        6522   \n",
      "6  Acton 2020-04-09                1                  0.0        6522   \n",
      "7  Acton 2020-04-10                5                  4.0        6522   \n",
      "8  Acton 2020-04-11                5                  0.0        6522   \n",
      "9  Acton 2020-04-12                5                  0.0        6522   \n",
      "\n",
      "   Density_Per_Sq_Mile  Income_level driving transit walking  \\\n",
      "0                  166             2   52.04    26.3    52.6   \n",
      "1                  166             2   44.77   22.14   48.28   \n",
      "2                  166             2   33.92   19.22   36.02   \n",
      "3                  166             2   40.81   21.76   37.63   \n",
      "4                  166             2   41.36   22.16   38.13   \n",
      "5                  166             2   42.38   21.82   41.92   \n",
      "6                  166             2   40.85    19.1   35.31   \n",
      "7                  166             2   48.47    21.7    45.5   \n",
      "8                  166             2   46.57   21.66   50.85   \n",
      "9                  166             2   30.88    17.8   31.73   \n",
      "\n",
      "   retail_and_recreation_percent_change_from_baseline  \\\n",
      "0                                              -43.0    \n",
      "1                                              -50.0    \n",
      "2                                              -53.0    \n",
      "3                                              -49.0    \n",
      "4                                              -51.0    \n",
      "5                                              -49.0    \n",
      "6                                              -55.0    \n",
      "7                                              -49.0    \n",
      "8                                              -51.0    \n",
      "9                                              -64.0    \n",
      "\n",
      "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
      "0                                              -15.0   \n",
      "1                                              -20.0   \n",
      "2                                              -27.0   \n",
      "3                                              -27.0   \n",
      "4                                              -30.0   \n",
      "5                                              -27.0   \n",
      "6                                              -34.0   \n",
      "7                                              -22.0   \n",
      "8                                              -19.0   \n",
      "9                                              -38.0   \n",
      "\n",
      "   parks_percent_change_from_baseline  \\\n",
      "0                               -38.0   \n",
      "1                               -54.0   \n",
      "2                               -59.0   \n",
      "3                               -58.0   \n",
      "4                               -58.0   \n",
      "5                               -51.0   \n",
      "6                               -69.0   \n",
      "7                               -55.0   \n",
      "8                               -54.0   \n",
      "9                               -69.0   \n",
      "\n",
      "   transit_stations_percent_change_from_baseline  \\\n",
      "0                                          -51.0   \n",
      "1                                          -51.0   \n",
      "2                                          -57.0   \n",
      "3                                          -59.0   \n",
      "4                                          -58.0   \n",
      "5                                          -57.0   \n",
      "6                                          -65.0   \n",
      "7                                          -58.0   \n",
      "8                                          -52.0   \n",
      "9                                          -60.0   \n",
      "\n",
      "   workplaces_percent_change_from_baseline  \\\n",
      "0                                    -51.0   \n",
      "1                                    -41.0   \n",
      "2                                    -43.0   \n",
      "3                                    -54.0   \n",
      "4                                    -54.0   \n",
      "5                                    -55.0   \n",
      "6                                    -57.0   \n",
      "7                                    -57.0   \n",
      "8                                    -43.0   \n",
      "9                                    -46.0   \n",
      "\n",
      "   residential_percent_change_from_baseline  ave_new7_10after  \n",
      "0                                      25.0              1.00  \n",
      "1                                      20.0              0.00  \n",
      "2                                      17.0              0.00  \n",
      "3                                      25.0              0.00  \n",
      "4                                      26.0              1.00  \n",
      "5                                      26.0              1.00  \n",
      "6                                      29.0              1.00  \n",
      "7                                      29.0              1.25  \n",
      "8                                      20.0              0.75  \n",
      "9                                      18.0              0.75  \n"
     ]
    }
   ],
   "source": [
    "print(LA_daily.head(10))\n",
    "print(LA_daily_predict.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_daily.py\n",
    "\"\"\"    super parameter     \"\"\"\n",
    "day_input = 6                      # how many days' feature we use to predict\n",
    "timelagging = 6                     # the length of latent window of Social Distancing data & Mobility data\n",
    "average_num = 4                     # how many days does the average cases get from\n",
    "### change the feature numbers  ###\n",
    "feature_num = 14+2*(day_input-1)    # the number of feature that one input contains\n",
    "### -------------------------  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_daily.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from parameter_daily import day_input, average_num, feature_num, timelagging\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, input, output):\n",
    "        super(Mydataset, self).__init__()\n",
    "        self.input = input\n",
    "        self.lable = output\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index], self.lable[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "\n",
    "def dataset_generate_daily():\n",
    "    \"\"\"    read data in and clean!     \"\"\"\n",
    "\n",
    "    ### change the input datset name ###\n",
    "#     filename = \"LA_daily.csv\"\n",
    "    ### ---------------------------- ###\n",
    "    zipcode_daily = LA_daily\n",
    "#     pd.read_csv(filename, encoding=\"ISO-8859-1\", dtype={'ZIP': str, 'date': str})\n",
    "    zip = zipcode_daily['ZIP']  # 'ZIP' column\n",
    "    date = zipcode_daily['date']  # we have to preserve the date\n",
    "    del zipcode_daily['ZIP']  # delete the non-numeric columns\n",
    "    del zipcode_daily['date']\n",
    "    zipcode_daily = pd.DataFrame(zipcode_daily, dtype=float)  # change the type from 'int' to 'float'\n",
    "    zipcode_daily['ZIP'] = zip  # add the 'ZIP' column again\n",
    "\n",
    "    # key: 'zip code', value: feature that belong to the 'zip code'\n",
    "    data_dict = {}\n",
    "    for i, zipcode in enumerate(zipcode_daily[:]['ZIP']):\n",
    "        if zipcode not in data_dict:\n",
    "            data_dict[zipcode] = []\n",
    "        feature = []\n",
    "        for f in zipcode_daily.iloc[i]:\n",
    "            feature.append(f)\n",
    "        data_dict[zipcode].append(feature)\n",
    "\n",
    "    data_x = []  # input\n",
    "    data_y = []  # lable\n",
    "    for key, values in data_dict.items():\n",
    "        l = len(values)\n",
    "        input_num = l - timelagging - average_num  # determine how many input here\n",
    "        feature = []\n",
    "        for i in range(input_num):  # one input point contains 6 days's data, that is day1~day6\n",
    "            first = True\n",
    "            for j in range(day_input):\n",
    "                if first:  # one input point contains all the feature of day1\n",
    "                    for k in values[i][:-4]:\n",
    "                        feature.append(k)\n",
    "                    first = False\n",
    "                else:  # for day2~day6, one input point only contains confirmed_cases & new_confirmed_cases\n",
    "                    feature.append(values[i + j][0])\n",
    "                    feature.append(values[i + j][1])\n",
    "            data_y.append(values[i][-4])  # output: average cases, that is ave_new7_10after\n",
    "            tmp = []\n",
    "            tmp.append(feature)\n",
    "            data_x.append(tmp)  # size: [1, feature_num]\n",
    "            feature = []\n",
    "    # split data to train and test, and split test to validation and test in the following.\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(data_x, data_y, test_size=0.3,\n",
    "                                                                        random_state=1)\n",
    "\n",
    "    train_x_ls = []  # Change the format for later processing\n",
    "    for j in train_x:\n",
    "        for i in j:\n",
    "            train_x_ls.append(i)\n",
    "    train_x_df = pd.DataFrame(train_x_ls)\n",
    "    train_y_df = pd.DataFrame(train_y)\n",
    "    train_x_mean = train_x_df.mean()  # train_x dataset mean\n",
    "    train_x_std = train_x_df.std()  # train_x dataset std\n",
    "    train_y_mean = train_y_df.mean()  # train_y dataset mean\n",
    "    train_y_std = train_y_df.std()  # train_y dataset std\n",
    "\n",
    "    for i in range(len(train_x)):       # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(train_x[i])):\n",
    "            for k in range(len(train_x[i][j])):\n",
    "                train_x[i][j][k] = (train_x[i][j][k] - train_x_mean[k]) / train_x_std[k]\n",
    "\n",
    "    for i in range(len(train_y)):       # using train_y mean and train_y std to normalize\n",
    "        train_y[i] = (train_y[i] - train_y_mean) / train_y_std\n",
    "\n",
    "    for i in range(len(test_x)):        # using train_x mean and train_x std to normalize\n",
    "        for j in range(len(test_x[i])):\n",
    "            for k in range(len(test_x[i][j])):\n",
    "                test_x[i][j][k] = (test_x[i][j][k] - train_x_mean[k]) / train_x_std[k]\n",
    "\n",
    "    for i in range(len(test_y)):        # using train_y mean and train_y std to normalize\n",
    "        test_y[i] = (test_y[i] - train_y_mean) / train_y_std\n",
    "\n",
    "    # split test to validation and test\n",
    "    validation_x, test_x, validation_y, test_y = model_selection.train_test_split(test_x, test_y, test_size=0.5,\n",
    "                                                                                  random_state=1)\n",
    "    train_x = torch.tensor(train_x)\n",
    "    train_y = torch.tensor(train_y).reshape(-1, 1)\n",
    "    validation_x = torch.tensor(validation_x)\n",
    "    validation_y = torch.tensor(validation_y).reshape(-1, 1)\n",
    "    test_x = torch.tensor(test_x)\n",
    "    test_y = torch.tensor(test_y).reshape(-1, 1)\n",
    "\n",
    "    # define dataset\n",
    "    train_data = Mydataset(train_x, train_y)\n",
    "    trainloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "\n",
    "    return trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "           test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function.py\n",
    "import torch\n",
    "\n",
    "\n",
    "# scale the output value back to its original size and cal the loss\n",
    "def loss_cal(predict, lable, train_mean, train_std):\n",
    "    x = predict[:]\n",
    "    y = lable[:]\n",
    "    for i in range(len(predict)):\n",
    "        x[i][0] = x[i][0] * torch.tensor(train_std) + torch.tensor(train_mean)\n",
    "        y[i][0] = y[i][0] * torch.tensor(train_std) + torch.tensor(train_mean)\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    loss = loss_fun(x, y)\n",
    "    return loss, x, y\n",
    "\n",
    "\n",
    "# change the learning rate\n",
    "def adjust_learning_rate(optimizer, learning_r=None):\n",
    "    i = 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = learning_r\n",
    "        if i == 0:\n",
    "            print(\"optimizer lr : {}\".format(param_group['lr']))\n",
    "            i += 1\n",
    "\n",
    "\n",
    "\"\"\"     define LSTM model   \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, feature_num):\n",
    "        super(Net, self).__init__()\n",
    "        # if batch_first=True, then input shape = (batch, seq, shape)\n",
    "        self.lstm = torch.nn.LSTM(input_size=feature_num, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(64 * 1, 32)\n",
    "        self.linear1 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(-1, 64 * 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_daily.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from dataset_daily import dataset_generate_daily\n",
    "#from function import loss_cal, adjust_learning_rate, Net\n",
    "#from parameter_daily import feature_num\n",
    "\n",
    "\n",
    "def train_daily():\n",
    "\n",
    "    trainloader, train_x, train_y, validation_x, validation_y, test_x, test_y, \\\n",
    "    train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate_daily()\n",
    "\n",
    "    \"\"\"         training start!         \"\"\"\n",
    "    # determine optimizer, loss_function and checkpoint path\n",
    "    model = Net(feature_num)\n",
    "    learning_r = 0.0002\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_r)\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    ### change the path name ###\n",
    "    path = 'checkpoint_0727.tar'\n",
    "    ### ------------------- ###\n",
    "\n",
    "    \"\"\" if you want train your model from a pre-trained model, uncomment the following code. \"\"\"\n",
    "    # checkpoint = torch.load(path)\n",
    "    # model.load_state_dict(checkpoint['net'])\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # validation_loss = checkpoint['best_validation_loss']\n",
    "    # learning_r = 6.400000000000004e-8\n",
    "\n",
    "    model.train()\n",
    "    # val_loss_info = [validation_loss]\n",
    "    val_loss_info = []      # preserve every epoch's train loss\n",
    "    train_loss_info = []    # preserve every epoch's validation loss\n",
    "    not_improve = 0\n",
    "    for epoch in range(1500):\n",
    "        for i, values in enumerate(trainloader):\n",
    "            input, lable = values\n",
    "            output = model(input)\n",
    "            loss = loss_fun(output, lable)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0 and epoch > 0:\n",
    "            train_loss = loss_fun(model(train_x),train_y).item()\n",
    "            vali_loss = loss_fun(model(validation_x), validation_y).item()\n",
    "            if len(val_loss_info) == 0 or vali_loss < min(val_loss_info):  # save the best model\n",
    "                not_improve = 0\n",
    "                state = {'net': model.state_dict(), 'optimizer': optimizer.state_dict(),'best_validation_loss': vali_loss}\n",
    "                torch.save(state, path)\n",
    "                print(\"Saved the model.\")\n",
    "            else:                           # if validation loss didn't decrease, reload the best model in next epoch.\n",
    "                checkpoint = torch.load(path)\n",
    "                model.load_state_dict(checkpoint['net'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                not_improve += 1\n",
    "                print(\"not_improve : {}\".format(not_improve))\n",
    "            if (not_improve+1) % 8 == 0:    # when validation loss doesn't decrease for 7 epochs, reduce the learning rate.\n",
    "                learning_r *= 0.2\n",
    "                adjust_learning_rate(optimizer, learning_r)\n",
    "            if (not_improve+1) % 25 == 0:   # early stopping\n",
    "                print(\"Training End......\")\n",
    "                break\n",
    "\n",
    "            print(\"epoch:{}, train_loss:{}, vali_loss: {}\".format(epoch, train_loss, vali_loss))\n",
    "            train_loss_info.append(train_loss)\n",
    "            val_loss_info.append(vali_loss)\n",
    "\n",
    "    return train_loss_info, val_loss_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_daily.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#from function import loss_cal, adjust_learning_rate, Net\n",
    "#from parameter_daily import feature_num\n",
    "import numpy as np\n",
    "\n",
    "def test_daily(path, test_x, test_y, train_mean, train_std):\n",
    "    \"\"\"     test start!     \"\"\"\n",
    "    # using the test dataset to test model\n",
    "    model = Net(feature_num)\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    model.eval()\n",
    "    predict = model(test_x)\n",
    "    real = test_y.clone()\n",
    "\n",
    "    loss_fun = torch.nn.MSELoss()\n",
    "    # two losses, one is normalized scale, another is original scale\n",
    "    loss = loss_fun(predict, real)\n",
    "    loss_original_scale, pre, rea = loss_cal(predict, real, train_mean, train_std)\n",
    "    pre = np.array(pre.data)\n",
    "    rea = np.array(rea.data)\n",
    "    print(\"Test loss: \" + str(loss))\n",
    "    print(\"Test loss in original scale: \" + str(loss_original_scale))\n",
    "\n",
    "    # true output and predicted output\n",
    "    plt.figure(2)\n",
    "    plt.plot(list(rea), label=\"real\")\n",
    "    plt.plot(list(pre), label=\"pred\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # true output and predicted output\n",
    "    plt.figure(3)\n",
    "    min_val = min(rea)\n",
    "    max_val = max(rea)\n",
    "    plt.scatter(rea,pre)\n",
    "    plt.plot([min_val,max_val],[min_val,max_val],color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\"\"\"\n",
    "\n",
    "In this project, We created a LSTM model to predict covid-19 daily new_cases and weekly new cases in Los Angeles.\n",
    "\n",
    "If you find anything wrong with the code, please feel free to contact us.\n",
    "\n",
    "@University: Umich & ZJU\n",
    "@author: Wenxue Li, Zixian Ma, Xinyu Li\n",
    "@email: liwenxue@zju.edu.cn, 3170103467@zju.edu.cn\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from dataset_daily import dataset_generate_daily\n",
    "from dataset_weekly import dataset_generate\n",
    "from train_daily import train_daily\n",
    "from train_weekly import train_weekly\n",
    "from test_daily import test_daily\n",
    "from test_weekly import test_weekly\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='COVID-LSTM')\n",
    "parser.add_argument('--mode', default='train', type=str, help='choose train or test')\n",
    "parser.add_argument('--type', default='daily', type=str, help='daily or weekly')\n",
    "\n",
    "args = parser.parse_args(args=[]) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the model.\n",
      "epoch:10, train_loss:0.23284544050693512, vali_loss: 0.22984692454338074\n",
      "Saved the model.\n",
      "epoch:20, train_loss:0.21980363130569458, vali_loss: 0.21790167689323425\n",
      "Saved the model.\n",
      "epoch:30, train_loss:0.20655454695224762, vali_loss: 0.20924806594848633\n",
      "Saved the model.\n",
      "epoch:40, train_loss:0.19708341360092163, vali_loss: 0.19989752769470215\n",
      "Saved the model.\n",
      "epoch:50, train_loss:0.19001129269599915, vali_loss: 0.19566801190376282\n",
      "Saved the model.\n",
      "epoch:60, train_loss:0.1840878427028656, vali_loss: 0.1917216181755066\n",
      "Saved the model.\n",
      "epoch:70, train_loss:0.1798422932624817, vali_loss: 0.1901325285434723\n",
      "Saved the model.\n",
      "epoch:80, train_loss:0.17533449828624725, vali_loss: 0.18775783479213715\n",
      "Saved the model.\n",
      "epoch:90, train_loss:0.17147515714168549, vali_loss: 0.1875474750995636\n",
      "not_improve : 1\n",
      "epoch:100, train_loss:0.16807495057582855, vali_loss: 0.1875678449869156\n",
      "not_improve : 2\n",
      "epoch:110, train_loss:0.16911639273166656, vali_loss: 0.1890987604856491\n",
      "not_improve : 3\n",
      "epoch:120, train_loss:0.16886237263679504, vali_loss: 0.1891438215970993\n",
      "not_improve : 4\n",
      "epoch:130, train_loss:0.16801530122756958, vali_loss: 0.18788471817970276\n",
      "not_improve : 5\n",
      "epoch:140, train_loss:0.17178644239902496, vali_loss: 0.1913694441318512\n",
      "not_improve : 6\n",
      "epoch:150, train_loss:0.16981202363967896, vali_loss: 0.18938389420509338\n",
      "not_improve : 7\n",
      "optimizer lr : 4e-05\n",
      "epoch:160, train_loss:0.16822296380996704, vali_loss: 0.18858951330184937\n",
      "not_improve : 8\n",
      "epoch:170, train_loss:0.17051997780799866, vali_loss: 0.18778909742832184\n",
      "not_improve : 9\n",
      "epoch:180, train_loss:0.1677752137184143, vali_loss: 0.18771976232528687\n",
      "not_improve : 10\n",
      "epoch:190, train_loss:0.16821704804897308, vali_loss: 0.18809813261032104\n",
      "not_improve : 11\n",
      "epoch:200, train_loss:0.16798338294029236, vali_loss: 0.1881624162197113\n",
      "not_improve : 12\n",
      "epoch:210, train_loss:0.16805492341518402, vali_loss: 0.18870790302753448\n",
      "not_improve : 13\n",
      "epoch:220, train_loss:0.16891439259052277, vali_loss: 0.19001737236976624\n",
      "not_improve : 14\n",
      "epoch:230, train_loss:0.16845251619815826, vali_loss: 0.1878204047679901\n",
      "not_improve : 15\n",
      "optimizer lr : 8.000000000000001e-06\n",
      "epoch:240, train_loss:0.1742476522922516, vali_loss: 0.19385454058647156\n",
      "not_improve : 16\n",
      "epoch:250, train_loss:0.17111706733703613, vali_loss: 0.18755832314491272\n",
      "not_improve : 17\n",
      "epoch:260, train_loss:0.16831658780574799, vali_loss: 0.18787169456481934\n",
      "not_improve : 18\n",
      "epoch:270, train_loss:0.1685483455657959, vali_loss: 0.18879172205924988\n",
      "not_improve : 19\n",
      "epoch:280, train_loss:0.16842207312583923, vali_loss: 0.18851235508918762\n",
      "not_improve : 20\n",
      "epoch:290, train_loss:0.1698915958404541, vali_loss: 0.18902187049388885\n",
      "not_improve : 21\n",
      "epoch:300, train_loss:0.16811566054821014, vali_loss: 0.18776017427444458\n",
      "not_improve : 22\n",
      "epoch:310, train_loss:0.16797371208667755, vali_loss: 0.18930695950984955\n",
      "not_improve : 23\n",
      "optimizer lr : 1.6000000000000004e-06\n",
      "epoch:320, train_loss:0.16810159385204315, vali_loss: 0.18768736720085144\n",
      "Saved the model.\n",
      "epoch:330, train_loss:0.17128069698810577, vali_loss: 0.18748024106025696\n",
      "not_improve : 1\n",
      "epoch:340, train_loss:0.17122969031333923, vali_loss: 0.18754513561725616\n",
      "not_improve : 2\n",
      "epoch:350, train_loss:0.17122864723205566, vali_loss: 0.18754947185516357\n",
      "not_improve : 3\n",
      "epoch:360, train_loss:0.17123009264469147, vali_loss: 0.1875459849834442\n",
      "not_improve : 4\n",
      "epoch:370, train_loss:0.17122970521450043, vali_loss: 0.18753524124622345\n",
      "not_improve : 5\n",
      "epoch:380, train_loss:0.17122900485992432, vali_loss: 0.18755225837230682\n",
      "not_improve : 6\n",
      "epoch:390, train_loss:0.1712283194065094, vali_loss: 0.18755576014518738\n",
      "not_improve : 7\n",
      "optimizer lr : 3.200000000000001e-07\n",
      "epoch:400, train_loss:0.17122890055179596, vali_loss: 0.18754766881465912\n",
      "not_improve : 8\n",
      "epoch:410, train_loss:0.17126917839050293, vali_loss: 0.18749766051769257\n",
      "not_improve : 9\n",
      "epoch:420, train_loss:0.17122764885425568, vali_loss: 0.18753741681575775\n",
      "not_improve : 10\n",
      "epoch:430, train_loss:0.17122973501682281, vali_loss: 0.18754537403583527\n",
      "not_improve : 11\n",
      "epoch:440, train_loss:0.17122876644134521, vali_loss: 0.18753191828727722\n",
      "not_improve : 12\n",
      "epoch:450, train_loss:0.17122915387153625, vali_loss: 0.18755052983760834\n",
      "not_improve : 13\n",
      "epoch:460, train_loss:0.17122924327850342, vali_loss: 0.1875416487455368\n",
      "not_improve : 14\n",
      "epoch:470, train_loss:0.171228289604187, vali_loss: 0.18754953145980835\n",
      "not_improve : 15\n",
      "optimizer lr : 6.400000000000003e-08\n",
      "epoch:480, train_loss:0.17122910916805267, vali_loss: 0.1875426024198532\n",
      "not_improve : 16\n",
      "epoch:490, train_loss:0.1712782233953476, vali_loss: 0.18748334050178528\n",
      "not_improve : 17\n",
      "epoch:500, train_loss:0.1712295114994049, vali_loss: 0.18753720819950104\n",
      "not_improve : 18\n",
      "epoch:510, train_loss:0.171230286359787, vali_loss: 0.18753618001937866\n",
      "not_improve : 19\n",
      "epoch:520, train_loss:0.17122876644134521, vali_loss: 0.18754366040229797\n",
      "not_improve : 20\n",
      "epoch:530, train_loss:0.17122946679592133, vali_loss: 0.18756064772605896\n",
      "not_improve : 21\n",
      "epoch:540, train_loss:0.1712292730808258, vali_loss: 0.18755127489566803\n",
      "not_improve : 22\n",
      "epoch:550, train_loss:0.17122943699359894, vali_loss: 0.18752725422382355\n",
      "not_improve : 23\n",
      "optimizer lr : 1.2800000000000007e-08\n",
      "epoch:560, train_loss:0.17122869193553925, vali_loss: 0.18754221498966217\n",
      "not_improve : 24\n",
      "Training End......\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if args.mode == 'train':\n",
    "    if args.type == 'daily':\n",
    "        train_loss_info, val_loss_info = train_daily()\n",
    "        # training loss trend and validation loss trend\n",
    "        plt.figure(1)\n",
    "        plt.plot(train_loss_info, label='train_loss')\n",
    "        plt.plot(val_loss_info, label='val_loss')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "    if args.type == 'weekly':\n",
    "        train_loss_info, val_loss_info = train_weekly()\n",
    "        # training loss trend and validation loss trend\n",
    "        plt.figure(1)\n",
    "        plt.plot(train_loss_info, label='train_loss')\n",
    "        plt.plot(val_loss_info, label='val_loss')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode == 'test':\n",
    "    if args.type == 'daily':\n",
    "        trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "        test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate_daily()\n",
    "        # path = 'checkpoint_1.tar'\n",
    "        path = 'checkpoint_daily.tar'\n",
    "        test_daily(path, test_x, test_y, train_y_mean, train_y_std)\n",
    "    if args.type == 'weekly':\n",
    "        # path = 'checkpoint_2.tar'\n",
    "        path = 'checkpoint_weekly_sequential.tar'\n",
    "        trainloader, train_x, train_y, validation_x, validation_y, \\\n",
    "        test_x, test_y, train_x_mean, train_x_std, train_y_mean, train_y_std = dataset_generate()\n",
    "        test_weekly(path, test_x, test_y, train_y_mean, train_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_predict_4_day_avg.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "day_input = 6\n",
    "timelagging = 6\n",
    "average_num = 4\n",
    "### change the numbers of feature ###\n",
    "feature_num = 14+2*(day_input-1)\n",
    "### ------------------------###\n",
    "\n",
    "\"\"\"     read in data and process, this part is very similar to lstm_1.py    \"\"\"\n",
    "### change the input dataset name ###\n",
    "# filename = \"LA_daily_predict.csv\"\n",
    "### --------------------------- ###\n",
    "zipcode_daily = LA_daily_predict\n",
    "# pd.read_csv(filename, encoding=\"ISO-8859-1\", dtype={'ZIP': str, 'date': str})\n",
    "zip = zipcode_daily['ZIP']\n",
    "date = zipcode_daily['date']  # we have to preserve the date\n",
    "del zipcode_daily['ZIP']\n",
    "del zipcode_daily['date']\n",
    "zipcode_daily = pd.DataFrame(zipcode_daily, dtype=float)  # change the type from 'int' to 'float'\n",
    "zipcode_daily['ZIP'] = zip\n",
    "zipcode_daily['date'] = date  # add date back\n",
    "\n",
    "data_dict = {}  # key: 'zip', value: feature that belong to the key\n",
    "for i, zipcode in enumerate(zipcode_daily[:]['ZIP']):\n",
    "    if zipcode not in data_dict:\n",
    "        data_dict[zipcode] = []\n",
    "    feature = []\n",
    "    for f in zipcode_daily.iloc[i]:\n",
    "        feature.append(f)\n",
    "    data_dict[zipcode].append(feature)\n",
    "\n",
    "zipcode = []  # save 'zip code' correlating to input point\n",
    "date = []     # save 'date' correlating to input point\n",
    "\n",
    "data_x = []  # input\n",
    "for key, values in data_dict.items():\n",
    "    l = len(values)\n",
    "    input_num = l - timelagging - average_num\n",
    "    feature = []\n",
    "    input_num=input_num+5\n",
    "    for i in range(input_num):\n",
    "        first = True\n",
    "        for j in range(day_input):\n",
    "            if first:\n",
    "                zipcode.append(values[i][-2])   # save 'zip code' correlating to ont input point\n",
    "                date.append(values[i][-1])      # save 'date' correlating to ont input point\n",
    "                # because we add 'date' back, the last feature is values[i][:-5] not values[i][:-4]\n",
    "                for k in values[i][:-3]:\n",
    "                    feature.append(k)\n",
    "                first = False\n",
    "            else:\n",
    "                feature.append(values[i + j][0])\n",
    "                feature.append(values[i + j][1])\n",
    "        tmp = []\n",
    "        tmp.append(feature)\n",
    "        data_x.append(tmp)  # one input point\n",
    "        feature = []\n",
    "\n",
    "data_x_ls = []\n",
    "for j in data_x:\n",
    "    for i in j:\n",
    "        data_x_ls.append(i)\n",
    "data_x_df = pd.DataFrame(data_x_ls)\n",
    "data_x_mean = data_x_df.mean()  # train dataset mean\n",
    "data_x_std = data_x_df.std()    # train dataset std\n",
    "\n",
    "for i in range(len(data_x)):    # using train_x mean and train_x std to normalize\n",
    "    for j in range(len(data_x[i])):\n",
    "        for k in range(len(data_x[i][j])):\n",
    "            data_x[i][j][k] = (data_x[i][j][k] - data_x_mean[k]) / data_x_std[k]\n",
    "\n",
    "data_x = torch.tensor(data_x)\n",
    "\n",
    "\n",
    "# scale the output value back to its original size and cal the loss\n",
    "def upscale(predict):\n",
    "    x = predict[:]\n",
    "    for i in range(len(predict)):\n",
    "        x[i][0] = x[i][0] * torch.tensor(data_x_std[1]) + torch.tensor(data_x_mean[1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     define LSTM model   \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # if batch_first=True, then input shape = (batch, seq, shape)\n",
    "        self.lstm = torch.nn.LSTM(input_size=feature_num, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(64 * 1, 32)\n",
    "        self.linear1 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(-1, 64 * 1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "### change the path name ###\n",
    "path = 'checkpoint_0727.tar'\n",
    "### -------------------- ###\n",
    "# load from file\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "model.eval()\n",
    "predict = np.array(model(data_x).data)  # output\n",
    "predict_upscale = upscale(predict)      # original scale output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "###\n",
    "date_list = []\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-04-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-05-'+str(i))\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-06-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-07-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-08-'+str(i))\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-09-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-10-'+str(i))\n",
    "for i in range(1,31):\n",
    "    date_list.append('2020-11-'+str(i))\n",
    "for i in range(1,32):\n",
    "    date_list.append('2020-12-'+str(i))\n",
    "\n",
    "\n",
    "date_list_new = []\n",
    "\"\"\"\n",
    "for date_ in date:\n",
    "    date_start = date_list[date_list.index(date_)+6]\n",
    "    date_end = date_list[date_list.index(date_)+9]\n",
    "    date_list_new.append(date_start+' - ' + date_end)\n",
    "\"\"\"\n",
    "for date_ in date:\n",
    "    date_start = (date_+datetime.timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "    date_end = (date_+datetime.timedelta(days=9)).strftime(\"%Y-%m-%d\")\n",
    "    date_list_new.append(date_start+' - ' + date_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region                Timestamp  Predicted new cases Risk_score_level  \\\n",
      "0  Acton  2020-04-09 - 2020-04-12            -1.373654             None   \n",
      "1  Acton  2020-04-10 - 2020-04-13            -1.713336             None   \n",
      "2  Acton  2020-04-11 - 2020-04-14            -0.108346             None   \n",
      "3  Acton  2020-04-12 - 2020-04-15            -1.042562             None   \n",
      "4  Acton  2020-04-13 - 2020-04-16            -1.036026             None   \n",
      "\n",
      "   Risk_score  \n",
      "0   -2.106185  \n",
      "1   -2.627011  \n",
      "2   -0.166124  \n",
      "3   -1.598530  \n",
      "4   -1.588510  \n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame()                            # generate table\n",
    "out['Region'] = zipcode                            # zip code column\n",
    "out['Timestamp'] = date_list_new    # date column\n",
    "out['Predicted new cases'] = predict_upscale     # predicted new cases columns\n",
    "out['Risk_score_level']=None\n",
    "###\n",
    "url5=\"https://raw.githubusercontent.com/skasralikar/Risk-Score-1-UMichZJU/master/data/LApopulation.csv\"\n",
    "pop = pd.read_csv(url5, index_col = False)  # population data\n",
    "###\n",
    "for i in range(out.shape[0]):\n",
    "    for j in range(pop.shape[0]):\n",
    "        if (out.at[i,'Region'] == pop.at[j,'ZIP']):\n",
    "            out.at[i,'Risk_score'] = 10000 * out.at[i,'Predicted new cases'] / pop.at[j,'population']\n",
    "\n",
    "print(out.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region                Timestamp  Predicted new cases  Risk_score_level  \\\n",
      "0  Acton  2020-04-09 - 2020-04-12            -1.373654                 1   \n",
      "1  Acton  2020-04-10 - 2020-04-13            -1.713336                 1   \n",
      "2  Acton  2020-04-11 - 2020-04-14            -0.108346                 1   \n",
      "3  Acton  2020-04-12 - 2020-04-15            -1.042562                 1   \n",
      "4  Acton  2020-04-13 - 2020-04-16            -1.036026                 1   \n",
      "\n",
      "   Risk_score  \n",
      "0   -2.106185  \n",
      "1   -2.627011  \n",
      "2   -0.166124  \n",
      "3   -1.598530  \n",
      "4   -1.588510  \n"
     ]
    }
   ],
   "source": [
    "# defind the risk score level\n",
    "# 1-very low level(risk score <=0.1)\n",
    "# 2-low level(0.1<risk score <=1)\n",
    "# 3-medium level(1<risk score <=2)\n",
    "# 4-high level(risk score >2)\n",
    "for i in range(len(out)):\n",
    "    if out['Risk_score'][i]<=0.1:\n",
    "        out.loc[i,'Risk_score_level']=1\n",
    "    elif out['Risk_score'][i]<=1:\n",
    "        out.loc[i,'Risk_score_level']=2\n",
    "    elif out['Risk_score'][i]<=2:\n",
    "        out.loc[i,'Risk_score_level']=3\n",
    "    else:\n",
    "        out.loc[i,'Risk_score_level']=4\n",
    "print(out.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region    Timestamp  Risk_score_level  Risk_score\n",
      "0  Acton  2020-04-09                  1   -2.106185\n",
      "1  Acton  2020-04-10                  1   -2.627011\n",
      "2  Acton  2020-04-11                  1   -0.166124\n",
      "3  Acton  2020-04-12                  1   -1.598530\n",
      "4  Acton  2020-04-13                  1   -1.588510\n"
     ]
    }
   ],
   "source": [
    "out=out.drop(columns=['Predicted new cases'])\n",
    "for i in range(len(out)):\n",
    "    out.loc[i,'Timestamp']=out.loc[i,'Timestamp'][0:11]\n",
    "print(out.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the output dataset name ###\n",
    "out.to_csv('LA_daily_out.csv')\n",
    "### ----------------------------   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
